# =============================================================================
# BrikByteOS ‚Äî Reusable Python Unit Test Workflow
# -----------------------------------------------------------------------------
# WBS ID : PIPE-TEST-UNIT-CI-BUILD-002
# Repos  :
#   - Implemented in:
#       ‚Ä¢ BrikByte-Studios/.github (.github/workflows/test-python.yml)
#   - Consumed by:
#       ‚Ä¢ BrikByte-Studios/brik-pipe-examples/python-api-example
#       ‚Ä¢ Product repos (via workflow_call)
#
# Contract:
#   - Expects:
#       ‚Ä¢ Makefile with `make test` calling `pytest`
#       ‚Ä¢ tests/ directory with test_*.py / *_test.py
#
# Parallelism (Governed):
#   - Uses BrikPipe matrix-plan to compute deterministic shard matrix for unit tests
#   - Default shards + caps come from .github/parallel-matrix.yml (org/repo override)
#   - override_shards input is clamped to caps (if clamp_to_caps=true)
#   - Provides shard env vars for repos that support deterministic splitting:
#       ‚Ä¢ UNIT_SHARD, UNIT_SHARD_TOTAL
#       ‚Ä¢ (aliases) E2E_SHARD, E2E_SHARD_TOTAL (optional compatibility)
# =============================================================================
name: "BrikByteOS ‚Äî Python Unit Tests"

on:
  workflow_call:
    inputs:
      python-version:
        description: "Python version (e.g. 3.11; must match runtime matrix)"
        required: false
        type: string
        default: "3.11"

      working-directory:
        description: "Path to Python project (Makefile + tests/)"
        required: false
        type: string
        default: "."

      # -----------------------------------------------------------------------
      # Governed matrix controls
      # -----------------------------------------------------------------------
      matrix_config_path:
        description: "Optional path to parallel-matrix.yml (repo override). If empty, action uses its default."
        required: false
        type: string
        default: ""

      override_shards:
        description: "Requested shard count (clamped by governance caps). Empty => default from config."
        required: false
        type: string
        default: ""

      parallel_mode:
        description: "Parallel mode: static|dynamic (default static)"
        required: false
        type: string
        default: "static"

      parallel_enabled:
        description: "Enable parallel shard execution (true|false)"
        required: false
        type: string
        default: "true"

      # -----------------------------------------------------------------------
      # Flaky detection (2.5.1)
      # -----------------------------------------------------------------------
      flaky_detect:
        description: "Enable suite-level flaky detection reruns (true|false)"
        required: false
        type: string
        default: "false"

      flaky_reruns:
        description: "Total attempts when flaky_detect=true (e.g., 3)"
        required: false
        type: string
        default: "3"

      flaky_export_path:
        description: "Relative path (from working-directory) to store flaky evidence"
        required: false
        type: string
        default: "out/flaky"

      # -----------------------------------------------------------------------
      # Flaky policy evaluation (2.5.2)
      # -----------------------------------------------------------------------
      flaky_policy_path:
        description: >
          Path to policy-as-code YAML (repo root) IF repo overrides exist.
          NOTE: If missing, central policy from BrikByte-Studios/.github is used.
        required: false
        type: string
        default: ".governance/flaky-tests.yml"

      flaky_policy_enforce:
        description: >
          If true, evaluator may block ONLY if policy enables blocking.
          If false, evaluator still runs (when flaky_detect=true) but never blocks.
        required: false
        type: boolean
        default: true

permissions:
  contents: read

jobs:
  # ----------------------------------------------------------------------------
  # PLAN: governed deterministic shard matrix for unit tests
  # ----------------------------------------------------------------------------
  plan:
    name: "Plan governed unit matrix"
    runs-on: ubuntu-latest
    outputs:
      matrix: ${{ steps.plan.outputs.matrix_json }}
    steps:
      - name: "Checkout repository"
        uses: actions/checkout@v4

      - name: "Generate unit shard matrix (governed)"
        id: plan
        uses: BrikByte-Studios/.github/.github/actions/matrix-plan@main
        with:
          test_type: unit
          config_path: ${{ inputs.matrix_config_path }}
          override_shards: ${{ inputs.override_shards }}
          browsers: ""
          items: ""

  # ----------------------------------------------------------------------------
  # MATRIX: run unit tests per shard
  # ----------------------------------------------------------------------------
  test:
    name: "Python: Unit Tests ‚Ä¢ shard ${{ matrix.shard }}"
    needs: plan
    runs-on: ubuntu-latest

    strategy:
      fail-fast: false
      matrix: ${{ fromJson(needs.plan.outputs.matrix) }}

    env:
      LANGUAGE: python
      PYTHON_VERSION: ${{ inputs.python-version != '' && inputs.python-version || '3.11' }}
      WORKING_DIRECTORY: ${{ inputs.working-directory != '' && inputs.working-directory || '.' }}

      # Optional alias (if you want one shared env naming style across runners)
      E2E_SHARD: ${{ matrix.shard }}
      E2E_SHARD_TOTAL: ${{ strategy.job-total }}

      PARALLEL_MODE: ${{ inputs.parallel_mode }}
      PARALLEL: ${{ inputs.parallel_enabled }}

      # Flaky detection (2.5.1)
      FLAKY_DETECT: ${{ inputs.flaky_detect }}
      FLAKY_RERUNS: ${{ inputs.flaky_reruns }}
      FLAKY_EXPORT_PATH: ${{ inputs.flaky_export_path }}

      # Flaky policy (2.5.2)
      FLAKY_POLICY_PATH: ${{ inputs.flaky_policy_path }}
      FLAKY_POLICY_ENFORCE: ${{ inputs.flaky_policy_enforce }}

      FORCE_COLOR: "0"

    steps:
      - name: "Checkout repository"
        uses: actions/checkout@v4

      - name: "Verify Python test layout"
        run: |
          set -euo pipefail
          echo "üìÅ Working directory: ${WORKING_DIRECTORY}"

          if [ ! -d "${WORKING_DIRECTORY}" ]; then
            echo "‚ùå WORKING_DIRECTORY '${WORKING_DIRECTORY}' does not exist."
            exit 1
          fi

          if [ ! -f "${WORKING_DIRECTORY}/Makefile" ]; then
            echo "‚ùå Makefile not found in ${WORKING_DIRECTORY}."
            echo "   Expected 'make test' calling pytest."
            exit 1
          fi

      - name: "Setup Python"
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: "Cache Python dependencies"
        uses: BrikByte-Studios/.github/.github/actions/cache-python-deps@main
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          project-path: ${{ env.WORKING_DIRECTORY }}

      - name: "Compute shard env (1-based for Makefile)"
        shell: bash
        run: |
          set -euo pipefail

          SHARD0='${{ matrix.shard }}'          # 0-based from matrix
          TOTAL='${{ strategy.job-total }}'     # total jobs in this matrix
          SHARD1=$((SHARD0 + 1))                # convert to 1-based

          {
            echo "UNIT_SHARD=${SHARD1}"
            echo "UNIT_SHARD_TOTAL=${TOTAL}"
          } >> "$GITHUB_ENV"

          echo "[SHARD] 0-based=${SHARD0} -> 1-based=${SHARD1} / total=${TOTAL}"

      - name: "Parallel runner (serial/static/dynamic)"
        id: pr
        uses: BrikByte-Studios/.github/.github/actions/parallel-runner@main
        with:
          parallel_enabled: ${{ env.PARALLEL }}
          parallel_mode: ${{ env.PARALLEL_MODE }}
          shard_index: ${{ matrix.shard }}          # 0-based
          shard_total: ${{ strategy.job-total }}
          selection_mode: "file-split"
          working_directory: ${{ env.WORKING_DIRECTORY }}
          test_glob: "tests/unit/**/*test*.py"
          out_list: "${{ env.WORKING_DIRECTORY }}/out/shard-files.txt"
          allow_missing_items_file: true

      # ----------------------------------------------------------------------------
      # Shared scripts repo (flaky-rerun.sh + evaluator sources + central policy)
      # ----------------------------------------------------------------------------
      - name: "Checkout BrikByte shared scripts"
        uses: actions/checkout@v4
        with:
          repository: BrikByte-Studios/.github
          ref: main
          path: .brikbyte-github

      # -----------------------------------------------------------------------
      # Run unit tests via flaky-rerun.sh (2.5.1)
      # -----------------------------------------------------------------------
      - name: "Run Python unit tests (make test) with flaky reruns (opt-in)"
        if: steps.pr.outputs.is_empty_shard != 'true'
        working-directory: ${{ env.WORKING_DIRECTORY }}
        run: |
          set -euo pipefail

          echo "üß™ [TEST] Language     : ${LANGUAGE}"
          echo "üß™ [TEST] Runtime      : Python ${PYTHON_VERSION}"
          echo "üß™ [TEST] Directory    : ${PWD}"
          echo "üß™ [TEST] Command      : make test"
          echo "üß™ [TEST] Shard        : ${UNIT_SHARD}/${UNIT_SHARD_TOTAL}"
          echo "üß™ [TEST] FlakyDetect  : ${FLAKY_DETECT:-false}"
          echo "üß™ [TEST] FlakyReruns  : ${FLAKY_RERUNS:-3}"
          echo "üß™ [TEST] Status       : STARTING"

          export UNIT_SHARD="${UNIT_SHARD}"
          export UNIT_SHARD_TOTAL="${UNIT_SHARD_TOTAL}"
          export TEST_ITEMS_FILE="${{ steps.pr.outputs.selection_path }}"

          mkdir -p out

          BRIK_SCRIPTS="${GITHUB_WORKSPACE}/.brikbyte-github/.github/scripts"
          FLAKY_SH="${BRIK_SCRIPTS}/flaky-rerun.sh"

          if [[ ! -f "${FLAKY_SH}" ]]; then
            echo "‚ùå flaky-rerun.sh not found at: ${FLAKY_SH}"
            echo "üìÅ Available scripts:"
            ls -la "${BRIK_SCRIPTS}" || true
            exit 1
          fi

          chmod +x "${FLAKY_SH}"

          # NOTE: absolute export dir so wrapper writes where we expect.
          export FLAKY_DETECT="${FLAKY_DETECT:-false}"
          export FLAKY_RERUNS="${FLAKY_RERUNS:-3}"
          export FLAKY_EXPORT_PATH="${PWD}/${FLAKY_EXPORT_PATH:-out/flaky}"
          export FLAKY_LABEL="python-unit"

          "${FLAKY_SH}" -- make test

          echo "‚úÖ [TEST] Status       : COMPLETED"

      - name: "Empty shard (skip)"
        if: steps.pr.outputs.is_empty_shard == 'true'
        run: echo "‚ÑπÔ∏è Empty shard ‚Äî nothing to run."

      # =============================================================================
      # PIPE-FLAKY-POLICY-CONFIG-002 ‚Äî Evaluate evidence against policy-as-code
      # Fixes:
      #  - Accepts legacy evidence file: *.summary.json
      #  - Policy selection: repo override -> central fallback
      #  - Module resolution: install js-yaml/tsx at repo root so scripts can require()
      # =============================================================================
      - name: "Setup Node (for flaky policy evaluator)"
        if: ${{ always() && env.FLAKY_DETECT == 'true' }}
        uses: actions/setup-node@v4
        with:
          node-version: "20"

      - name: "Select policy source (repo override -> central fallback)"
        if: ${{ always() && env.FLAKY_DETECT == 'true' }}
        working-directory: ${{ github.workspace }}
        run: |
          set -euo pipefail

          mkdir -p .tmp-flaky-eval

          REPO_POLICY="${GITHUB_WORKSPACE}/${FLAKY_POLICY_PATH}"
          CENTRAL_POLICY="${GITHUB_WORKSPACE}/.brikbyte-github/.governance/flaky-tests.yml"
          OUT_POLICY="${GITHUB_WORKSPACE}/.tmp-flaky-eval/policy.yml"

          echo "üß© [FLAKY] Repo policy     : ${REPO_POLICY}"
          echo "üèõÔ∏è [FLAKY] Central policy  : ${CENTRAL_POLICY}"
          echo "üìå [FLAKY] Selected policy : ${OUT_POLICY}"

          if [[ -f "${REPO_POLICY}" ]]; then
            echo "‚úÖ [FLAKY] Using repo override policy."
            cp "${REPO_POLICY}" "${OUT_POLICY}"
          else
            if [[ ! -f "${CENTRAL_POLICY}" ]]; then
              echo "‚ùå [FLAKY] Central policy missing at: ${CENTRAL_POLICY}"
              exit 1
            fi
            echo "‚úÖ [FLAKY] Repo policy not found; using central policy."
            cp "${CENTRAL_POLICY}" "${OUT_POLICY}"
          fi

      - name: "Install evaluator deps (repo-root, pinned)"
        if: ${{ always() && env.FLAKY_DETECT == 'true' }}
        working-directory: ${{ github.workspace }}
        env:
          NPM_CONFIG_FUND: "false"
          NPM_CONFIG_AUDIT: "false"
        run: |
          set -euo pipefail

          node -v
          npm -v

          if [[ ! -f package.json ]]; then
            npm init -y >/dev/null 2>&1
          fi

          npm i --no-save js-yaml@4 tsx@4 >/dev/null 2>&1
          echo "‚úÖ deps installed into repo-root node_modules"

      - name: "Normalize flaky summary (derive counts from exit_code)"
        if: ${{ always() && env.FLAKY_DETECT == 'true' }}
        working-directory: ${{ env.WORKING_DIRECTORY }}
        run: |
          set -euo pipefail

          EXPORT_DIR="${PWD}/${FLAKY_EXPORT_PATH}"
          EXPECTED="${EXPORT_DIR}/summary.json"
          LABELED="${EXPORT_DIR}/${FLAKY_LABEL:-python-unit}.summary.json"

          # Resolve evidence
          EVIDENCE=""
          if [[ -f "${EXPECTED}" ]]; then
            EVIDENCE="${EXPECTED}"
          elif [[ -f "${LABELED}" ]]; then
            EVIDENCE="${LABELED}"
          else
            found="$(ls -1 "${EXPORT_DIR}"/*.summary.json 2>/dev/null | head -n 1 || true)"
            if [[ -n "${found}" ]]; then EVIDENCE="${found}"; fi
          fi

          if [[ -z "${EVIDENCE}" ]]; then
            echo "‚ÑπÔ∏è [FLAKY] No evidence found ‚Üí skipping normalization."
            exit 0
          fi

          OUT_NORM="${EXPORT_DIR}/summary.normalized.json"
          echo "üîß [FLAKY] Normalizing: ${EVIDENCE} -> ${OUT_NORM}"

          EVIDENCE_PATH="${EVIDENCE}" OUT_NORM_PATH="${OUT_NORM}" python - << 'PY'
          import json, os
          from pathlib import Path

          evidence = Path(os.environ["EVIDENCE_PATH"])
          out_norm = Path(os.environ["OUT_NORM_PATH"])

          data = json.loads(evidence.read_text(encoding="utf-8"))

          attempts = data.get("attempts") if isinstance(data, dict) else None
          if not isinstance(attempts, list):
              attempts = []

          pass_count = 0
          fail_count = 0

          for a in attempts:
              if not isinstance(a, dict):
                  continue

              status = (a.get("status") or a.get("result") or "").lower().strip()
              if status in ("pass", "passed", "ok", "success"):
                  pass_count += 1
                  a["status"] = "pass"
                  continue
              if status in ("fail", "failed", "error"):
                  fail_count += 1
                  a["status"] = "fail"
                  continue

              exit_code = a.get("exit_code")
              try:
                  exit_code = int(exit_code)
              except Exception:
                  exit_code = None

              if exit_code == 0:
                  pass_count += 1
                  a["status"] = "pass"
              else:
                  fail_count += 1
                  a["status"] = "fail"

          total_attempts = len(attempts)

          data["attempts"] = attempts
          data["pass_count"] = pass_count
          data["fail_count"] = fail_count
          data["total_attempts"] = total_attempts

          out_norm.write_text(json.dumps(data, indent=2), encoding="utf-8")
          print(f"‚úÖ wrote {out_norm} (pass={pass_count}, fail={fail_count}, total={total_attempts})")
          PY

      - name: "Evaluate flaky policy (normalized + policy-as-code)"
        if: ${{ always() && env.FLAKY_DETECT == 'true' }}
        working-directory: ${{ env.WORKING_DIRECTORY }}
        run: |
          set -euo pipefail

          EXPORT_DIR="${PWD}/${FLAKY_EXPORT_PATH}"
          POLICY="${GITHUB_WORKSPACE}/.tmp-flaky-eval/policy.yml"

          NORM="${EXPORT_DIR}/summary.normalized.json"
          OUT_JSON="${EXPORT_DIR}/evaluation.json"

          echo "üß© [FLAKY] Policy     : ${POLICY}"
          echo "üìÅ [FLAKY] Export dir : ${EXPORT_DIR}"
          echo "üì• [FLAKY] Normalized : ${NORM}"
          echo "üì§ [FLAKY] Output     : ${OUT_JSON}"
          echo "üõ°Ô∏è [FLAKY] Enforce    : ${FLAKY_POLICY_ENFORCE}"

          if [[ ! -f "${NORM}" ]]; then
            echo "‚ÑπÔ∏è [FLAKY] Normalized summary missing ‚Üí skipping evaluation (non-blocking)."
            exit 0
          fi

          EVAL_TS="${GITHUB_WORKSPACE}/.brikbyte-github/.github/scripts/evaluate-flaky.ts"
          if [[ ! -f "${EVAL_TS}" ]]; then
            echo "‚ùå [FLAKY] evaluate-flaky.ts not found at: ${EVAL_TS}"
            exit 1
          fi

          # Run from local node project so js-yaml always resolves
          pushd "${GITHUB_WORKSPACE}/.tmp-flaky-eval" >/dev/null
          npx tsx "${EVAL_TS}" \
            --policy "${POLICY}" \
            --input "${NORM}" \
            --out "${OUT_JSON}" \
            --md || rc=$?
          popd >/dev/null

          if [[ "${rc:-0}" != "0" && "${FLAKY_POLICY_ENFORCE}" != "true" ]]; then
            echo "‚ö†Ô∏è [FLAKY] Evaluator exit=${rc} but enforce=false ‚Üí not blocking."
            exit 0
          fi

          exit "${rc:-0}"

      - name: Export flaky analytics (when enabled)
        if: ${{ env.FLAKY_DETECT == 'true' }}
        run: |
          set -euo pipefail
          BRIK_SCRIPTS="${GITHUB_WORKSPACE}/.brikbyte-github/.github/scripts"
          FLAKY_SH="${BRIK_SCRIPTS}/export-flaky-analytics.mjs"

          if [[ ! -f "${FLAKY_SH}" ]]; then
            echo "‚ùå export-flaky-analytics.ts not found at: ${FLAKY_SH}"
            echo "üìÅ Available scripts:"
            ls -la "${BRIK_SCRIPTS}" || true
            exit 1
          fi

          chmod +x "${FLAKY_SH}"
          node "${FLAKY_SH}" \
            --suite integ \
            --audit-root .audit \
            --out-dir out/flaky \
            --top-n 10 \
            --write-md true
      - name: "Upload flaky evaluation (always)"
        if: ${{ always() && env.FLAKY_DETECT == 'true' }}
        uses: actions/upload-artifact@v4
        with:
          name: flaky-eval-${{ env.LANGUAGE }}-shard${{ matrix.shard }}
          path: |
            ${{ env.WORKING_DIRECTORY }}/${{ inputs.flaky_export_path }}/
          if-no-files-found: warn
          include-hidden-files: true
          retention-days: 14

      # -----------------------------------------------------------------------
      # Coverage handling + uploads...
      # -----------------------------------------------------------------------
      - name: "Detect coverage outputs (this shard)"
        id: cov
        working-directory: ${{ env.WORKING_DIRECTORY }}
        run: |
          set -euo pipefail
          has_xml="false"
          has_json="false"

          if [ -f "coverage.xml" ]; then has_xml="true"; fi
          if [ -f "out/coverage.json" ]; then has_json="true"; fi

          echo "has_xml=${has_xml}"  >> "$GITHUB_OUTPUT"
          echo "has_json=${has_json}" >> "$GITHUB_OUTPUT"
          echo "üîé has_xml=${has_xml} has_json=${has_json}"

      - name: "Normalize coverage ‚Üí coverage.json"
        if: ${{ steps.cov.outputs.has_xml == 'true' || steps.cov.outputs.has_json == 'true' }}
        uses: BrikByte-Studios/.github/.github/actions/coverage-merge@main
        with:
          language: ${{ env.LANGUAGE }}
          working-directory: ${{ env.WORKING_DIRECTORY }}
          out: out/coverage.json

      - name: Detect out/coverage.json presence
        id: covjson
        working-directory: ${{ env.WORKING_DIRECTORY }}
        run: |
          set -euo pipefail
          if [ -f "out/coverage.json" ]; then
            echo "has_covjson=true" >> "$GITHUB_OUTPUT"
          else
            echo "has_covjson=false" >> "$GITHUB_OUTPUT"
          fi

      - name: "Ensure summary.line is set in coverage.json (Python)"
        if: ${{ steps.cov.outputs.has_xml == 'true' }}
        working-directory: ${{ env.WORKING_DIRECTORY }}
        run: |
          set -euo pipefail
          echo "üîß Normalizing coverage: syncing summary.line from coverage.xml"

          if [ ! -f "coverage.xml" ]; then
            echo "‚ùå coverage.xml not found ‚Äì did pytest run with --cov-report=xml:coverage.xml?"
            ls -R
            exit 1
          fi

          python - << 'EOF'
          import json
          import xml.etree.ElementTree as ET
          from pathlib import Path

          xml_path = Path("coverage.xml")
          tree = ET.parse(xml_path)
          root = tree.getroot()

          line_rate_attr = root.get("line-rate", "0")
          line_rate = float(line_rate_attr) * 100.0

          out_dir = Path("out")
          out_dir.mkdir(parents=True, exist_ok=True)
          cov_path = out_dir / "coverage.json"

          try:
            cov = json.loads(cov_path.read_text(encoding="utf-8"))
          except FileNotFoundError:
            cov = {}

          cov.setdefault("summary", {})
          cov["summary"]["line"] = line_rate
          cov.setdefault("files", [])

          cov_path.write_text(json.dumps(cov, indent=2), encoding="utf-8")
          print(f"‚úÖ Updated out/coverage.json with summary.line = {line_rate:.1f}")
          EOF

      - name: Upload Python coverage artifacts
        if: steps.covjson.outputs.has_covjson == 'true'
        uses: actions/upload-artifact@v4
        with:
          name: coverage-${{ env.LANGUAGE }}-shard${{ matrix.shard }}
          path: |
            ${{ env.WORKING_DIRECTORY }}/out/coverage.json
            ${{ env.WORKING_DIRECTORY }}/coverage.xml
            ${{ env.WORKING_DIRECTORY }}/out/junit.xml
            ${{ env.WORKING_DIRECTORY }}/out/shard-files.txt
            ${{ env.WORKING_DIRECTORY }}/out/shard-packages.txt
          if-no-files-found: error
          include-hidden-files: true
          retention-days: 14

      - name: Upload flaky evidence (always)
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: flaky-${{ env.LANGUAGE }}-shard${{ matrix.shard }}
          path: |
            ${{ env.WORKING_DIRECTORY }}/${{ inputs.flaky_export_path }}/
          if-no-files-found: ignore
          include-hidden-files: true
          retention-days: 14
