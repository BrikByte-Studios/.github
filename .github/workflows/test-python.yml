# =============================================================================
# BrikByteOS ‚Äî Reusable Python Unit Test Workflow
# -----------------------------------------------------------------------------
# WBS ID : PIPE-TEST-UNIT-CI-BUILD-002
# Repos  :
#   - Implemented in:
#       ‚Ä¢ BrikByte-Studios/.github (.github/workflows/test-python.yml)
#   - Consumed by:
#       ‚Ä¢ BrikByte-Studios/brik-pipe-examples/python-api-example
#       ‚Ä¢ Product repos (via workflow_call)
#
# Contract:
#   - Expects:
#       ‚Ä¢ Makefile with `make test` calling `pytest`
#       ‚Ä¢ tests/ directory with test_*.py / *_test.py
#
# Parallelism (Governed):
#   - Uses BrikPipe matrix-plan to compute deterministic shard matrix for unit tests
#   - Default shards + caps come from .github/parallel-matrix.yml (org/repo override)
#   - override_shards input is clamped to caps (if clamp_to_caps=true)
#   - Provides shard env vars for repos that support deterministic splitting:
#       ‚Ä¢ UNIT_SHARD, UNIT_SHARD_TOTAL
#       ‚Ä¢ (aliases) E2E_SHARD, E2E_SHARD_TOTAL (optional compatibility)
# =============================================================================
name: "BrikByteOS ‚Äî Python Unit Tests"

on:
  workflow_call:
    inputs:
      python-version:
        description: "Python version (e.g. 3.11; must match runtime matrix)"
        required: false
        type: string
        default: "3.11"

      working-directory:
        description: "Path to Python project (Makefile + tests/)"
        required: false
        type: string
        default: "."

      # -----------------------------------------------------------------------
      # Governed matrix controls
      # -----------------------------------------------------------------------
      matrix_config_path:
        description: "Optional path to parallel-matrix.yml (repo override). If empty, action uses its default."
        required: false
        type: string
        default: ""

      override_shards:
        description: "Requested shard count (clamped by governance caps). Empty => default from config."
        required: false
        type: string
        default: ""
      parallel_mode:
        description: "Parallel mode: static|dynamic (default static)"
        required: false
        type: string
        default: "static"
      parallel_enabled:
        description: "Enable parallel shard execution (true|false)"
        required: false
        type: string
        default: "true"
permissions:
  contents: read

jobs:
  # ----------------------------------------------------------------------------
  # PLAN: governed deterministic shard matrix for unit tests
  # ----------------------------------------------------------------------------
  plan:
    name: "Plan governed unit matrix"
    runs-on: ubuntu-latest
    outputs:
      matrix: ${{ steps.plan.outputs.matrix_json }}
    steps:
      - name: "Checkout repository"
        uses: actions/checkout@v4

      - name: "Generate unit shard matrix (governed)"
        id: plan
        uses: BrikByte-Studios/.github/.github/actions/matrix-plan@main
        with:
          test_type: unit
          config_path: ${{ inputs.matrix_config_path }}
          override_shards: ${{ inputs.override_shards }}
          # unit doesn't use browsers/items
          browsers: ""
          items: ""

  # ----------------------------------------------------------------------------
  # MATRIX: run unit tests per shard
  # ----------------------------------------------------------------------------
  test:
    name: "Python: Unit Tests ‚Ä¢ shard ${{ matrix.shard }}"
    needs: plan
    runs-on: ubuntu-latest

    strategy:
      fail-fast: false
      matrix: ${{ fromJson(needs.plan.outputs.matrix) }}

    env:
      LANGUAGE: python
      PYTHON_VERSION: ${{ inputs.python-version != '' && inputs.python-version || '3.11' }}
      WORKING_DIRECTORY: ${{ inputs.working-directory != '' && inputs.working-directory || '.' }}

      # Optional alias (if you want one shared env naming style across runners)
      E2E_SHARD: ${{ matrix.shard }}
      E2E_SHARD_TOTAL: ${{ strategy.job-total }}

      PARALLEL_MODE: ${{ inputs.parallel_mode }}
      PARALLEL: ${{ inputs.parallel_enabled }}

      FORCE_COLOR: "0"

    steps:
      - name: "Checkout repository"
        uses: actions/checkout@v4

      - name: "Verify Python test layout"
        run: |
          set -euo pipefail
          echo "üìÅ Working directory: ${WORKING_DIRECTORY}"

          if [ ! -d "${WORKING_DIRECTORY}" ]; then
            echo "‚ùå WORKING_DIRECTORY '${WORKING_DIRECTORY}' does not exist."
            exit 1
          fi

          if [ ! -f "${WORKING_DIRECTORY}/Makefile" ]; then
            echo "‚ùå Makefile not found in ${WORKING_DIRECTORY}."
            echo "   Expected 'make test' calling pytest."
            exit 1
          fi

      - name: "Setup Python"
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      # Optional: central Python cache composite
      - name: "Cache Python dependencies"
        uses: BrikByte-Studios/.github/.github/actions/cache-python-deps@main
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          project-path: ${{ env.WORKING_DIRECTORY }}

      - name: Compute shard env (1-based for Makefile)
        shell: bash
        run: |
          set -euo pipefail

          SHARD0='${{ matrix.shard }}'          # 0-based from matrix
          TOTAL='${{ strategy.job-total }}'     # total jobs in this matrix

          # Convert to 1-based (for your Node Makefile/shard-tests.cjs)
          SHARD1=$((SHARD0 + 1))

          {
            echo "UNIT_SHARD=${SHARD1}"
            echo "UNIT_SHARD_TOTAL=${TOTAL}"
          } >> "$GITHUB_ENV"

          echo "[SHARD] 0-based=${SHARD0} -> 1-based=${SHARD1} / total=${TOTAL}"


      - name: Parallel runner (serial/static/dynamic)
        id: pr
        uses: BrikByte-Studios/.github/.github/actions/parallel-runner@main
        with:
          parallel_enabled: ${{ env.PARALLEL }}
          parallel_mode: ${{ env.PARALLEL_MODE }}
          shard_index: ${{ matrix.shard }}          # 0-based
          shard_total: ${{ strategy.job-total }}
          selection_mode: "file-split"
          working_directory: ${{ env.WORKING_DIRECTORY }}
          test_glob: "tests/unit/**/*test*.py"
          out_list: "${{ env.WORKING_DIRECTORY }}/out/shard-files.txt"
          # items_file: "${{ env.WORKING_DIRECTORY }}/out/test-items.txt"
          # optional knobs:
          # allow_empty_items: true
          # selection_mode: file-split|shard-map|framework-native

      # - name: Discover Python unit test items
      #   shell: bash
      #   run: |
      #     set -euo pipefail
      #     mkdir -p python-api-example/out

      #     # Adjust patterns if your repo differs
      #     find python-api-example -type f \( \
      #       -path "*/tests/*" -o -path "*/test/*" \
      #     \) \( \
      #       -name "test_*.py" -o -name "*_test.py" \
      #     \) | sort > python-api-example/out/test-items.txt

      #     echo "Discovered $(wc -l < python-api-example/out/test-items.txt) items"
      #     head -n 30 python-api-example/out/test-items.txt || true
      #     ls -la python-api-example/out
      # - name: "Plan shards (static/dynamic) ‚Äî non-blocking"
      #   id: shardplan
      #   continue-on-error: true
      #   uses: BrikByte-Studios/.github/.github/actions/shard-plan@main
      #   with:
      #     mode: ${{ env.PARALLEL_MODE }}
      #     shard_count: ${{ env.UNIT_SHARD_TOTAL }}
      #     test_type: "unit"
      #     items_file: "${{ env.WORKING_DIRECTORY }}/out/test-items.txt"
      #     workdir: "${{ env.WORKING_DIRECTORY }}"
      #     out_dir: "${{ env.WORKING_DIRECTORY }}/out"
      #     audit_root: ".audit"
      #     seed: "${{ github.sha }}" # deterministic input

      # - name: "Fallback to static if shard planner failed"
      #   if: steps.shardplan.outcome != 'success'
      #   run: |
      #     echo "::warning::Shard planner failed; falling back to static mode."
      #     echo "PARALLEL_MODE=static" >> "$GITHUB_ENV"

      # -----------------------------------------------------------------------
      # Run unit tests via `make test`
      # -----------------------------------------------------------------------
      - name: "Run Python unit tests (make test)"
        if: steps.pr.outputs.is_empty_shard != 'true'
        working-directory: ${{ env.WORKING_DIRECTORY }}
        run: |
          set -euo pipefail

          echo "üß™ [TEST] Language     : ${LANGUAGE}"
          echo "üß™ [TEST] Runtime      : Python ${PYTHON_VERSION}"
          echo "üß™ [TEST] Directory    : ${PWD}"
          echo "üß™ [TEST] Command      : make test"
          echo "üß™ [TEST] Shard        : ${UNIT_SHARD}/${UNIT_SHARD_TOTAL}"
          echo "üß™ [TEST] Status       : STARTING"

          START_TS=$(date +%s)

          export UNIT_SHARD="${UNIT_SHARD}"
          export UNIT_SHARD_TOTAL="${UNIT_SHARD_TOTAL}"
          export TEST_ITEMS_FILE="${{ steps.pr.outputs.selection_path }}"
          make test

          END_TS=$(date +%s)
          DURATION=$((END_TS - START_TS))

          echo "‚úÖ [TEST] Status       : COMPLETED"
          echo "‚è±  [TEST] Duration    : ${DURATION} seconds"
          echo "‚ÑπÔ∏è  [TEST] See pytest summary above for test counts."

      - name: Empty shard (skip)
        if: steps.pr.outputs.is_empty_shard == 'true'
        run: echo "‚ÑπÔ∏è Empty shard ‚Äî nothing to run."

      - name: "Detect coverage outputs (this shard)"
        id: cov
        working-directory: ${{ env.WORKING_DIRECTORY }}
        run: |
          set -euo pipefail
          has_xml="false"
          has_json="false"

          if [ -f "coverage.xml" ]; then has_xml="true"; fi
          if [ -f "out/coverage.json" ]; then has_json="true"; fi

          echo "has_xml=${has_xml}"  >> "$GITHUB_OUTPUT"
          echo "has_json=${has_json}" >> "$GITHUB_OUTPUT"

          echo "üîé has_xml=${has_xml} has_json=${has_json}"

      # -----------------------------------------------------------------------
      # Coverage normalization
      # -----------------------------------------------------------------------
      - name: "Normalize coverage ‚Üí coverage.json"
        if: ${{ steps.cov.outputs.has_xml == 'true' || steps.cov.outputs.has_json == 'true' }}
        uses: BrikByte-Studios/.github/.github/actions/coverage-merge@main
        with:
          language: ${{ env.LANGUAGE }}
          working-directory: ${{ env.WORKING_DIRECTORY }}
          out: out/coverage.json

      - name: "Ensure summary.line is set in coverage.json (Python)"
        if: ${{ steps.cov.outputs.has_xml == 'true' }}
        working-directory: ${{ env.WORKING_DIRECTORY }}
        run: |
          set -euo pipefail
          echo "üîß Normalizing coverage: syncing summary.line from coverage.xml"

          if [ ! -f "coverage.xml" ]; then
            echo "‚ùå coverage.xml not found ‚Äì did pytest run with --cov-report=xml:coverage.xml?"
            ls -R
            exit 1
          fi

          python - << 'EOF'
          import json
          import xml.etree.ElementTree as ET
          from pathlib import Path

          xml_path = Path("coverage.xml")
          tree = ET.parse(xml_path)
          root = tree.getroot()

          line_rate_attr = root.get("line-rate", "0")
          try:
            line_rate = float(line_rate_attr) * 100.0
          except ValueError:
            raise SystemExit(f"Invalid line-rate in coverage.xml: {line_rate_attr!r}")

          out_dir = Path("out")
          out_dir.mkdir(parents=True, exist_ok=True)
          cov_path = out_dir / "coverage.json"

          try:
            cov = json.loads(cov_path.read_text(encoding="utf-8"))
          except FileNotFoundError:
            cov = {}

          cov.setdefault("summary", {})
          cov["summary"]["line"] = line_rate
          cov.setdefault("files", [])

          cov_path.write_text(json.dumps(cov, indent=2), encoding="utf-8")
          print(f"‚úÖ Updated out/coverage.json with summary.line = {line_rate:.1f}")
          EOF

          echo "‚úÖ coverage.json after normalization:"
          cat out/coverage.json

      - name: "Upload Python coverage artifacts"
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: coverage-${{ env.LANGUAGE }}-shard${{ matrix.shard }}-${{ github.run_id }}
          path: |
            ${{ env.WORKING_DIRECTORY }}/out/coverage.json
            ${{ env.WORKING_DIRECTORY }}/coverage.xml
            ${{ env.WORKING_DIRECTORY }}/out/junit.xml
          if-no-files-found: ignore
          include-hidden-files: true
          retention-days: 14
