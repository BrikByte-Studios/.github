# =============================================================================
# BrikByteOS â€” Reusable Go Unit Test Workflow (with governed sharding)
# -----------------------------------------------------------------------------
# WBS ID : PIPE-TEST-UNIT-CI-BUILD-002
#
# Key fixes for â€œ0.0% flaky gateâ€ + merge-hurdles:
#   1) DO NOT use parallel-runner for Go selection (it emits *.go files)
#      â†’ Go sharding is package-based (go list ./... + deterministic split)
#   2) Treat coverage.out header-only (mode: atomic) as EMPTY coverage
#      â†’ skip normalization + skip upload (prevents poison merges)
#   3) Coverage artifacts upload ONLY when out/coverage.json exists AND is real
#   4) Always upload flaky-go-shard* and (when enabled) junit-go-shard* + flaky-audit-go-shard*
#      â†’ merge job patterns wonâ€™t miss evidence (avoids â€œNo summary.normalized.json foundâ€)
#
# PIPE-FLAKY-POLICY-CONFIG-002 wiring:
#   - Select policy (repo override -> central fallback)
#   - Normalize flaky summary to evaluator contract
#   - Evaluate using normalized summary
#   - Export analytics
#
# Contract:
#   - Makefile exposes: make test (or make test-unit)
#   - Makefile should support (recommended):
#       - UNIT_SHARD, UNIT_SHARD_TOTAL (1-based)
#       - GO_TEST_PKGS_FILE (newline list of packages for this shard)
#   - Makefile should write (recommended):
#       - out/junit.xml
#       - coverage.out (coverprofile) ONLY when tests ran (or allow header-only; we guard it)
# =============================================================================
name: "BrikByteOS â€” Go Unit Tests"

on:
  workflow_call:
    inputs:
      go-version:
        description: "Go version (must align with runtime matrix, e.g. 1.22.x)"
        required: false
        type: string
        default: "1.22.x"

      working-directory:
        description: "Path to Go module root (Makefile + go.mod)"
        required: false
        type: string
        default: "."

      # ------------------------------
      # Governed parallelism (optional)
      # ------------------------------
      override_shards:
        description: "Optional requested shard count (clamped to caps)."
        required: false
        type: string
        default: ""

      matrix_config_path:
        description: >
          Optional path to parallel-matrix.yml.
          Leave empty to use default inside BrikByte-Studios/.github.
        required: false
        type: string
        default: ""

      parallel_mode:
        description: "Parallel mode: static|dynamic (default static)"
        required: false
        type: string
        default: "static"

      parallel_enabled:
        description: "Enable parallel shard execution (true|false)"
        required: false
        type: string
        default: "true"

      # -----------------------------------------------------------------------
      # Flaky detection (PIPE-FLAKY-RERUN-INTEG-001)
      # -----------------------------------------------------------------------
      flaky_detect:
        description: "Enable suite-level flaky detection reruns (true|false)"
        required: false
        type: string
        default: "false"

      flaky_reruns:
        description: "Total attempts when flaky_detect=true (e.g., 3)"
        required: false
        type: string
        default: "3"

      flaky_export_path:
        description: "Relative path (from working-directory) to store flaky evidence"
        required: false
        type: string
        default: "out/flaky"

      # -----------------------------------------------------------------------
      # Flaky policy evaluation (PIPE-FLAKY-POLICY-CONFIG-002)
      # -----------------------------------------------------------------------
      flaky_policy_path:
        description: >
          Path to policy-as-code YAML (repo root) IF repo overrides exist.
          NOTE: If missing, central policy from BrikByte-Studios/.github is used.
        required: false
        type: string
        default: ".governance/flaky-tests.yml"

      flaky_policy_enforce:
        description: >
          If true, evaluator may block ONLY if policy enables blocking.
          If false, evaluator still runs (when flaky_detect=true) but never blocks.
        required: false
        type: boolean
        default: true

permissions:
  contents: read

jobs:
  # ---------------------------------------------------------------------------
  # 0) Plan matrix (separate job to use outputs in strategy.matrix)
  # ---------------------------------------------------------------------------
  plan:
    name: "Plan matrix (go unit)"
    runs-on: ubuntu-latest
    outputs:
      matrix: ${{ steps.plan.outputs.matrix_json }}
    steps:
      - name: "Checkout repository"
        uses: actions/checkout@v4

      - name: "Compute matrix plan (unit)"
        id: plan
        uses: BrikByte-Studios/.github/.github/actions/matrix-plan@main
        with:
          test_type: "unit"
          config_path: ${{ inputs.matrix_config_path }}
          override_shards: ${{ inputs.override_shards }}

  # ---------------------------------------------------------------------------
  # 1) Execute tests (sharded)
  # ---------------------------------------------------------------------------
  test:
    name: "Go: Unit Tests â€¢ shard ${{ matrix.shard }}"
    runs-on: ubuntu-latest
    needs: plan

    strategy:
      fail-fast: false
      matrix: ${{ fromJson(needs.plan.outputs.matrix) }}

    env:
      LANGUAGE: go
      GO_VERSION: ${{ inputs.go-version != '' && inputs.go-version || '1.22.x' }}
      WORKING_DIRECTORY: ${{ inputs.working-directory != '' && inputs.working-directory || '.' }}
      GOFLAGS: "-mod=readonly"

      # shard metadata (0-based)
      SHARD_INDEX: ${{ matrix.shard }}
      SHARD_TOTAL: ${{ strategy.job-total }}

      PARALLEL_MODE: ${{ inputs.parallel_mode }}
      PARALLEL: ${{ inputs.parallel_enabled }}

      # Flaky detection contract
      FLAKY_DETECT: ${{ inputs.flaky_detect }}
      FLAKY_RERUNS: ${{ inputs.flaky_reruns }}
      FLAKY_EXPORT_PATH: ${{ inputs.flaky_export_path }}

      # Flaky policy (PIPE-FLAKY-POLICY-CONFIG-002)
      FLAKY_POLICY_PATH: ${{ inputs.flaky_policy_path }}
      FLAKY_POLICY_ENFORCE: ${{ inputs.flaky_policy_enforce }}

      FORCE_COLOR: "0"

    steps:
      - name: "Checkout repository"
        uses: actions/checkout@v4

      - name: "Verify Go test layout"
        run: |
          set -euo pipefail
          echo "ðŸ“ Working directory: ${WORKING_DIRECTORY}"

          if [ ! -d "${WORKING_DIRECTORY}" ]; then
            echo "âŒ WORKING_DIRECTORY '${WORKING_DIRECTORY}' does not exist."
            exit 1
          fi

          if [ ! -f "${WORKING_DIRECTORY}/go.mod" ]; then
            echo "âŒ go.mod not found in ${WORKING_DIRECTORY}."
            exit 1
          fi

          if [ ! -f "${WORKING_DIRECTORY}/Makefile" ]; then
            echo "âŒ Makefile not found in ${WORKING_DIRECTORY}."
            echo "   Expected 'make test' (or equivalent)."
            exit 1
          fi

      - name: "Setup Go"
        uses: actions/setup-go@v5
        with:
          go-version: ${{ env.GO_VERSION }}

      - name: "Cache Go modules & build cache"
        uses: BrikByte-Studios/.github/.github/actions/cache-go-deps@main
        with:
          go-version: ${{ env.GO_VERSION }}
          project-path: ${{ env.WORKING_DIRECTORY }}

      # -------------------------------------------------------------------
      # Install go-junit-report so Makefile can safely emit out/junit.xml
      # -------------------------------------------------------------------
      - name: "Install go-junit-report"
        working-directory: ${{ env.WORKING_DIRECTORY }}
        run: |
          set -euo pipefail
          echo "ðŸ“¦ Installing go-junit-report..."
          go install github.com/jstemmer/go-junit-report/v2@latest
          GOPATH="$(go env GOPATH)"
          echo "${GOPATH}/bin" >> "$GITHUB_PATH"
          echo "âœ… go-junit-report installed and added to PATH"

      - name: "Compute shard env (1-based for Makefile)"
        shell: bash
        run: |
          set -euo pipefail
          SHARD0="${SHARD_INDEX}"
          TOTAL="${SHARD_TOTAL}"
          SHARD1=$((SHARD0 + 1))

          {
            echo "UNIT_SHARD=${SHARD1}"
            echo "UNIT_SHARD_TOTAL=${TOTAL}"
          } >> "$GITHUB_ENV"

          echo "[SHARD] 0-based=${SHARD0} -> 1-based=${SHARD1} / total=${TOTAL}"

      # -----------------------------------------------------------------------
      # Go package-based shard selection (DON'T use parallel-runner)
      # -----------------------------------------------------------------------
      - name: "Compute package list for this shard (deterministic)"
        id: pkgs
        working-directory: ${{ env.WORKING_DIRECTORY }}
        run: |
          set -euo pipefail

          mkdir -p out
          PKG_ALL="out/all-packages.txt"
          PKG_SHARD="out/shard-packages.txt"

          # List packages deterministically; filter out vendor; stable sort.
          go list ./... \
            | grep -vE '(^|/)vendor($|/)' \
            | sort \
            > "${PKG_ALL}"

          TOTAL_PKGS="$(wc -l < "${PKG_ALL}" | tr -d ' ')"
          echo "ðŸ“¦ Total packages: ${TOTAL_PKGS}"

          if [ "${TOTAL_PKGS}" -eq 0 ]; then
            echo "â„¹ï¸ No packages found. Marking shard empty."
            echo "is_empty_shard=true" >> "$GITHUB_OUTPUT"
            echo "pkgs_file=${PKG_SHARD}" >> "$GITHUB_OUTPUT"
            : > "${PKG_SHARD}"
            exit 0
          fi

          # Split by modulo: (line_index % SHARD_TOTAL) == SHARD_INDEX
          awk \
            -v idx="${SHARD_INDEX}" \
            -v tot="${SHARD_TOTAL}" \
            'NR>0 { if ((NR-1) % tot == idx) print }' \
            "${PKG_ALL}" \
            > "${PKG_SHARD}"

          SHARD_COUNT="$(wc -l < "${PKG_SHARD}" | tr -d ' ')"
          echo "ðŸ“¦ Packages in shard ${SHARD_INDEX}/${SHARD_TOTAL}: ${SHARD_COUNT}"

          if [ "${SHARD_COUNT}" -eq 0 ]; then
            echo "is_empty_shard=true" >> "$GITHUB_OUTPUT"
          else
            echo "is_empty_shard=false" >> "$GITHUB_OUTPUT"
          fi

          echo "pkgs_file=${PKG_SHARD}" >> "$GITHUB_OUTPUT"

          # Expose to Makefile as a contract (optional)
          {
            echo "GO_TEST_PKGS_FILE=${PWD}/${PKG_SHARD}"
          } >> "$GITHUB_ENV"

          echo "âœ… Wrote package list to ${PKG_SHARD}"
          head -n 20 "${PKG_SHARD}" || true

      # -----------------------------------------------------------------------
      # Shared scripts (flaky-rerun.sh + evaluator + central policy)
      # -----------------------------------------------------------------------
      - name: "Checkout BrikByte shared scripts"
        uses: actions/checkout@v4
        with:
          repository: BrikByte-Studios/.github
          ref: main
          path: .brikbyte-github

      # -----------------------------------------------------------------------
      # Run tests
      # NOTE:
      #   - We DO NOT use TEST_ITEMS_FILE for Go; we use GO_TEST_PKGS_FILE.
      #   - If your Makefile doesn't support GO_TEST_PKGS_FILE yet, it can ignore it
      #     and just use UNIT_SHARD/UNIT_SHARD_TOTAL.
      # -----------------------------------------------------------------------
      - name: "Run Go unit tests (make test) with flaky reruns (opt-in)"
        if: steps.pkgs.outputs.is_empty_shard != 'true'
        working-directory: ${{ env.WORKING_DIRECTORY }}
        run: |
          set -euo pipefail

          echo "ðŸ§ª [TEST] Language      : ${LANGUAGE}"
          echo "ðŸ§ª [TEST] Runtime       : Go ${GO_VERSION}"
          echo "ðŸ§ª [TEST] Directory     : ${PWD}"
          echo "ðŸ§ª [TEST] Command       : make test"
          echo "ðŸ§ª [TEST] Shard (1-based): ${UNIT_SHARD}/${UNIT_SHARD_TOTAL}"
          echo "ðŸ§ª [TEST] Shard (0-based): ${SHARD_INDEX}/${SHARD_TOTAL}"
          echo "ðŸ§ª [TEST] Pkgs file     : ${GO_TEST_PKGS_FILE}"
          echo "ðŸ§ª [TEST] FlakyDetect   : ${FLAKY_DETECT:-false}"
          echo "ðŸ§ª [TEST] FlakyReruns   : ${FLAKY_RERUNS:-3}"
          echo "ðŸ§ª [TEST] FlakyExport   : ${FLAKY_EXPORT_PATH:-out/flaky}"
          echo "ðŸ§ª [TEST] Status        : STARTING"

          export UNIT_SHARD="${UNIT_SHARD:-$((SHARD_INDEX + 1))}"
          export UNIT_SHARD_TOTAL="${UNIT_SHARD_TOTAL:-$SHARD_TOTAL}"
          export GO_TEST_PKGS_FILE="${GO_TEST_PKGS_FILE}"

          # Flaky wrapper config (used by flaky-rerun.sh)
          export FLAKY_DETECT="${FLAKY_DETECT:-false}"
          export FLAKY_RERUNS="${FLAKY_RERUNS:-3}"
          export FLAKY_EXPORT_PATH="${PWD}/${FLAKY_EXPORT_PATH:-out/flaky}"
          export FLAKY_LABEL="go-unit"

          BRIK_SCRIPTS="${GITHUB_WORKSPACE}/.brikbyte-github/.github/scripts"
          FLAKY_SH="${BRIK_SCRIPTS}/flaky-rerun.sh"

          if [[ ! -f "${FLAKY_SH}" ]]; then
            echo "âŒ flaky-rerun.sh not found at: ${FLAKY_SH}"
            echo "ðŸ“ Available scripts:"
            ls -la "${BRIK_SCRIPTS}" || true
            exit 1
          fi
          chmod +x "${FLAKY_SH}"

          "${FLAKY_SH}" -- make test

          echo "âœ… [TEST] Status        : COMPLETED"

      - name: "Empty shard (skip)"
        if: steps.pkgs.outputs.is_empty_shard == 'true'
        run: echo "â„¹ï¸ Empty shard â€” no packages to test."

      # =============================================================================
      # PIPE-FLAKY-POLICY-CONFIG-002 â€” Evaluate evidence against policy-as-code
      # =============================================================================
      - name: "Setup Node (for flaky policy evaluator)"
        if: ${{ always() && env.FLAKY_DETECT == 'true' }}
        uses: actions/setup-node@v4
        with:
          node-version: "20"

      - name: "Select policy source (repo override -> central fallback)"
        if: ${{ always() && env.FLAKY_DETECT == 'true' }}
        working-directory: ${{ github.workspace }}
        run: |
          set -euo pipefail
          mkdir -p .tmp-flaky-eval

          REPO_POLICY="${GITHUB_WORKSPACE}/${FLAKY_POLICY_PATH}"
          CENTRAL_POLICY="${GITHUB_WORKSPACE}/.brikbyte-github/.governance/flaky-tests.yml"
          OUT_POLICY="${GITHUB_WORKSPACE}/.tmp-flaky-eval/policy.yml"

          echo "ðŸ§© [FLAKY] Repo policy     : ${REPO_POLICY}"
          echo "ðŸ›ï¸ [FLAKY] Central policy  : ${CENTRAL_POLICY}"
          echo "ðŸ“Œ [FLAKY] Selected policy : ${OUT_POLICY}"

          if [[ -f "${REPO_POLICY}" ]]; then
            echo "âœ… [FLAKY] Using repo override policy."
            cp "${REPO_POLICY}" "${OUT_POLICY}"
          else
            if [[ ! -f "${CENTRAL_POLICY}" ]]; then
              echo "âŒ [FLAKY] Central policy missing at: ${CENTRAL_POLICY}"
              exit 1
            fi
            echo "âœ… [FLAKY] Repo policy not found; using central policy."
            cp "${CENTRAL_POLICY}" "${OUT_POLICY}"
          fi

      - name: "Install evaluator deps (repo-root, pinned) [js-yaml + tsx]"
        if: ${{ always() && env.FLAKY_DETECT == 'true' }}
        working-directory: ${{ github.workspace }}
        env:
          NPM_CONFIG_FUND: "false"
          NPM_CONFIG_AUDIT: "false"
        run: |
          set -euo pipefail
          node -v
          npm -v

          if [[ ! -f package.json ]]; then
            npm init -y >/dev/null 2>&1
          fi

          npm i --no-save js-yaml@4 tsx@4 >/dev/null 2>&1
          echo "âœ… deps installed into repo-root node_modules"

      - name: "Normalize flaky evidence â†’ summary.normalized.json"
        if: ${{ always() && env.FLAKY_DETECT == 'true' }}
        working-directory: ${{ env.WORKING_DIRECTORY }}
        run: |
          set -euo pipefail

          EXPORT_DIR="${PWD}/${FLAKY_EXPORT_PATH}"
          EXPECTED="${EXPORT_DIR}/summary.json"
          LABELED="${EXPORT_DIR}/${FLAKY_LABEL:-go-unit}.summary.json"

          EVIDENCE=""
          if [[ -f "${EXPECTED}" ]]; then
            EVIDENCE="${EXPECTED}"
          elif [[ -f "${LABELED}" ]]; then
            EVIDENCE="${LABELED}"
          else
            found="$(ls -1 "${EXPORT_DIR}"/*.summary.json 2>/dev/null | head -n 1 || true)"
            if [[ -n "${found}" ]]; then EVIDENCE="${found}"; fi
          fi

          if [[ -z "${EVIDENCE}" ]]; then
            echo "â„¹ï¸ [FLAKY] No evidence found â†’ skipping normalization."
            ls -la "${EXPORT_DIR}" || true
            exit 0
          fi

          OUT_NORM="${EXPORT_DIR}/summary.normalized.json"
          echo "ðŸ”§ [FLAKY] Normalizing: ${EVIDENCE} -> ${OUT_NORM}"

          EVIDENCE="${EVIDENCE}" OUT_NORM="${OUT_NORM}" python - <<'PY'
          import json
          from pathlib import Path
          import os

          evidence = Path(os.environ["EVIDENCE"])
          out_norm = Path(os.environ["OUT_NORM"])
          data = json.loads(evidence.read_text(encoding="utf-8"))

          attempts = data.get("attempts") if isinstance(data, dict) else None
          pass_count = 0
          fail_count = 0
          total_attempts = 0

          if isinstance(attempts, list) and attempts:
            total_attempts = len(attempts)
            for a in attempts:
              s = (a.get("status") or "").strip().lower()
              if not s:
                rc = int(a.get("exit_code", 0) or 0)
                s = "pass" if rc == 0 else "fail"
                a["status"] = s
              if s in ("pass", "passed", "ok", "success"):
                pass_count += 1
              elif s in ("fail", "failed", "error"):
                fail_count += 1
          else:
            pass_count = int(data.get("pass_count", 0) or 0) if isinstance(data, dict) else 0
            fail_count = int(data.get("fail_count", 0) or 0) if isinstance(data, dict) else 0
            total_attempts = pass_count + fail_count

          if isinstance(data, dict):
            data["pass_count"] = pass_count
            data["fail_count"] = fail_count
            data["total_attempts"] = total_attempts
            data["attempts"] = attempts if isinstance(attempts, list) else data.get("attempts", [])

          out_norm.parent.mkdir(parents=True, exist_ok=True)
          out_norm.write_text(json.dumps(data, indent=2), encoding="utf-8")
          print(f"âœ… wrote {out_norm} (pass={pass_count}, fail={fail_count}, total={total_attempts})")
          PY

      - name: "Evaluate flaky policy (use normalized summary)"
        if: ${{ always() && env.FLAKY_DETECT == 'true' }}
        working-directory: ${{ env.WORKING_DIRECTORY }}
        run: |
          set -euo pipefail

          POLICY="${GITHUB_WORKSPACE}/.tmp-flaky-eval/policy.yml"
          EXPORT_DIR="${PWD}/${FLAKY_EXPORT_PATH}"
          IN_NORM="${EXPORT_DIR}/summary.normalized.json"
          OUT_JSON="${EXPORT_DIR}/evaluation.json"

          echo "ðŸ§© [FLAKY] Policy     : ${POLICY}"
          echo "ðŸ“ [FLAKY] Export dir : ${EXPORT_DIR}"
          echo "ðŸ“¥ [FLAKY] Normalized : ${IN_NORM}"
          echo "ðŸ“¤ [FLAKY] Output     : ${OUT_JSON}"
          echo "ðŸ›¡ï¸ [FLAKY] Enforce    : ${FLAKY_POLICY_ENFORCE}"

          if [[ ! -f "${IN_NORM}" ]]; then
            echo "â„¹ï¸ [FLAKY] Normalized summary missing â†’ skipping evaluation (non-blocking)."
            exit 0
          fi

          EVAL_TS="${GITHUB_WORKSPACE}/.brikbyte-github/.github/scripts/evaluate-flaky.ts"
          if [[ ! -f "${EVAL_TS}" ]]; then
            echo "âŒ [FLAKY] evaluate-flaky.ts not found at: ${EVAL_TS}"
            exit 1
          fi

          pushd "${GITHUB_WORKSPACE}" >/dev/null
          npx tsx "${EVAL_TS}" \
            --policy "${POLICY}" \
            --input "${IN_NORM}" \
            --out "${OUT_JSON}" \
            --md || rc=$?
          popd >/dev/null

          if [[ "${rc:-0}" != "0" && "${FLAKY_POLICY_ENFORCE}" != "true" ]]; then
            echo "âš ï¸ [FLAKY] Evaluator exit=${rc} but enforce=false â†’ not blocking."
            exit 0
          fi
          exit "${rc:-0}"

      - name: "Export flaky analytics (when enabled)"
        if: ${{ always() && env.FLAKY_DETECT == 'true' }}
        working-directory: ${{ env.WORKING_DIRECTORY }}
        run: |
          set -euo pipefail
          BRIK_SCRIPTS="${GITHUB_WORKSPACE}/.brikbyte-github/.github/scripts"
          FLAKY_JS="${BRIK_SCRIPTS}/export-flaky-analytics.mjs"

          if [[ ! -f "${FLAKY_JS}" ]]; then
            echo "âŒ export-flaky-analytics.mjs not found at: ${FLAKY_JS}"
            ls -la "${BRIK_SCRIPTS}" || true
            exit 1
          fi

          chmod +x "${FLAKY_JS}"
          node "${FLAKY_JS}" \
            --suite go-unit \
            --audit-root "${GITHUB_WORKSPACE}/.audit" \
            --out-dir "${FLAKY_EXPORT_PATH:-out/flaky}" \
            --top-n 10 \
            --write-md true \
            --allow-missing-evaluation true

      - name: "Upload flaky audit ledger (.audit) â€” shard"
        if: ${{ always() && env.FLAKY_DETECT == 'true' }}
        uses: actions/upload-artifact@v4
        with:
          name: flaky-audit-${{ env.LANGUAGE }}-shard${{ matrix.shard }}
          path: |
            .audit/**/flaky/*.json
          if-no-files-found: warn
          include-hidden-files: true
          retention-days: 14

      - name: "Upload JUnit (for flaky report) â€” shard"
        if: ${{ always() && env.FLAKY_DETECT == 'true' }}
        uses: actions/upload-artifact@v4
        with:
          name: junit-${{ env.LANGUAGE }}-shard${{ matrix.shard }}
          path: |
            ${{ env.WORKING_DIRECTORY }}/out/junit.xml
          if-no-files-found: warn
          retention-days: 14

      - name: "Upload flaky evaluation (always)"
        if: ${{ always() && env.FLAKY_DETECT == 'true' }}
        uses: actions/upload-artifact@v4
        with:
          name: flaky-eval-${{ env.LANGUAGE }}-shard${{ matrix.shard }}
          path: |
            ${{ env.WORKING_DIRECTORY }}/${{ inputs.flaky_export_path }}/
          if-no-files-found: warn
          include-hidden-files: true
          retention-days: 14

      # -----------------------------------------------------------------------
      # Coverage sanity: header-only coverage.out is EMPTY â†’ skip upload/merge
      # -----------------------------------------------------------------------
      - name: "Detect real coverage.out (non-header)"
        id: cov
        working-directory: ${{ env.WORKING_DIRECTORY }}
        run: |
          set -euo pipefail

          if [ ! -f "coverage.out" ]; then
            echo "has_real_covout=false" >> "$GITHUB_OUTPUT"
            echo "â„¹ï¸ No coverage.out found."
            exit 0
          fi

          NONEMPTY="$(grep -cve '^[[:space:]]*$' coverage.out || true)"
          echo "nonempty_lines=${NONEMPTY}" >> "$GITHUB_OUTPUT"
          echo "ðŸ”Ž coverage.out non-empty line count: ${NONEMPTY}"
          head -n 5 coverage.out || true

          if [ "${NONEMPTY}" -le 1 ]; then
            echo "has_real_covout=false" >> "$GITHUB_OUTPUT"
            echo "âš ï¸ coverage.out is header-only (empty shard coverage). Skipping normalization/upload."
          else
            echo "has_real_covout=true" >> "$GITHUB_OUTPUT"
            echo "âœ… coverage.out looks real."
          fi

      - name: "Normalize coverage â†’ out/coverage.json"
        if: steps.cov.outputs.has_real_covout == 'true'
        uses: BrikByte-Studios/.github/.github/actions/coverage-merge@main
        with:
          language: ${{ env.LANGUAGE }}
          working-directory: ${{ env.WORKING_DIRECTORY }}
          out: out/coverage.json

      - name: "Ensure summary.line is set in out/coverage.json (Go)"
        if: steps.cov.outputs.has_real_covout == 'true'
        working-directory: ${{ env.WORKING_DIRECTORY }}
        run: |
          set -euo pipefail

          go tool cover -func=coverage.out > coverage-func.txt
          tail -n 5 coverage-func.txt || true

          python - <<'PY'
          import json
          from pathlib import Path

          lines = Path("coverage-func.txt").read_text(encoding="utf-8").strip().splitlines()
          last = lines[-1] if lines else ""
          pct = float(last.split()[-1].rstrip("%"))

          out = Path("out")
          out.mkdir(parents=True, exist_ok=True)
          cov_path = out / "coverage.json"

          cov = json.loads(cov_path.read_text(encoding="utf-8")) if cov_path.exists() else {}
          cov.setdefault("summary", {})
          cov["summary"]["line"] = pct
          cov.setdefault("files", [])

          cov_path.write_text(json.dumps(cov, indent=2), encoding="utf-8")
          print(f"âœ… summary.line set to {pct:.1f}")
          PY

      - name: "Detect out/coverage.json presence"
        id: covjson
        working-directory: ${{ env.WORKING_DIRECTORY }}
        run: |
          set -euo pipefail
          if [ -f "out/coverage.json" ]; then
            echo "has_covjson=true" >> "$GITHUB_OUTPUT"
          else
            echo "has_covjson=false" >> "$GITHUB_OUTPUT"
          fi

      - name: "Upload Go coverage artifacts (ONLY when real coverage.json exists)"
        if: steps.covjson.outputs.has_covjson == 'true'
        uses: actions/upload-artifact@v4
        with:
          name: coverage-go-shard${{ matrix.shard }}
          path: |
            ${{ env.WORKING_DIRECTORY }}/out/coverage.json
            ${{ env.WORKING_DIRECTORY }}/coverage.out
            ${{ env.WORKING_DIRECTORY }}/coverage-func.txt
            ${{ env.WORKING_DIRECTORY }}/out/junit.xml
            ${{ env.WORKING_DIRECTORY }}/out/test-unit-report.json
            ${{ env.WORKING_DIRECTORY }}/out/shard-packages.txt
          if-no-files-found: error
          include-hidden-files: true
          retention-days: 14

      # -----------------------------------------------------------------------
      # Upload flaky evidence (always) â€” critical for merge job patterns
      # -----------------------------------------------------------------------
      - name: "Upload flaky evidence (always)"
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: flaky-go-shard${{ matrix.shard }}
          path: |
            ${{ env.WORKING_DIRECTORY }}/${{ inputs.flaky_export_path }}/
          if-no-files-found: ignore
          include-hidden-files: true
          retention-days: 14
