# =============================================================================
# BrikByteOS ‚Äî Reusable .NET Unit Test Workflow (with governed sharding)
# -----------------------------------------------------------------------------
# PIPE-FLAKY-POLICY-CONFIG-002 wiring added:
#   - Select policy (repo override -> central fallback)
#   - Normalize flaky summary to satisfy evaluator contract
#   - Evaluate using normalized summary (prevents total_attempts=0 hurdle)
#   - Upload flaky-eval artifact per shard
#
# Extra hardening (avoid Python hurdles):
#   - Run evaluator from repo-root so Node deps resolve
#   - Install js-yaml + tsx locally (no reliance on repo‚Äôs node_modules)
# =============================================================================
name: "BrikByteOS ‚Äî .NET Unit Tests"

on:
  workflow_call:
    inputs:
      dotnet-version:
        description: ".NET SDK version (e.g. 8.0.x)"
        required: false
        type: string
        default: "8.0.x"

      working-directory:
        description: "Path to .NET solution root (Makefile + *.sln or *.csproj)"
        required: false
        type: string
        default: "."

      # ------------------------------
      # Governed parallelism (optional)
      # ------------------------------
      override_shards:
        description: "Optional requested shard count (clamped to caps)."
        required: false
        type: string
        default: ""

      matrix_config_path:
        description: >
          Optional path to parallel-matrix.yml.
          Leave empty to use default inside BrikByte-Studios/.github.
        required: false
        type: string
        default: ""

      parallel_mode:
        description: "Parallel mode: static|dynamic (default static)"
        required: false
        type: string
        default: "static"

      parallel_enabled:
        description: "Enable parallel shard execution (true|false)"
        required: false
        type: string
        default: "true"

      # -----------------------------------------------------------------------
      # Flaky detection (PIPE-FLAKY-RERUN-INTEG-001)
      # -----------------------------------------------------------------------
      flaky_detect:
        description: "Enable suite-level flaky detection reruns (true|false)"
        required: false
        type: string
        default: "false"

      flaky_reruns:
        description: "Total attempts when flaky_detect=true (e.g., 3)"
        required: false
        type: string
        default: "3"

      flaky_export_path:
        description: "Relative path (from working-directory) to store flaky evidence"
        required: false
        type: string
        default: "out/flaky"

      # -----------------------------------------------------------------------
      # Flaky policy evaluation (PIPE-FLAKY-POLICY-CONFIG-002)
      # -----------------------------------------------------------------------
      flaky_policy_path:
        description: >
          Path to policy-as-code YAML (repo root) IF repo overrides exist.
          NOTE: If missing, central policy from BrikByte-Studios/.github is used.
        required: false
        type: string
        default: ".governance/flaky-tests.yml"

      flaky_policy_enforce:
        description: >
          If true, evaluator may block ONLY if policy enables blocking.
          If false, evaluator still runs (when flaky_detect=true) but never blocks.
        required: false
        type: boolean
        default: true

permissions:
  contents: read

jobs:
  # ---------------------------------------------------------------------------
  # 0) PLAN: compute governed matrix JSON (job output)
  # ---------------------------------------------------------------------------
  plan:
    name: "Matrix Plan (.NET unit)"
    runs-on: ubuntu-latest
    outputs:
      matrix_json: ${{ steps.matrix.outputs.matrix_json }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: "Compute matrix plan (unit)"
        id: matrix
        uses: BrikByte-Studios/.github/.github/actions/matrix-plan@main
        with:
          test_type: "unit"
          config_path: ${{ inputs.matrix_config_path }}
          override_shards: ${{ inputs.override_shards }}

      - name: "Debug matrix_json"
        run: |
          echo "matrix_json=${{ steps.matrix.outputs.matrix_json }}"

  # ---------------------------------------------------------------------------
  # 1) TEST: run shards from matrix computed in plan job
  # ---------------------------------------------------------------------------
  test:
    name: ".NET: Unit Tests ‚Ä¢ shard ${{ matrix.shard }}"
    runs-on: ubuntu-latest
    needs: plan

    strategy:
      fail-fast: false
      matrix: ${{ fromJson(needs.plan.outputs.matrix_json) }}

    env:
      LANGUAGE: dotnet
      DOTNET_VERSION: ${{ inputs.dotnet-version != '' && inputs.dotnet-version || '8.0.x' }}
      WORKING_DIRECTORY: ${{ inputs.working-directory != '' && inputs.working-directory || '.' }}

      # shard metadata (deterministic) ‚Äî 0-based
      SHARD_INDEX: ${{ matrix.shard }}
      SHARD_TOTAL: ${{ strategy.job-total }}

      PARALLEL_MODE: ${{ inputs.parallel_mode }}
      PARALLEL: ${{ inputs.parallel_enabled }}

      # Flaky detection contract
      FLAKY_DETECT: ${{ inputs.flaky_detect }}
      FLAKY_RERUNS: ${{ inputs.flaky_reruns }}
      FLAKY_EXPORT_PATH: ${{ inputs.flaky_export_path }}

      # Flaky policy (PIPE-FLAKY-POLICY-CONFIG-002)
      FLAKY_POLICY_PATH: ${{ inputs.flaky_policy_path }}
      FLAKY_POLICY_ENFORCE: ${{ inputs.flaky_policy_enforce }}

      FORCE_COLOR: "0"

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Verify .NET test layout
        run: |
          set -euo pipefail
          echo "üìÅ Working directory: ${WORKING_DIRECTORY}"

          if [ ! -d "${WORKING_DIRECTORY}" ]; then
            echo "‚ùå WORKING_DIRECTORY '${WORKING_DIRECTORY}' does not exist."
            exit 1
          fi

          cd "${WORKING_DIRECTORY}"

          if [ ! -f "Makefile" ]; then
            echo "‚ùå Makefile not found in ${PWD}."
            echo "   Expected 'make test' mapping to 'dotnet test'."
            exit 1
          fi

          # Require either a solution or at least one csproj somewhere nearby
          if ! ls *.sln >/dev/null 2>&1; then
            if ! find . -maxdepth 6 -name "*.csproj" | head -n 1 | grep -q .; then
              echo "‚ùå No .sln in ${PWD} and no *.csproj found within maxdepth 6."
              exit 1
            fi
          fi

      - name: Setup .NET
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: ${{ env.DOTNET_VERSION }}

      - name: "Cache .NET dependencies & tools"
        uses: BrikByte-Studios/.github/.github/actions/cache-dotnet-deps@main
        with:
          dotnet-version: ${{ env.DOTNET_VERSION }}
          project-path: ${{ env.WORKING_DIRECTORY }}

      - name: Compute shard env (1-based for Makefile)
        shell: bash
        run: |
          set -euo pipefail

          SHARD0="${SHARD_INDEX}"
          TOTAL="${SHARD_TOTAL}"
          SHARD1=$((SHARD0 + 1))

          {
            echo "UNIT_SHARD=${SHARD1}"
            echo "UNIT_SHARD_TOTAL=${TOTAL}"
          } >> "$GITHUB_ENV"

          echo "[SHARD] 0-based=${SHARD0} -> 1-based=${SHARD1} / total=${TOTAL}"

      # -----------------------------------------------------------------------
      # Parallel runner ‚Äî produce deterministic per-shard selection file
      # -----------------------------------------------------------------------
      - name: Parallel runner (serial/static/dynamic)
        id: pr
        uses: BrikByte-Studios/.github/.github/actions/parallel-runner@main
        with:
          parallel_enabled: ${{ env.PARALLEL }}
          parallel_mode: ${{ env.PARALLEL_MODE }}

          # 0-based shard contract (matches matrix-plan)
          shard_index: ${{ matrix.shard }}
          shard_total: ${{ strategy.job-total }}

          selection_mode: "file-split"
          working_directory: ${{ env.WORKING_DIRECTORY }}

          # Prefer sharding by test projects; include sln as fallback
          test_glob: |
            **/*Tests.csproj
            **/*.Tests.csproj
            tests/**/*.csproj
            **/*.sln

          out_list: "${{ env.WORKING_DIRECTORY }}/out/shard-files.txt"
          allow_missing_items_file: true

      # -----------------------------------------------------------------------
      # Shared scripts (flaky-rerun.sh + evaluator + central policy)
      # -----------------------------------------------------------------------
      - name: Checkout BrikByte shared scripts
        uses: actions/checkout@v4
        with:
          repository: BrikByte-Studios/.github
          ref: main
          path: .brikbyte-github

      # -----------------------------------------------------------------------
      # Run unit tests via `make test` (wired through flaky-rerun.sh)
      # -----------------------------------------------------------------------
      - name: Run .NET unit tests (make test) with flaky reruns (opt-in)
        if: ${{ steps.pr.outputs.is_empty_shard != 'true' }}
        working-directory: ${{ env.WORKING_DIRECTORY }}
        run: |
          set -euo pipefail

          echo "üß™ [TEST] Language     : ${LANGUAGE}"
          echo "üß™ [TEST] Runtime      : .NET SDK ${DOTNET_VERSION}"
          echo "üß™ [TEST] Directory    : ${PWD}"
          echo "üß™ [TEST] Command      : make test"
          echo "üß™ [TEST] Shard        : ${SHARD_INDEX}/${SHARD_TOTAL}"
          echo "üß™ [TEST] Selection    : ${{ steps.pr.outputs.selection_path }}"
          echo "üß™ [TEST] FlakyDetect  : ${FLAKY_DETECT:-false}"
          echo "üß™ [TEST] FlakyReruns  : ${FLAKY_RERUNS:-3}"
          echo "üß™ [TEST] FlakyExport  : ${FLAKY_EXPORT_PATH:-out/flaky}"
          echo "üß™ [TEST] Status       : STARTING"

          START_TS=$(date +%s)

          # Provide selection/shard env to your Makefile if it supports them
          export TEST_ITEMS_FILE="${{ steps.pr.outputs.selection_path }}"
          export UNIT_SHARD="${UNIT_SHARD:-$((SHARD_INDEX + 1))}"
          export UNIT_SHARD_TOTAL="${UNIT_SHARD_TOTAL:-$SHARD_TOTAL}"

          # Flaky wrapper config (used by flaky-rerun.sh)
          export FLAKY_DETECT="${FLAKY_DETECT:-false}"
          export FLAKY_RERUNS="${FLAKY_RERUNS:-3}"
          export FLAKY_EXPORT_PATH="${PWD}/${FLAKY_EXPORT_PATH:-out/flaky}"
          export FLAKY_LABEL="dotnet-unit"

          BRIK_SCRIPTS="${GITHUB_WORKSPACE}/.brikbyte-github/.github/scripts"
          FLAKY_SH="${BRIK_SCRIPTS}/flaky-rerun.sh"

          if [[ ! -f "${FLAKY_SH}" ]]; then
            echo "‚ùå flaky-rerun.sh not found at: ${FLAKY_SH}"
            echo "üìÅ Available scripts:"
            ls -la "${BRIK_SCRIPTS}" || true
            exit 1
          fi
          chmod +x "${FLAKY_SH}"

          # Run through wrapper (opt-in via FLAKY_DETECT)
          "${FLAKY_SH}" -- make test

          END_TS=$(date +%s)
          DURATION=$((END_TS - START_TS))

          echo "‚úÖ [TEST] Status       : COMPLETED"
          echo "‚è±  [TEST] Duration     : ${DURATION} seconds"

      - name: Empty shard (nothing to run)
        if: ${{ steps.pr.outputs.is_empty_shard == 'true' }}
        working-directory: ${{ env.WORKING_DIRECTORY }}
        run: |
          set -euo pipefail
          echo "‚ÑπÔ∏è Empty shard; skipping tests."
          mkdir -p out
          : > out/junit.xml || true

      # =============================================================================
      # PIPE-FLAKY-POLICY-CONFIG-002 ‚Äî Evaluate evidence against policy-as-code
      # =============================================================================

      - name: "Select policy source (repo override -> central fallback)"
        if: ${{ always() && env.FLAKY_DETECT == 'true' }}
        working-directory: ${{ github.workspace }}
        run: |
          set -euo pipefail

          mkdir -p .tmp-flaky-eval

          REPO_POLICY="${GITHUB_WORKSPACE}/${FLAKY_POLICY_PATH}"
          CENTRAL_POLICY="${GITHUB_WORKSPACE}/.brikbyte-github/.governance/flaky-tests.yml"
          OUT_POLICY="${GITHUB_WORKSPACE}/.tmp-flaky-eval/policy.yml"

          echo "üß© [FLAKY] Repo policy     : ${REPO_POLICY}"
          echo "üèõÔ∏è [FLAKY] Central policy  : ${CENTRAL_POLICY}"
          echo "üìå [FLAKY] Selected policy : ${OUT_POLICY}"

          if [[ -f "${REPO_POLICY}" ]]; then
            echo "‚úÖ [FLAKY] Using repo override policy."
            cp "${REPO_POLICY}" "${OUT_POLICY}"
          else
            if [[ ! -f "${CENTRAL_POLICY}" ]]; then
              echo "‚ùå [FLAKY] Central policy missing at: ${CENTRAL_POLICY}"
              exit 1
            fi
            echo "‚úÖ [FLAKY] Repo policy not found; using central policy."
            cp "${CENTRAL_POLICY}" "${OUT_POLICY}"
          fi

      - name: "Install evaluator deps (repo-root) [js-yaml + tsx]"
        if: ${{ always() && env.FLAKY_DETECT == 'true' }}
        working-directory: ${{ github.workspace }}
        env:
          NPM_CONFIG_FUND: "false"
          NPM_CONFIG_AUDIT: "false"
        run: |
          set -euo pipefail
          node -v
          npm -v

          if [[ ! -f package.json ]]; then
            npm init -y >/dev/null 2>&1
          fi

          npm i --no-save js-yaml@4 tsx@4 >/dev/null 2>&1
          echo "‚úÖ deps installed into repo-root node_modules"

      - name: "Normalize flaky evidence ‚Üí summary.normalized.json"
        if: ${{ always() && env.FLAKY_DETECT == 'true' }}
        working-directory: ${{ env.WORKING_DIRECTORY }}
        run: |
          set -euo pipefail

          EXPORT_DIR="${PWD}/${FLAKY_EXPORT_PATH}"
          EXPECTED="${EXPORT_DIR}/summary.json"
          LABELED="${EXPORT_DIR}/${FLAKY_LABEL:-dotnet-unit}.summary.json"

          EVIDENCE=""
          if [[ -f "${EXPECTED}" ]]; then
            EVIDENCE="${EXPECTED}"
          elif [[ -f "${LABELED}" ]]; then
            EVIDENCE="${LABELED}"
          else
            found="$(ls -1 "${EXPORT_DIR}"/*.summary.json 2>/dev/null | head -n 1 || true)"
            if [[ -n "${found}" ]]; then EVIDENCE="${found}"; fi
          fi

          if [[ -z "${EVIDENCE}" ]]; then
            echo "‚ÑπÔ∏è [FLAKY] No evidence found ‚Üí skipping normalization."
            ls -la "${EXPORT_DIR}" || true
            exit 0
          fi

          OUT_NORM="${EXPORT_DIR}/summary.normalized.json"
          echo "üîß [FLAKY] Normalizing: ${EVIDENCE} -> ${OUT_NORM}"

          EVIDENCE="${EVIDENCE}" OUT_NORM="${OUT_NORM}" python - <<'PY'
          import json
          from pathlib import Path
          import os

          evidence = Path(os.environ["EVIDENCE"])
          out_norm = Path(os.environ["OUT_NORM"])

          data = json.loads(evidence.read_text(encoding="utf-8"))

          attempts = data.get("attempts") if isinstance(data, dict) else None
          pass_count = 0
          fail_count = 0
          total_attempts = 0

          if isinstance(attempts, list) and attempts:
            total_attempts = len(attempts)
            for a in attempts:
              s = (a.get("status") or "").strip().lower()
              if not s:
                rc = int(a.get("exit_code", 0) or 0)
                s = "pass" if rc == 0 else "fail"
                a["status"] = s
              if s in ("pass", "passed", "ok", "success"):
                pass_count += 1
              elif s in ("fail", "failed", "error"):
                fail_count += 1
          else:
            pass_count = int(data.get("pass_count", 0) or 0) if isinstance(data, dict) else 0
            fail_count = int(data.get("fail_count", 0) or 0) if isinstance(data, dict) else 0
            total_attempts = pass_count + fail_count

          if isinstance(data, dict):
            data["pass_count"] = pass_count
            data["fail_count"] = fail_count
            data["total_attempts"] = total_attempts
            data["attempts"] = attempts if isinstance(attempts, list) else data.get("attempts", [])

          out_norm.parent.mkdir(parents=True, exist_ok=True)
          out_norm.write_text(json.dumps(data, indent=2), encoding="utf-8")
          print(f"‚úÖ wrote {out_norm} (pass={pass_count}, fail={fail_count}, total={total_attempts})")
          PY

          echo "=== normalized summary ==="
          cat "${OUT_NORM}"

      - name: "Evaluate flaky policy (use normalized summary)"
        if: ${{ always() && env.FLAKY_DETECT == 'true' }}
        working-directory: ${{ env.WORKING_DIRECTORY }}
        run: |
          set -euo pipefail

          POLICY="${GITHUB_WORKSPACE}/.tmp-flaky-eval/policy.yml"
          EXPORT_DIR="${PWD}/${FLAKY_EXPORT_PATH}"
          IN_NORM="${EXPORT_DIR}/summary.normalized.json"
          OUT_JSON="${EXPORT_DIR}/evaluation.json"

          echo "üß© [FLAKY] Policy     : ${POLICY}"
          echo "üìÅ [FLAKY] Export dir : ${EXPORT_DIR}"
          echo "üì• [FLAKY] Normalized : ${IN_NORM}"
          echo "üì§ [FLAKY] Output     : ${OUT_JSON}"
          echo "üõ°Ô∏è [FLAKY] Enforce    : ${FLAKY_POLICY_ENFORCE}"

          if [[ ! -f "${POLICY}" ]]; then
            echo "‚ùå [FLAKY] Missing policy file: ${POLICY}"
            exit 1
          fi

          if [[ ! -f "${IN_NORM}" ]]; then
            echo "‚ÑπÔ∏è [FLAKY] Normalized summary missing ‚Üí skipping evaluation (non-blocking)."
            ls -la "${EXPORT_DIR}" || true
            exit 0
          fi

          EVAL_TS="${GITHUB_WORKSPACE}/.brikbyte-github/.github/scripts/evaluate-flaky.ts"
          if [[ ! -f "${EVAL_TS}" ]]; then
            echo "‚ùå [FLAKY] evaluate-flaky.ts not found at: ${EVAL_TS}"
            exit 1
          fi

          pushd "${GITHUB_WORKSPACE}" >/dev/null
          npx tsx "${EVAL_TS}" \
            --policy "${POLICY}" \
            --input "${IN_NORM}" \
            --out "${OUT_JSON}" \
            --md || rc=$?
          popd >/dev/null

          if [[ "${rc:-0}" != "0" && "${FLAKY_POLICY_ENFORCE}" != "true" ]]; then
            echo "‚ö†Ô∏è [FLAKY] Evaluator exit=${rc} but enforce=false ‚Üí not blocking."
            exit 0
          fi

          exit "${rc:-0}"

      - name: Export flaky analytics (when enabled)
        if: ${{ always() && env.FLAKY_DETECT == 'true' }}
        working-directory: ${{ env.WORKING_DIRECTORY }}
        run: |
          set -euo pipefail
          BRIK_SCRIPTS="${GITHUB_WORKSPACE}/.brikbyte-github/.github/scripts"
          FLAKY_SH="${BRIK_SCRIPTS}/export-flaky-analytics.mjs"

          if [[ ! -f "${FLAKY_SH}" ]]; then
            echo "‚ùå export-flaky-analytics.mjs not found at: ${FLAKY_SH}"
            echo "üìÅ Available scripts:"
            ls -la "${BRIK_SCRIPTS}" || true
            exit 1
          fi

          chmod +x "${FLAKY_SH}"
          node "${FLAKY_SH}" \
            --suite unit \
            --audit-root "${GITHUB_WORKSPACE}/.audit" \
            --out-dir "${FLAKY_EXPORT_PATH:-out/flaky}" \
            --top-n 10 \
            --write-md true \
            --allow-missing-evaluation true

      - name: "Upload flaky evaluation (always)"
        if: ${{ always() && env.FLAKY_DETECT == 'true' }}
        uses: actions/upload-artifact@v4
        with:
          name: flaky-eval-dotnet-shard${{ env.SHARD_INDEX }}
          path: |
            ${{ env.WORKING_DIRECTORY }}/${{ inputs.flaky_export_path }}/
          if-no-files-found: warn
          include-hidden-files: true
          retention-days: 14

      # -----------------------------------------------------------------------
      # Detect whether this shard produced Coverlet JSON
      # -----------------------------------------------------------------------
      - name: Detect Coverlet JSON presence
        id: covdetect
        working-directory: ${{ env.WORKING_DIRECTORY }}
        run: |
          set -euo pipefail

          FOUND="$(
            find . -type f \
              \( -name "coverage.net*.json" -o -name "coverage.json" -o -name "coverage.*.json" \) \
              | head -n 1 || true
          )"

          if [ -n "${FOUND}" ]; then
            echo "has_coverage=true" >> "$GITHUB_OUTPUT"
            echo "coverlet_json=${FOUND}" >> "$GITHUB_OUTPUT"
            echo "‚úÖ Found Coverlet JSON: ${FOUND}"
          else
            echo "has_coverage=false" >> "$GITHUB_OUTPUT"
            echo "‚ö†Ô∏è No Coverlet JSON found for this shard or coverage not enabled."
          fi

      # -----------------------------------------------------------------------
      # Normalize coverage to out/coverage.json (summary.line)
      # -----------------------------------------------------------------------
      - name: Ensure summary.line is set in out/coverage.json (.NET / Coverlet)
        if: steps.covdetect.outputs.has_coverage == 'true'
        working-directory: ${{ env.WORKING_DIRECTORY }}
        env:
          COVERLET_JSON: ${{ steps.covdetect.outputs.coverlet_json }}
        run: |
          set -euo pipefail
          echo "üîß Normalizing .NET coverage: syncing summary.line from Coverlet JSON"
          echo "‚ÑπÔ∏è Using Coverlet JSON: ${COVERLET_JSON}"

          python - <<'PY'
          import json, os
          from pathlib import Path

          coverlet_path = Path(os.environ["COVERLET_JSON"])
          data = json.loads(coverlet_path.read_text(encoding="utf-8"))

          def iter_lines_maps(obj):
            if isinstance(obj, dict):
              for k, v in obj.items():
                if k.lower() == "lines" and isinstance(v, dict):
                  yield v
                else:
                  yield from iter_lines_maps(v)
            elif isinstance(obj, list):
              for item in obj:
                yield from iter_lines_maps(item)

          total = 0
          covered = 0
          for lines_map in iter_lines_maps(data):
            for _, hits in lines_map.items():
              try:
                h = int(hits)
              except Exception:
                continue
              total += 1
              if h > 0:
                covered += 1

          if total <= 0:
            raise SystemExit("Cannot determine coverage: no line hit data found in Coverlet JSON.")

          pct = (covered / total) * 100.0

          out_dir = Path("out")
          out_dir.mkdir(parents=True, exist_ok=True)
          cov_path = out_dir / "coverage.json"

          cov = json.loads(cov_path.read_text(encoding="utf-8")) if cov_path.exists() else {}
          cov.setdefault("summary", {})
          cov["summary"]["line"] = float(pct)
          cov.setdefault("files", [])

          cov_path.write_text(json.dumps(cov, indent=2), encoding="utf-8")
          print(f"‚úÖ Updated out/coverage.json with summary.line = {pct:.2f} (covered={covered}, total={total})")
          PY

          echo "‚úÖ out/coverage.json:"
          cat out/coverage.json

      - name: Detect out/coverage.json presence
        id: covjson
        working-directory: ${{ env.WORKING_DIRECTORY }}
        run: |
          set -euo pipefail
          if [ -f "out/coverage.json" ]; then
            echo "has_covjson=true" >> "$GITHUB_OUTPUT"
          else
            echo "has_covjson=false" >> "$GITHUB_OUTPUT"
          fi

      # -----------------------------------------------------------------------
      # Upload artifacts
      # -----------------------------------------------------------------------
      - name: Upload .NET coverage artifacts (per shard)
        if: steps.covjson.outputs.has_covjson == 'true'
        uses: actions/upload-artifact@v4
        with:
          name: coverage-dotnet-shard${{ env.SHARD_INDEX }}
          path: |
            ${{ env.WORKING_DIRECTORY }}/out/coverage.json
            ${{ env.WORKING_DIRECTORY }}/out/junit.xml
            ${{ env.WORKING_DIRECTORY }}/tests/**/TestResults/**
            ${{ env.WORKING_DIRECTORY }}/TestResults/**
            ${{ env.WORKING_DIRECTORY }}/out/shard-files.txt
            ${{ env.WORKING_DIRECTORY }}/out/shard-packages.txt
          if-no-files-found: ignore
          include-hidden-files: true
          retention-days: 14

      - name: Upload flaky evidence (always)
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: flaky-dotnet-shard${{ env.SHARD_INDEX }}
          path: |
            ${{ env.WORKING_DIRECTORY }}/${{ inputs.flaky_export_path }}/
          if-no-files-found: ignore
          include-hidden-files: true
          retention-days: 14
