# File: .github/workflows/integration-test.yml
#
# BrikPipe â€” Containerized Integration Tests (Reusable Workflow)
# --------------------------------------------------------------
# Purpose:
#   Provide a reusable, container-based integration test job that:
#     - Builds or pulls the *real* service image under test.
#     - Orchestrates app + DB + optional cache/messaging containers.
#     - Runs language-specific integration tests from a dedicated runner.
#     - Uses explicit health checks (DB + app) to avoid flaky race conditions.
#     - Tears everything down deterministically in under 5 minutes.
#
# Usage from a service repo (e.g. brik-pipe-examples):
#
#   jobs:
#     integration:
#       uses: BrikByte-Studios/.github/.github/workflows/integration-test.yml@main
#       secrets: inherit
#       with:
#         image: ghcr.io/brikbyte-studios/node-api-example:sha-${{ github.sha }}
#         dockerfile: node-api-example/Dockerfile
#         context: node-api-example
#         db_image: postgres:16
#         cache_image: redis:7
#         enable_cache_service: true
#         test_language: "node"
#         # Optional override:
#         # test_command: "npm run test:integration"
#         healthcheck_path: "/health"
#         healthcheck_timeout: "60"
#         app_port: "3000"
#         db_port: "5432"
#
# Notes:
#   - Shared templates live in the .github governance repo:
#       .github/templates/integration-test-runner.Dockerfile
#       .github/scripts/run-integration-tests.sh
#   - This workflow checks out that repo and syncs those files into the
#     caller repo before building the runner image.

name: "BrikPipe â€” Containerized Integration Tests"

on:
  workflow_call:
    inputs:
      image:
        description: >
          Full tag for the service image under test. If the image does not
          exist in the registry yet, this workflow will attempt to pull it
          and, on failure, build it locally using dockerfile + context.
        required: true
        type: string
      dockerfile:
        description: >
          Path to the Dockerfile for building the service image under test.
        required: false
        type: string
        default: "./Dockerfile"
      context:
        description: >
          Build context directory for the service image under test.
        required: false
        type: string
        default: "."
      db_image:
        description: >
          Database image to use for integration tests. Example: postgres:16.
        required: false
        type: string
        default: "postgres:16"
      cache_image:
        description: >
          Optional cache or message broker image (e.g., redis:7, rabbitmq:3-management).
          Used only when enable_cache_service is true.
        required: false
        type: string
        default: ""
      test_command:
        description: >
          Shell command to run inside the test-runner container to execute
          integration tests. If empty, the runner falls back to language-specific
          defaults based on test_language.
        required: false
        type: string
        default: ""
      healthcheck_path:
        description: >
          Path on the app for readiness probing (combined with app_port).
          Example: /health or /actuator/health.
        required: false
        type: string
        default: "/health"
      healthcheck_timeout:
        description: >
          Maximum number of seconds to wait for DB + app readiness.
        required: false
        type: string
        default: "60"
      app_port:
        description: >
          Port exposed by the app container for HTTP health checks.
        required: false
        type: string
        default: "3000"
      db_port:
        description: >
          Database port for readiness checks.
        required: false
        type: string
        default: "5432"
      enable_cache_service:
        description: >
          If true, start a cache/message broker container using cache_image.
        required: false
        type: boolean
        default: false
      test_language:
        description: >
          Language hint for the test runner. Supported: node | python | java | go | dotnet.
          Used when test_command is empty.
        required: false
        type: string
        default: ""
      services_csv:
        description: "CSV of service IDs (integration only)."
        required: false
        type: string
        default: ""

      scenarios_csv:
        description: "CSV of scenario IDs (integration only)."
        required: false
        type: string
        default: ""

      override_shards:
        description: "Optional requested shard count for integration (clamped to caps 2â€“4)."
        required: false
        type: string
        default: ""

      matrix_config_path:
        description: "Optional path to parallel-matrix.yml (leave empty to use default in .github action)."
        required: false
        type: string
        default: ""

jobs:
  # 0) PLAN: compute governed matrix for integration serviceÃ—scenario
  plan:
    name: "Matrix Plan (integration)"
    runs-on: ubuntu-latest
    outputs:
      matrix_json: ${{ steps.matrix.outputs.matrix_json }}
    steps:
      - name: "Compute matrix plan (integration)"
        id: matrix
        uses: BrikByte-Studios/.github/.github/actions/matrix-plan@main
        with:
          test_type: "integration"
          config_path: ${{ inputs.matrix_config_path }}
          override_shards: ${{ inputs.override_shards }}
          services_csv: ${{ inputs.services_csv }}
          scenarios_csv: ${{ inputs.scenarios_csv }}

      - name: Debug
        run: echo "matrix_json=${{ steps.matrix.outputs.matrix_json }}"

  integration-tests:
    name: "Integration â€¢ shard ${{ matrix.shard }}"
    runs-on: ubuntu-latest
    timeout-minutes: 5  # DoD: sample repos under 5 minutes
    needs: plan

    strategy:
      fail-fast: false
      matrix: ${{ fromJson(needs.plan.outputs.matrix_json) }}

    # Use GitHub Environment "integration"
    environment: integration

    env:
      SERVICE_IMAGE: ${{ inputs.image }}
      DOCKERFILE_PATH: ${{ inputs.dockerfile }}
      BUILD_CONTEXT: ${{ inputs.context }}
      DB_IMAGE: ${{ inputs.db_image }}
      CACHE_IMAGE: ${{ inputs.cache_image }}
      TEST_COMMAND: ${{ inputs.test_command }}
      HEALTHCHECK_PATH: ${{ inputs.healthcheck_path }}
      HEALTHCHECK_TIMEOUT: ${{ inputs.healthcheck_timeout }}
      APP_PORT: ${{ inputs.app_port }}
      DB_PORT: ${{ inputs.db_port }}
      ENABLE_CACHE_SERVICE: ${{ inputs.enable_cache_service }}
      TEST_LANGUAGE: ${{ inputs.test_language }}
      SERVICE_WORKDIR: ${{ inputs.context }}

      # shard meta
      INTEG_SHARD: ${{ matrix.shard }}
      INTEG_ITEMS_CSV: ${{ matrix.items_csv }}  # <-- service::scenario pairs for this shard

      # Standardized integration secrets (INTEG_* naming)
      INTEG_DB_USER: ${{ secrets.INTEG_DB_USER }}
      INTEG_DB_PASS: ${{ secrets.INTEG_DB_PASS }}
      INTEG_DB_NAME: ${{ secrets.INTEG_DB_NAME }}
      INTEG_DB_HOST: ${{ secrets.INTEG_DB_HOST }}
      INTEG_DB_PORT: ${{ secrets.INTEG_DB_PORT }}
      JWT_SECRET_TEST: ${{ secrets.JWT_SECRET_TEST }}

    steps:
      - name: "Checkout caller repository (service under test)"
        #
        # This is the repo that invoked the reusable workflow
        # (e.g., brik-pipe-examples). All docker build and
        # integration test operations run in this workspace.
        #
        uses: actions/checkout@v4

      - name: "Checkout governance repo (.github) for shared integration templates"
        #
        # This repo contains the canonical integration-test runner Dockerfile
        # and orchestration script. We sync them into the caller repo so
        # docker build can reference local paths.
        #
        uses: actions/checkout@v4
        with:
          repository: BrikByte-Studios/.github
          path: org-dotgithub

      - name: "Sync shared integration-test templates into caller repo"
        run: |
          set -euo pipefail

          mkdir -p .github/scripts .github/templates

          # Core runner script
          cp org-dotgithub/.github/scripts/run-integration-tests.sh \
             .github/scripts/run-integration-tests.sh

          # DB fixtures loader (single source of truth in org .github repo)
          cp org-dotgithub/.github/scripts/db-load-fixtures.sh \
             .github/scripts/db-load-fixtures.sh

          # JSON seed helper (the one you said lives in the home .github repo)
          cp org-dotgithub/.github/scripts/db-seed-json.mjs \
             .github/scripts/db-seed-json.mjs

          # shared HTTP health helper
          cp org-dotgithub/.github/scripts/wait-for-health.sh \
             .github/scripts/wait-for-health.sh

          # Integration audit exporter
          cp org-dotgithub/.github/scripts/export-integration-audit.mjs \
             .github/scripts/export-integration-audit.mjs

          # integration env generator
          cp org-dotgithub/.github/scripts/env-generate-integration.sh \
            .github/scripts/env-generate-integration.sh

          # Integration test runner Dockerfile
          cp org-dotgithub/.github/templates/integration-test-runner.Dockerfile \
             .github/templates/integration-test-runner.Dockerfile

          # Ensure shell scripts are executable
          chmod +x .github/scripts/run-integration-tests.sh
          chmod +x .github/scripts/db-load-fixtures.sh
          chmod +x .github/scripts/wait-for-health.sh
          chmod +x .github/scripts/env-generate-integration.sh

          echo "Shared integration-test templates synced into caller workspace:"
          ls -R .github

      - name: "Log integration-test configuration"
        run: |
          echo "Service image         : ${SERVICE_IMAGE}"
          echo "Dockerfile path       : ${DOCKERFILE_PATH}"
          echo "Build context         : ${BUILD_CONTEXT}"
          echo "DB image              : ${DB_IMAGE}"
          echo "Cache image           : ${CACHE_IMAGE}"
          echo "Test command          : ${TEST_COMMAND}"
          echo "Healthcheck path      : ${HEALTHCHECK_PATH}"
          echo "Healthcheck timeout   : ${HEALTHCHECK_TIMEOUT}s"
          echo "App port              : ${APP_PORT}"
          echo "DB port               : ${DB_PORT}"
          echo "Enable cache service  : ${ENABLE_CACHE_SERVICE}"
          echo "Test language         : ${TEST_LANGUAGE}"

      - name: "Login to GHCR (if using GitHub Container Registry)"
        if: startsWith(env.SERVICE_IMAGE, 'ghcr.io/')
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: "Ensure service image exists (pull or build)"
        #
        # Preferred path:
        #   - Use Kaniko-built image (already pushed to registry).
        # Fallback:
        #   - If pull fails (e.g., first run), build locally using Dockerfile/context.
        #
        run: |
          set -euo pipefail

          echo "Attempting to pull service image: ${SERVICE_IMAGE}"
          if docker pull "${SERVICE_IMAGE}"; then
            echo "Successfully pulled existing service image."
          else
            echo "WARNING: Failed to pull service image; building locally..."
            docker build \
              -f "${DOCKERFILE_PATH}" \
              -t "${SERVICE_IMAGE}" \
              "${BUILD_CONTEXT}"
            echo "Local service image build complete."
          fi

      - name: "Build integration test runner image"
        #
        # Build the generic integration test runner from the synced template.
        #
        run: |
          set -euo pipefail

          docker build \
            -f .github/templates/integration-test-runner.Dockerfile \
            --build-arg SERVICE_WORKDIR="${SERVICE_WORKDIR}" \
            -t brikpipe/integration-test-runner:latest \
            .

      - name: "Create dedicated Docker network"
        #
        # Network so that app, db, cache, and runner can talk via hostnames.
        #
        run: |
          set -euo pipefail

          NETWORK_NAME="brikpipe-integ-net"

          if ! docker network inspect "${NETWORK_NAME}" >/dev/null 2>&1; then
            docker network create "${NETWORK_NAME}"
          fi

          echo "NETWORK_NAME=${NETWORK_NAME}" >> "$GITHUB_ENV"
          echo "Created/using Docker network: ${NETWORK_NAME}"

      - name: "Start DB container"
        #
        # Starts the database container on the dedicated network:
        #   - Name/hostname: db
        #   - Port exposed on host for diagnostics: DB_PORT
        #
        run: |
          set -euo pipefail

          echo "Starting DB container using image: ${DB_IMAGE}"
          docker run -d \
            --name db \
            --network "${NETWORK_NAME}" \
            -e POSTGRES_USER=testuser \
            -e POSTGRES_PASSWORD=testpass \
            -e POSTGRES_DB=testdb \
            -p "${DB_PORT}:5432" \
            --cpus="1.0" \
            --memory="512m" \
            "${DB_IMAGE}"

          echo "Currently running containers:"
          docker ps

      - name: "Install JSON seeding dependencies (pg)"
        run: |
          set -euo pipefail
          echo "ðŸ“¦ Installing JSON seeding dependencies under .github/scripts..."
          cd .github/scripts

          if [ ! -f package.json ]; then
            echo "Initializing package.json in .github/scripts..."
            npm init -y >/dev/null 2>&1
          fi

          npm install pg

      - name: "Load DB fixtures for integration tests"
        run: |
          set -euo pipefail
          echo "ðŸ”§ Loading DB fixtures for integration tests..."
          echo "Working directory: $(pwd)"
          echo "Listing .github/scripts:"
          ls -la .github/scripts || echo "No .github/scripts directory!"
          ./.github/scripts/db-load-fixtures.sh
        env:
          ENABLE_DB_FIXTURES: "true"
          DB_ENGINE: "postgres"
          DB_HOST: "localhost"            # host port is mapped via -p "${DB_PORT}:5432"
          DB_PORT: "${{ env.DB_PORT }}"
          DB_USER: "testuser"
          DB_PASSWORD: "testpass"
          DB_NAME: "testdb"
          FIXTURE_DIR: "${{ env.BUILD_CONTEXT }}/tests/integration/fixtures/db"
      - name: "Generate integration runtime env file"
        #
        # Builds .env.integ.runtime from INTEG_* env vars (in this job).
        # Fails fast if any required secret is missing.
        #
        run: |
          set -euo pipefail
          echo "ðŸ”’ Generating integration runtime env file for service..."
          SERVICE_WORKDIR="${BUILD_CONTEXT}" \
          .github/scripts/env-generate-integration.sh

          echo "Generated files in ${BUILD_CONTEXT}:"
          ls -la "${BUILD_CONTEXT}"


      - name: "Start cache/message broker container (optional)"
        if: env.ENABLE_CACHE_SERVICE == 'true'
        run: |
          set -euo pipefail

          if [ -z "${CACHE_IMAGE}" ]; then
            echo "::error::ENABLE_CACHE_SERVICE is true but CACHE_IMAGE is empty."
            exit 1
          fi

          echo "Starting cache container using image: ${CACHE_IMAGE}"
          docker run -d \
            --name cache \
            --network "${NETWORK_NAME}" \
            --cpus="0.5" \
            --memory="256m" \
            "${CACHE_IMAGE}"

          echo "Currently running containers (after cache start):"
          docker ps

      - name: "Start app container"
        #
        # Starts the service image under test:
        #   - Name/hostname: app
        #   - Exposes APP_PORT for HTTP health checks.
        #
        run: |
          set -euo pipefail

          echo "Starting app container using image: ${SERVICE_IMAGE}"

          RUNTIME_ENV_FILE="${BUILD_CONTEXT}/.env.integ.runtime"
          if [ ! -f "${RUNTIME_ENV_FILE}" ]; then
            echo "::error::Expected runtime env file not found: ${RUNTIME_ENV_FILE}"
            exit 1
          fi

          echo "Starting app container using image: ${SERVICE_IMAGE}"
          docker run -d \
            --name app \
            --network "${NETWORK_NAME}" \
            --env-file "${RUNTIME_ENV_FILE}" \
            -e DB_HOST=db \
            -e DB_PORT="${DB_PORT}" \
            -e CACHE_HOST=cache \
            -e CACHE_PORT=6379 \
            -e EXTERNAL_API_STUB_MODE=true \
            -p "${APP_PORT}:${APP_PORT}" \
            --cpus="1.0" \
            --memory="512m" \
            "${SERVICE_IMAGE}"

          echo "Currently running containers (after app start):"
          docker ps

      - name: "Run integration tests in runner container"
        #
        # Runs the tests in the dedicated runner container. Health checks
        # (DB + app) and actual test execution happen inside run-integration-tests.sh.
        #
        run: |
          set -euo pipefail

          APP_BASE_URL="http://app:${APP_PORT}"
          APP_HEALTH_URL="${APP_BASE_URL}${HEALTHCHECK_PATH}"
          

          echo "Running integration tests with:"
          echo "  APP_BASE_URL        : ${APP_BASE_URL}"
          echo "  APP_HEALTH_URL      : ${APP_HEALTH_URL}"
          echo "  DB_HOST             : db"
          echo "  DB_PORT             : ${DB_PORT}"
          echo "  HEALTHCHECK_TIMEOUT : ${HEALTHCHECK_TIMEOUT}"
          echo "  TEST_LANGUAGE       : ${TEST_LANGUAGE}"
          echo "  TEST_COMMAND        : ${TEST_COMMAND}"
          echo "  SERVICE_WORKDIR     : ${SERVICE_WORKDIR}"
          echo "Shard: ${INTEG_SHARD}"
          echo "Items: ${INTEG_ITEMS_CSV}"

          # Mark job start time for audit metadata
          INTEG_JOB_STARTED_AT="$(date -u +%Y-%m-%dT%H:%M:%SZ)"
          echo "INTEG_JOB_STARTED_AT=${INTEG_JOB_STARTED_AT}" >> "$GITHUB_ENV"

          docker run --rm \
            --name tests \
            --network "${NETWORK_NAME}" \
            -v "${PWD}/${SERVICE_WORKDIR}:/workspace/${SERVICE_WORKDIR}" \
            -e APP_BASE_URL="${APP_BASE_URL}" \
            -e APP_HEALTH_URL="${APP_HEALTH_URL}" \
            -e DB_HOST="db" \
            -e DB_PORT="${DB_PORT}" \
            -e HEALTHCHECK_TIMEOUT="${HEALTHCHECK_TIMEOUT}" \
            -e TEST_LANGUAGE="${TEST_LANGUAGE}" \
            -e TEST_COMMAND="${TEST_COMMAND}" \
            -e SERVICE_WORKDIR="${SERVICE_WORKDIR}" \
            -e INTEG_SHARD="${INTEG_SHARD}" \
            -e INTEG_ITEMS_CSV="${INTEG_ITEMS_CSV}" \
            brikpipe/integration-test-runner:latest

      - name: "Dump service logs on failure (diagnostic aid)"
        if: failure()
        run: |
          set -euo pipefail

          echo "==== Docker logs: db ===="
          docker logs db || true

          echo "==== Docker logs: cache ===="
          docker logs cache || true

          echo "==== Docker logs: app ===="
          docker logs app || true

      - name: "Capture integration container logs to workspace"
        if: always()
        run: |
          set -euo pipefail

          LOG_DIR="${SERVICE_WORKDIR}/out/integration-logs"
          mkdir -p "${LOG_DIR}"

          echo "Capturing container logs into ${LOG_DIR}..."

          # App container logs
          docker logs app > "${LOG_DIR}/app.log" 2>&1 || echo "No app logs."

          # DB container logs
          docker logs db > "${LOG_DIR}/db.log" 2>&1 || echo "No db logs."

          # Cache / mocks container logs (optional)
          if docker ps -a --format '{{.Names}}' | grep -q '^cache$'; then
            docker logs cache > "${LOG_DIR}/cache.log" 2>&1 || echo "No cache logs."
          fi

          # Test runner container logs (if still present)
          if docker ps -a --format '{{.Names}}' | grep -q '^tests$'; then
            docker logs tests > "${LOG_DIR}/tests.log" 2>&1 || echo "No tests logs."
          fi

          echo "Log capture complete. Files:"
          ls -la "${LOG_DIR}"

      - name: "Tear down containers and network"
        if: always()
        run: |
          set -euo pipefail

          echo "Stopping containers (tests, app, db, cache)..."
          docker stop tests app db cache 2>/dev/null || true

          echo "Removing containers..."
          docker rm -f tests app db cache 2>/dev/null || true

          echo "Removing network..."
          docker network rm "${NETWORK_NAME}" 2>/dev/null || true

          echo "Cleanup completed."

      - name: "Export integration audit bundle"
        if: always()
        run: |
          set -euo pipefail

          echo "Exporting integration audit bundle..."
          echo "Repo root: $(pwd)"
          echo "SERVICE_WORKDIR: ${SERVICE_WORKDIR}"

          # Paths are relative to repo root.
          JUNIT_PATH="${SERVICE_WORKDIR}/out/junit-integration.xml"
          RESULTS_PATH="${SERVICE_WORKDIR}/out/integration-results.json"
          LOGS_DIR="${SERVICE_WORKDIR}/out/integration-logs"
          COVERAGE_PATH="${SERVICE_WORKDIR}/out/coverage-integration.json"

          node .github/scripts/export-integration-audit.mjs \
            --junit "${JUNIT_PATH}" \
            --results "${RESULTS_PATH}" \
            --logs-dir "${LOGS_DIR}" \
            --coverage "${COVERAGE_PATH}"
        env:
          SERVICE_IMAGE: "${{ env.SERVICE_IMAGE }}"
          SERVICE_WORKDIR: "${{ env.SERVICE_WORKDIR }}"

      - name: "Upload integration audit artifact"
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: "integration-audit-${{ github.run_id }}"
          path: .audit
          if-no-files-found: warn
          retention-days: 14
