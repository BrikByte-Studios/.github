# File: .github/workflows/integration-test.yml
#
# BrikPipe — Containerized Integration Tests (Reusable Workflow)
# --------------------------------------------------------------
# Purpose:
#   Provide a reusable, container-based integration test job that:
#     - Builds or pulls the *real* service image under test.
#     - Orchestrates app + DB + optional cache/messaging containers.
#     - Runs language-specific integration tests from a dedicated runner.
#     - Uses explicit health checks (DB + app) to avoid flaky race conditions.
#     - Tears everything down deterministically in under 5 minutes.
#
# Usage from a service repo (e.g. brik-pipe-examples):
#
#   jobs:
#     integration:
#       uses: BrikByte-Studios/.github/.github/workflows/integration-test.yml@main
#       secrets: inherit
#       with:
#         image: ghcr.io/brikbyte-studios/node-api-example:sha-${{ github.sha }}
#         dockerfile: node-api-example/Dockerfile
#         context: node-api-example
#         db_image: postgres:16
#         cache_image: redis:7
#         enable_cache_service: true
#         test_language: "node"
#         # Optional override:
#         # test_command: "npm run test:integration"
#         healthcheck_path: "/health"
#         healthcheck_timeout: "60"
#         app_port: "3000"
#         db_port: "5432"
#
# Notes:
#   - Shared templates live in the .github governance repo:
#       .github/templates/integration-test-runner.Dockerfile
#       .github/scripts/run-integration-tests.sh
#   - This workflow checks out that repo and syncs those files into the
#     caller repo before building the runner image.

name: "BrikPipe — Containerized Integration Tests"

on:
  workflow_call:
    inputs:
      image:
        description: >
          Full tag for the service image under test. If the image does not
          exist in the registry yet, this workflow will attempt to pull it
          and, on failure, build it locally using dockerfile + context.
        required: true
        type: string

      dockerfile:
        description: "Path to the Dockerfile for building the service image under test."
        required: false
        type: string
        default: "./Dockerfile"

      context:
        description: "Build context directory for the service image under test."
        required: false
        type: string
        default: "."

      db_image:
        description: "Database image to use for integration tests. Example: postgres:16."
        required: false
        type: string
        default: "postgres:16"

      cache_image:
        description: >
          Optional cache or message broker image (e.g., redis:7, rabbitmq:3-management).
          Used only when enable_cache_service is true.
        required: false
        type: string
        default: ""

      test_command:
        description: >
          Shell command to run inside the test-runner container to execute
          integration tests. If empty, the runner falls back to language-specific
          defaults based on test_language.
        required: false
        type: string
        default: ""

      healthcheck_path:
        description: >
          Path on the app for readiness probing (combined with app_port).
          Example: /health or /actuator/health.
        required: false
        type: string
        default: "/health"

      healthcheck_timeout:
        description: "Maximum number of seconds to wait for DB + app readiness."
        required: false
        type: string
        default: "60"

      app_port:
        description: "Port exposed by the app container for HTTP health checks."
        required: false
        type: string
        default: "3000"

      db_port:
        description: >
          Host port to expose Postgres on (diagnostics/seeding from runner host).
          Container port remains 5432 inside the docker network.
        required: false
        type: string
        default: "5432"

      enable_cache_service:
        description: "If true, start a cache/message broker container using cache_image."
        required: false
        type: boolean
        default: false

      test_language:
        description: >
          Language hint for the test runner. Supported: node | python | java | go | dotnet.
          Used when test_command is empty.
        required: false
        type: string
        default: ""

      services_csv:
        description: "CSV of service IDs (integration only)."
        required: false
        type: string
        default: ""

      scenarios_csv:
        description: "CSV of scenario IDs (integration only)."
        required: false
        type: string
        default: ""

      override_shards:
        description: "Optional requested shard count for integration (clamped to caps 2–4)."
        required: false
        type: string
        default: ""

      matrix_config_path:
        description: "Optional path to parallel-matrix.yml (leave empty to use default in .github action)."
        required: false
        type: string
        default: ""

    secrets:
      INTEG_DB_USER:
        required: false
      INTEG_DB_PASS:
        required: false
      INTEG_DB_NAME:
        required: false
      INTEG_DB_HOST:
        required: false
      INTEG_DB_PORT:
        required: false
      JWT_SECRET_TEST:
        required: false

permissions:
  contents: read
  packages: read

jobs:
  # ---------------------------------------------------------------------------
  # 0) PLAN: compute governed matrix for integration service×scenario
  # ---------------------------------------------------------------------------
  plan:
    name: "Matrix Plan (integration)"
    runs-on: ubuntu-latest
    outputs:
      matrix_json: ${{ steps.matrix.outputs.matrix_json }}

    steps:
      - name: "Compute matrix plan (integration)"
        id: matrix
        uses: BrikByte-Studios/.github/.github/actions/matrix-plan@main
        with:
          test_type: "integration"
          config_path: ${{ inputs.matrix_config_path }}
          override_shards: ${{ inputs.override_shards }}
          services_csv: ${{ inputs.services_csv }}
          scenarios_csv: ${{ inputs.scenarios_csv }}

      - name: Debug
        run: echo "matrix_json=${{ steps.matrix.outputs.matrix_json }}"

  # ---------------------------------------------------------------------------
  # 1) RUN: containerized integration tests per shard
  # ---------------------------------------------------------------------------
  integration-tests:
    name: "Integration • shard ${{ matrix.shard }}"
    runs-on: ubuntu-latest
    timeout-minutes: 10
    needs: plan

    strategy:
      fail-fast: false
      matrix: ${{ fromJson(needs.plan.outputs.matrix_json) }}

    environment: integration

    env:
      SERVICE_IMAGE: ${{ inputs.image }}
      DOCKERFILE_PATH: ${{ inputs.dockerfile }}
      BUILD_CONTEXT: ${{ inputs.context }}

      DB_IMAGE: ${{ inputs.db_image }}
      CACHE_IMAGE: ${{ inputs.cache_image }}

      TEST_COMMAND: ${{ inputs.test_command }}
      TEST_LANGUAGE: ${{ inputs.test_language }}

      HEALTHCHECK_PATH: ${{ inputs.healthcheck_path }}
      HEALTHCHECK_TIMEOUT: ${{ inputs.healthcheck_timeout }}

      # Ports
      APP_PORT: ${{ inputs.app_port }}
      DB_HOST_PORT: ${{ inputs.db_port }}          # host mapping (optional)
      DB_CONTAINER_PORT: "5432"                    # always 5432 inside docker network

      ENABLE_CACHE_SERVICE: ${{ inputs.enable_cache_service }}

      SERVICE_WORKDIR: ${{ inputs.context }}

      # shard meta (from matrix-plan)
      INTEG_SHARD: ${{ matrix.shard }}
      INTEG_ITEMS_CSV: ${{ matrix.items_csv }}

      # Standardized integration secrets (INTEG_* naming)
      INTEG_DB_USER: ${{ secrets.INTEG_DB_USER }}
      INTEG_DB_PASS: ${{ secrets.INTEG_DB_PASS }}
      INTEG_DB_NAME: ${{ secrets.INTEG_DB_NAME }}
      INTEG_DB_HOST: ${{ secrets.INTEG_DB_HOST }}
      INTEG_DB_PORT: ${{ secrets.INTEG_DB_PORT }}
      JWT_SECRET_TEST: ${{ secrets.JWT_SECRET_TEST }}

      FORCE_COLOR: "0"

    steps:
      - name: "Checkout caller repository (service under test)"
        uses: actions/checkout@v4

      - name: "Checkout governance repo (.github) for shared integration templates"
        uses: actions/checkout@v4
        with:
          repository: BrikByte-Studios/.github
          path: org-dotgithub

      - name: "Sync shared integration-test templates into caller repo"
        run: |
          set -euo pipefail
          mkdir -p .github/scripts .github/templates

          cp org-dotgithub/.github/scripts/run-integration-tests.sh \
             .github/scripts/run-integration-tests.sh
          cp org-dotgithub/.github/scripts/db-load-fixtures.sh \
             .github/scripts/db-load-fixtures.sh
          cp org-dotgithub/.github/scripts/db-seed-json.mjs \
             .github/scripts/db-seed-json.mjs
          cp org-dotgithub/.github/scripts/wait-for-health.sh \
             .github/scripts/wait-for-health.sh
          cp org-dotgithub/.github/scripts/export-integration-audit.mjs \
             .github/scripts/export-integration-audit.mjs
          cp org-dotgithub/.github/scripts/env-generate-integration.sh \
             .github/scripts/env-generate-integration.sh

          cp org-dotgithub/.github/templates/integration-test-runner.Dockerfile \
             .github/templates/integration-test-runner.Dockerfile

          chmod +x .github/scripts/run-integration-tests.sh
          chmod +x .github/scripts/db-load-fixtures.sh
          chmod +x .github/scripts/wait-for-health.sh
          chmod +x .github/scripts/env-generate-integration.sh

          echo "Shared integration-test templates synced."
          ls -R .github

      # -----------------------------------------------------------------------
      # Standard contract header (BrikByteOS)
      # -----------------------------------------------------------------------
      - name: "Parallel runner (contract only)"
        id: pr
        uses: BrikByte-Studios/.github/.github/actions/parallel-runner@main
        with:
          parallel_enabled: "true"
          parallel_mode: "static"
          shard_index: ${{ matrix.shard }}          # matrix-plan should be 0-based
          shard_total: ${{ strategy.job-total }}
          selection_mode: "none"
          working_directory: ${{ env.SERVICE_WORKDIR }}

      - name: "Log integration-test configuration"
        run: |
          set -euo pipefail
          echo "Service image        : ${SERVICE_IMAGE}"
          echo "Dockerfile path      : ${DOCKERFILE_PATH}"
          echo "Build context        : ${BUILD_CONTEXT}"
          echo "DB image             : ${DB_IMAGE}"
          echo "Cache image          : ${CACHE_IMAGE}"
          echo "Test command         : ${TEST_COMMAND}"
          echo "Test language        : ${TEST_LANGUAGE}"
          echo "Health path          : ${HEALTHCHECK_PATH}"
          echo "Health timeout       : ${HEALTHCHECK_TIMEOUT}s"
          echo "App port             : ${APP_PORT}"
          echo "DB container port    : ${DB_CONTAINER_PORT}"
          echo "DB host port         : ${DB_HOST_PORT}"
          echo "Enable cache service : ${ENABLE_CACHE_SERVICE}"
          echo "Shard                : ${INTEG_SHARD}/${{ strategy.job-total }}"
          echo "Items                : ${INTEG_ITEMS_CSV}"

      - name: "Login to GHCR (if using GitHub Container Registry)"
        if: startsWith(env.SERVICE_IMAGE, 'ghcr.io/')
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: "Ensure service image exists (pull or build)"
        run: |
          set -euo pipefail
          echo "Attempting to pull service image: ${SERVICE_IMAGE}"
          if docker pull "${SERVICE_IMAGE}"; then
            echo "Pulled existing service image."
          else
            echo "WARNING: pull failed; building locally..."
            docker build -f "${DOCKERFILE_PATH}" -t "${SERVICE_IMAGE}" "${BUILD_CONTEXT}"
          fi

      - name: "Build integration test runner image"
        run: |
          set -euo pipefail
          docker build \
            -f .github/templates/integration-test-runner.Dockerfile \
            --build-arg SERVICE_WORKDIR="${SERVICE_WORKDIR}" \
            -t brikpipe/integration-test-runner:latest \
            .

      - name: "Create dedicated Docker network"
        run: |
          set -euo pipefail
          NETWORK_NAME="brikpipe-integ-net"
          docker network inspect "${NETWORK_NAME}" >/dev/null 2>&1 || docker network create "${NETWORK_NAME}"
          echo "NETWORK_NAME=${NETWORK_NAME}" >> "$GITHUB_ENV"
          echo "Using network: ${NETWORK_NAME}"

      - name: "Start DB container"
        run: |
          set -euo pipefail
          echo "Starting DB container: ${DB_IMAGE}"
          docker run -d \
            --name db \
            --network "${NETWORK_NAME}" \
            -e POSTGRES_USER=testuser \
            -e POSTGRES_PASSWORD=testpass \
            -e POSTGRES_DB=testdb \
            -p "${DB_HOST_PORT}:${DB_CONTAINER_PORT}" \
            --cpus="1.0" \
            --memory="512m" \
            "${DB_IMAGE}"

          docker ps

      - name: "Install JSON seeding dependencies (pg)"
        run: |
          set -euo pipefail
          cd .github/scripts
          if [ ! -f package.json ]; then npm init -y >/dev/null 2>&1; fi
          npm install pg

      - name: "Load DB fixtures for integration tests"
        env:
          ENABLE_DB_FIXTURES: "true"
          DB_ENGINE: "postgres"
          DB_HOST: "localhost"
          DB_PORT: "${{ env.DB_HOST_PORT }}"
          DB_USER: "testuser"
          DB_PASSWORD: "testpass"
          DB_NAME: "testdb"
          FIXTURE_DIR: "${{ env.BUILD_CONTEXT }}/tests/integration/fixtures/db"
        run: |
          set -euo pipefail
          ./.github/scripts/db-load-fixtures.sh

      - name: "Generate integration runtime env file"
        run: |
          set -euo pipefail
          SERVICE_WORKDIR="${BUILD_CONTEXT}" .github/scripts/env-generate-integration.sh
          ls -la "${BUILD_CONTEXT}"

      - name: "Start cache/message broker container (optional)"
        if: env.ENABLE_CACHE_SERVICE == 'true'
        run: |
          set -euo pipefail
          if [ -z "${CACHE_IMAGE}" ]; then
            echo "::error::ENABLE_CACHE_SERVICE is true but CACHE_IMAGE is empty."
            exit 1
          fi
          docker run -d \
            --name cache \
            --network "${NETWORK_NAME}" \
            --cpus="0.5" \
            --memory="256m" \
            "${CACHE_IMAGE}"
          docker ps

      - name: "Start app container"
        run: |
          set -euo pipefail

          RUNTIME_ENV_FILE="${BUILD_CONTEXT}/.env.integ.runtime"
          if [ ! -f "${RUNTIME_ENV_FILE}" ]; then
            echo "::error::Expected runtime env file not found: ${RUNTIME_ENV_FILE}"
            exit 1
          fi

          docker run -d \
            --name app \
            --network "${NETWORK_NAME}" \
            --env-file "${RUNTIME_ENV_FILE}" \
            -e DB_HOST=db \
            -e DB_PORT="${DB_CONTAINER_PORT}" \
            -e CACHE_HOST=cache \
            -e CACHE_PORT=6379 \
            -e EXTERNAL_API_STUB_MODE=true \
            -p "${APP_PORT}:${APP_PORT}" \
            --cpus="1.0" \
            --memory="512m" \
            "${SERVICE_IMAGE}"

          docker ps

      - name: "Run integration tests in runner container"
        run: |
          set -euo pipefail

          APP_BASE_URL="http://app:${APP_PORT}"
          APP_HEALTH_URL="${APP_BASE_URL}${HEALTHCHECK_PATH}"

          INTEG_JOB_STARTED_AT="$(date -u +%Y-%m-%dT%H:%M:%SZ)"
          echo "INTEG_JOB_STARTED_AT=${INTEG_JOB_STARTED_AT}" >> "$GITHUB_ENV"

          docker run --rm \
            --name tests \
            --network "${NETWORK_NAME}" \
            -v "${PWD}/${SERVICE_WORKDIR}:/workspace/${SERVICE_WORKDIR}" \
            -e APP_BASE_URL="${APP_BASE_URL}" \
            -e APP_HEALTH_URL="${APP_HEALTH_URL}" \
            -e DB_HOST="db" \
            -e DB_PORT="${DB_CONTAINER_PORT}" \
            -e HEALTHCHECK_TIMEOUT="${HEALTHCHECK_TIMEOUT}" \
            -e TEST_LANGUAGE="${TEST_LANGUAGE}" \
            -e TEST_COMMAND="${TEST_COMMAND}" \
            -e SERVICE_WORKDIR="${SERVICE_WORKDIR}" \
            -e INTEG_SHARD="${INTEG_SHARD}" \
            -e INTEG_ITEMS_CSV="${INTEG_ITEMS_CSV}" \
            brikpipe/integration-test-runner:latest

      - name: "Dump service logs on failure (diagnostic aid)"
        if: failure()
        run: |
          set -euo pipefail
          echo "==== Docker logs: db ===="
          docker logs db || true
          echo "==== Docker logs: cache ===="
          docker logs cache || true
          echo "==== Docker logs: app ===="
          docker logs app || true

      - name: "Capture integration container logs to workspace"
        if: always()
        run: |
          set -euo pipefail
          LOG_DIR="${SERVICE_WORKDIR}/out/integration-logs"
          mkdir -p "${LOG_DIR}"
          docker logs app > "${LOG_DIR}/app.log" 2>&1 || true
          docker logs db > "${LOG_DIR}/db.log" 2>&1 || true
          if docker ps -a --format '{{.Names}}' | grep -q '^cache$'; then
            docker logs cache > "${LOG_DIR}/cache.log" 2>&1 || true
          fi
          echo "Captured logs:"
          ls -la "${LOG_DIR}"

      - name: "Tear down containers and network"
        if: always()
        run: |
          set -euo pipefail
          docker rm -f tests app db cache 2>/dev/null || true
          docker network rm "${NETWORK_NAME}" 2>/dev/null || true

      - name: "Ensure .audit root exists (always)"
        if: always()
        run: |
          set -euo pipefail
          mkdir -p .audit
          echo "Audit root ready: $(pwd)/.audit"

      - name: "Export integration audit bundle"
        if: always()
        run: |
          set -euo pipefail

          mkdir -p .audit

          JUNIT_PATH="${SERVICE_WORKDIR}/out/junit-integration.xml"
          RESULTS_PATH="${SERVICE_WORKDIR}/out/integration-results.json"
          LOGS_DIR="${SERVICE_WORKDIR}/out/integration-logs"
          COVERAGE_PATH="${SERVICE_WORKDIR}/out/coverage-integration.json"

          echo "Exporting integration audit bundle..."
          echo "JUNIT_PATH=${JUNIT_PATH}"
          echo "RESULTS_PATH=${RESULTS_PATH}"
          echo "LOGS_DIR=${LOGS_DIR}"
          echo "COVERAGE_PATH=${COVERAGE_PATH}"

          node .github/scripts/export-integration-audit.mjs \
            --junit "${JUNIT_PATH}" \
            --results "${RESULTS_PATH}" \
            --logs-dir "${LOGS_DIR}" \
            --coverage "${COVERAGE_PATH}"

          echo "==== .audit tree ===="
          find .audit -maxdepth 6 -type f -print || true


      - name: "Upload integration audit artifact"
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: "integration-audit-${{ github.run_id }}"
          path: .audit
          if-no-files-found: warn
          retention-days: 14
          include-hidden-files: true
