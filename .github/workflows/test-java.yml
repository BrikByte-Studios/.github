# =============================================================================
# BrikByteOS ‚Äî Reusable Java Unit Test Workflow (Maven/Gradle)
# -----------------------------------------------------------------------------
# WBS ID : PIPE-TEST-UNIT-CI-BUILD-002
# Repos  :
#   - Implemented in:
#       ‚Ä¢ BrikByte-Studios/.github (.github/workflows/test-java.yml)
#   - Consumed by:
#       ‚Ä¢ BrikByte-Studios/brik-pipe-examples/java-api-example
#       ‚Ä¢ Product repos (via workflow_call)
#
# Contract:
#   - Expects:
#       ‚Ä¢ Makefile with `make test` calling:
#           - Maven: mvn -B test
#           - Gradle: ./gradlew test
#       ‚Ä¢ src/test/java for tests.
#
# Matrix plan integration:
#   - Uses BrikPipe Matrix Plan composite action to compute shards deterministically
#   - Parallel rules live in:
#       BrikByte-Studios/.github/.github/actions/matrix-plan/parallel-matrix.yml
# =============================================================================
name: "BrikByteOS ‚Äî Java Unit Tests"

on:
  workflow_call:
    inputs:
      java-version:
        description: "Java version (e.g. 17 or 21; must align with runtime matrix)"
        required: false
        type: string
        default: "17"

      distribution:
        description: "JDK distribution (e.g. temurin)"
        required: false
        type: string
        default: "temurin"

      working-directory:
        description: "Path to Java project (Makefile + pom.xml/build.gradle)"
        required: false
        type: string
        default: "."

      # ------------------------------
      # Governed parallelism (optional)
      # ------------------------------
      override_shards:
        description: "Optional requested shard count (clamped to caps)."
        required: false
        type: string
        default: ""

      matrix_config_path:
        description: >
          Optional path to parallel-matrix.yml.
          Leave empty to use default inside BrikByte-Studios/.github.
        required: false
        type: string
        default: ""

      parallel_mode:
        description: "Parallel mode: static|dynamic (default static)"
        required: false
        type: string
        default: "static"

      parallel_enabled:
        description: "Enable parallel shard execution (true|false)"
        required: false
        type: string
        default: "true"

      # -----------------------------------------------------------------------
      # Flaky detection (PIPE-FLAKY-RERUN-INTEG-001)
      # -----------------------------------------------------------------------
      flaky_detect:
        description: "Enable suite-level flaky detection reruns (true|false)"
        required: false
        type: string
        default: "false"

      flaky_reruns:
        description: "Total attempts when flaky_detect=true (e.g., 3)"
        required: false
        type: string
        default: "3"

      flaky_export_path:
        description: "Relative path (from working-directory) to store flaky evidence"
        required: false
        type: string
        default: "out/flaky"

      # -----------------------------------------------------------------------
      # Flaky policy evaluation (PIPE-FLAKY-POLICY-CONFIG-002)
      # -----------------------------------------------------------------------
      flaky_policy_path:
        description: >
          Path to policy-as-code YAML (repo root) IF repo overrides exist.
          NOTE: If missing, central policy from BrikByte-Studios/.github is used.
        required: false
        type: string
        default: ".governance/flaky-tests.yml"

      flaky_policy_enforce:
        description: >
          If true, evaluator may block ONLY if policy enables blocking.
          If false, evaluator still runs (when flaky_detect=true) but never blocks.
        required: false
        type: boolean
        default: true

permissions:
  contents: read

jobs:
  # ------------------------------------------------------------
  # 1) PLAN: compute governed matrix JSON (job output)
  # ------------------------------------------------------------
  plan:
    name: "Matrix Plan (java unit)"
    runs-on: ubuntu-latest
    outputs:
      matrix_json: ${{ steps.matrix.outputs.matrix_json }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: "Compute matrix plan (unit)"
        id: matrix
        uses: BrikByte-Studios/.github/.github/actions/matrix-plan@main
        with:
          test_type: "unit"
          config_path: ${{ inputs.matrix_config_path }}
          override_shards: ${{ inputs.override_shards }}

      - name: "Debug matrix_json"
        run: |
          echo "matrix_json=${{ steps.matrix.outputs.matrix_json }}"

  # ------------------------------------------------------------
  # 2) TEST: run shards from matrix computed in plan job
  # ------------------------------------------------------------
  test:
    name: "Java: Unit Tests ‚Ä¢ shard ${{ matrix.shard }}"
    needs: plan
    runs-on: ubuntu-latest

    strategy:
      fail-fast: false
      matrix: ${{ fromJson(needs.plan.outputs.matrix_json) }}

    env:
      LANGUAGE: java
      JAVA_VERSION: ${{ inputs.java-version != '' && inputs.java-version || '17' }}
      JAVA_DISTRIBUTION: ${{ inputs.distribution || 'temurin' }}
      WORKING_DIRECTORY: ${{ inputs.working-directory != '' && inputs.working-directory || '.' }}

      # shard metadata (defined by matrix-plan)
      SHARD_INDEX: ${{ matrix.shard }}              # 0-based
      SHARD_TOTAL: ${{ strategy.job-total }}

      PARALLEL_MODE: ${{ inputs.parallel_mode }}
      PARALLEL: ${{ inputs.parallel_enabled }}

      # Flaky detection contract (2.5.1)
      FLAKY_DETECT: ${{ inputs.flaky_detect }}
      FLAKY_RERUNS: ${{ inputs.flaky_reruns }}
      FLAKY_EXPORT_PATH: ${{ inputs.flaky_export_path }}

      # Flaky policy (2.5.2)
      FLAKY_POLICY_PATH: ${{ inputs.flaky_policy_path }}
      FLAKY_POLICY_ENFORCE: ${{ inputs.flaky_policy_enforce }}

      FORCE_COLOR: "0"

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Verify Java test layout
        run: |
          set -euo pipefail
          echo "üìÅ Working directory: ${WORKING_DIRECTORY}"

          if [ ! -d "${WORKING_DIRECTORY}" ]; then
            echo "‚ùå WORKING_DIRECTORY '${WORKING_DIRECTORY}' does not exist."
            exit 1
          fi

          if [ ! -f "${WORKING_DIRECTORY}/Makefile" ]; then
            echo "‚ùå Makefile not found in ${WORKING_DIRECTORY}."
            echo "   Expected 'make test' using Maven or Gradle."
            exit 1
          fi

          if [ ! -f "${WORKING_DIRECTORY}/pom.xml" ] && \
             [ ! -f "${WORKING_DIRECTORY}/build.gradle" ] && \
             [ ! -f "${WORKING_DIRECTORY}/build.gradle.kts" ]; then
            echo "‚ùå No pom.xml or build.gradle(.kts) found in ${WORKING_DIRECTORY}."
            exit 1
          fi

      - name: Setup Java
        uses: actions/setup-java@v4
        with:
          distribution: ${{ env.JAVA_DISTRIBUTION }}
          java-version: ${{ env.JAVA_VERSION }}

      - name: "Cache JVM dependencies (Maven / Gradle)"
        uses: BrikByte-Studios/.github/.github/actions/cache-java-deps@main
        with:
          java-version: ${{ env.JAVA_VERSION }}
          project-path: ${{ env.WORKING_DIRECTORY }}

      - name: Compute shard env (1-based for Makefile)
        shell: bash
        run: |
          set -euo pipefail

          SHARD0="${SHARD_INDEX}"
          TOTAL="${SHARD_TOTAL}"

          # Convert to 1-based (only if your Makefile expects it)
          SHARD1=$((SHARD0 + 1))

          {
            echo "UNIT_SHARD=${SHARD1}"
            echo "UNIT_SHARD_TOTAL=${TOTAL}"
          } >> "$GITHUB_ENV"

          echo "[SHARD] 0-based=${SHARD0} -> 1-based=${SHARD1} / total=${TOTAL}"

      - name: Parallel runner (serial/static/dynamic)
        id: pr
        uses: BrikByte-Studios/.github/.github/actions/parallel-runner@main
        with:
          parallel_enabled: ${{ env.PARALLEL }}
          parallel_mode: ${{ env.PARALLEL_MODE }}
          shard_index: ${{ matrix.shard }}          # 0-based
          shard_total: ${{ strategy.job-total }}
          selection_mode: "file-split"
          working_directory: ${{ env.WORKING_DIRECTORY }}
          test_glob: "**/*Test.java"
          out_list: "${{ env.WORKING_DIRECTORY }}/out/shard-files.txt"
          allow_missing_items_file: true

      # -----------------------------------------------------------------------
      # Shared scripts repo (flaky-rerun.sh + evaluator sources + central policy)
      # -----------------------------------------------------------------------
      - name: Checkout BrikByte shared scripts
        uses: actions/checkout@v4
        with:
          repository: BrikByte-Studios/.github
          ref: main
          path: .brikbyte-github

      # -----------------------------------------------------------------------
      # Run unit tests via `make test` (wired through flaky-rerun.sh)
      # -----------------------------------------------------------------------
      - name: Run Java unit tests (make test) with flaky reruns (opt-in)
        if: ${{ steps.pr.outputs.is_empty_shard != 'true' }}
        working-directory: ${{ env.WORKING_DIRECTORY }}
        run: |
          set -euo pipefail

          echo "üß™ [TEST] Language     : ${LANGUAGE}"
          echo "üß™ [TEST] Runtime      : Java (${JAVA_DISTRIBUTION}) ${JAVA_VERSION}"
          echo "üß™ [TEST] Directory    : ${PWD}"
          echo "üß™ [TEST] Shard        : ${SHARD_INDEX}/${SHARD_TOTAL}"
          echo "üß™ [TEST] Command      : make test"
          echo "üß™ [TEST] FlakyDetect  : ${FLAKY_DETECT:-false}"
          echo "üß™ [TEST] FlakyReruns  : ${FLAKY_RERUNS:-3}"
          echo "üß™ [TEST] FlakyExport  : ${FLAKY_EXPORT_PATH:-out/flaky}"
          echo "üß™ [TEST] Status       : STARTING"

          # Provide selection/shard env to your Makefile if it supports them
          export UNIT_SHARD="${UNIT_SHARD:-$((SHARD_INDEX + 1))}"
          export UNIT_SHARD_TOTAL="${UNIT_SHARD_TOTAL:-$SHARD_TOTAL}"

          # Flaky wrapper config (used by flaky-rerun.sh)
          export FLAKY_DETECT="${FLAKY_DETECT:-false}"
          export FLAKY_RERUNS="${FLAKY_RERUNS:-3}"
          export FLAKY_EXPORT_PATH="${PWD}/${FLAKY_EXPORT_PATH:-out/flaky}"
          export FLAKY_LABEL="java-unit"

          BRIK_SCRIPTS="${GITHUB_WORKSPACE}/.brikbyte-github/.github/scripts"
          FLAKY_SH="${BRIK_SCRIPTS}/flaky-rerun.sh"

          if [[ ! -f "${FLAKY_SH}" ]]; then
            echo "‚ùå flaky-rerun.sh not found at: ${FLAKY_SH}"
            echo "üìÅ Available scripts:"
            ls -la "${BRIK_SCRIPTS}" || true
            exit 1
          fi
          chmod +x "${FLAKY_SH}"

          # Run through wrapper (opt-in via FLAKY_DETECT)
          "${FLAKY_SH}" -- make test

          echo "‚úÖ [TEST] Status       : COMPLETED"
          echo "‚ÑπÔ∏è  [TEST] See Maven/Gradle test summary above."

      - name: Empty shard (nothing to run)
        if: ${{ steps.pr.outputs.is_empty_shard == 'true' }}
        run: |
          echo "‚ÑπÔ∏è Empty shard ${SHARD_INDEX}/${SHARD_TOTAL} ‚Äî skipping tests."

      # =============================================================================
      # PIPE-FLAKY-POLICY-CONFIG-002 ‚Äî Evaluate evidence against policy-as-code
      # =============================================================================

      - name: "Select policy source (repo override -> central fallback)"
        if: ${{ always() && env.FLAKY_DETECT == 'true' }}
        working-directory: ${{ github.workspace }}
        run: |
          set -euo pipefail

          mkdir -p .tmp-flaky-eval

          REPO_POLICY="${GITHUB_WORKSPACE}/${FLAKY_POLICY_PATH}"
          CENTRAL_POLICY="${GITHUB_WORKSPACE}/.brikbyte-github/.governance/flaky-tests.yml"
          OUT_POLICY="${GITHUB_WORKSPACE}/.tmp-flaky-eval/policy.yml"

          echo "üß© [FLAKY] Repo policy     : ${REPO_POLICY}"
          echo "üèõÔ∏è [FLAKY] Central policy  : ${CENTRAL_POLICY}"
          echo "üìå [FLAKY] Selected policy : ${OUT_POLICY}"

          if [[ -f "${REPO_POLICY}" ]]; then
            echo "‚úÖ [FLAKY] Using repo override policy."
            cp "${REPO_POLICY}" "${OUT_POLICY}"
          else
            if [[ ! -f "${CENTRAL_POLICY}" ]]; then
              echo "‚ùå [FLAKY] Central policy missing at: ${CENTRAL_POLICY}"
              exit 1
            fi
            echo "‚úÖ [FLAKY] Repo policy not found; using central policy."
            cp "${CENTRAL_POLICY}" "${OUT_POLICY}"
          fi

      # Install deps at repo root so tsx + require() resolve regardless of CWD.
      # We *still* use Node here for evaluate-flaky.ts.
      - name: "Install evaluator deps (repo-root, pinned) [js-yaml + tsx]"
        if: ${{ always() && env.FLAKY_DETECT == 'true' }}
        working-directory: ${{ github.workspace }}
        env:
          NPM_CONFIG_FUND: "false"
          NPM_CONFIG_AUDIT: "false"
        run: |
          set -euo pipefail

          # Node is available on ubuntu-latest. Pin if you want, but not required.
          node -v
          npm -v

          if [[ ! -f package.json ]]; then
            npm init -y >/dev/null 2>&1
          fi

          npm i --no-save js-yaml@4 tsx@4 >/dev/null 2>&1
          echo "‚úÖ deps installed into repo-root node_modules"

      # Normalize wrapper output to evaluator contract:
      # - Ensure attempts have status
      # - Ensure pass_count/fail_count/total_attempts are consistent
      - name: "Normalize flaky evidence ‚Üí summary.normalized.json"
        if: ${{ always() && env.FLAKY_DETECT == 'true' }}
        working-directory: ${{ env.WORKING_DIRECTORY }}
        run: |
          set -euo pipefail

          EXPORT_DIR="${PWD}/${FLAKY_EXPORT_PATH}"
          EXPECTED="${EXPORT_DIR}/summary.json"
          LABELED="${EXPORT_DIR}/${FLAKY_LABEL:-java-unit}.summary.json"

          # Resolve evidence path
          EVIDENCE=""
          if [[ -f "${EXPECTED}" ]]; then
            EVIDENCE="${EXPECTED}"
          elif [[ -f "${LABELED}" ]]; then
            EVIDENCE="${LABELED}"
          else
            found="$(ls -1 "${EXPORT_DIR}"/*.summary.json 2>/dev/null | head -n 1 || true)"
            if [[ -n "${found}" ]]; then EVIDENCE="${found}"; fi
          fi

          if [[ -z "${EVIDENCE}" ]]; then
            echo "‚ÑπÔ∏è [FLAKY] No evidence found ‚Üí skipping normalization."
            ls -la "${EXPORT_DIR}" || true
            exit 0
          fi

          OUT_NORM="${EXPORT_DIR}/summary.normalized.json"
          echo "üîß [FLAKY] Normalizing: ${EVIDENCE} -> ${OUT_NORM}"

          EVIDENCE="${EVIDENCE}" OUT_NORM="${OUT_NORM}" python - <<'PY'
          import json
          from pathlib import Path
          import os

          evidence = Path(os.environ["EVIDENCE"])
          out_norm = Path(os.environ["OUT_NORM"])

          data = json.loads(evidence.read_text(encoding="utf-8"))

          attempts = data.get("attempts") if isinstance(data, dict) else None
          pass_count = 0
          fail_count = 0
          total_attempts = 0

          if isinstance(attempts, list) and attempts:
            total_attempts = len(attempts)
            for a in attempts:
              s = (a.get("status") or "").strip().lower()
              if not s:
                rc = int(a.get("exit_code", 0) or 0)
                s = "pass" if rc == 0 else "fail"
                a["status"] = s

              if s in ("pass", "passed", "ok", "success"):
                pass_count += 1
              elif s in ("fail", "failed", "error"):
                fail_count += 1
          else:
            pass_count = int(data.get("pass_count", 0) or 0) if isinstance(data, dict) else 0
            fail_count = int(data.get("fail_count", 0) or 0) if isinstance(data, dict) else 0
            total_attempts = pass_count + fail_count

          if isinstance(data, dict):
            data["pass_count"] = pass_count
            data["fail_count"] = fail_count
            data["total_attempts"] = total_attempts
            data["attempts"] = attempts if isinstance(attempts, list) else data.get("attempts", [])

          out_norm.parent.mkdir(parents=True, exist_ok=True)
          out_norm.write_text(json.dumps(data, indent=2), encoding="utf-8")
          print(f"‚úÖ wrote {out_norm} (pass={pass_count}, fail={fail_count}, total={total_attempts})")
          PY

          echo "=== normalized summary ==="
          cat "${OUT_NORM}"

      - name: "Evaluate flaky policy (use normalized summary)"
        if: ${{ always() && env.FLAKY_DETECT == 'true' }}
        working-directory: ${{ env.WORKING_DIRECTORY }}
        run: |
          set -euo pipefail

          POLICY="${GITHUB_WORKSPACE}/.tmp-flaky-eval/policy.yml"
          EXPORT_DIR="${PWD}/${FLAKY_EXPORT_PATH}"
          IN_NORM="${EXPORT_DIR}/summary.normalized.json"
          OUT_JSON="${EXPORT_DIR}/evaluation.json"

          echo "üß© [FLAKY] Policy     : ${POLICY}"
          echo "üìÅ [FLAKY] Export dir : ${EXPORT_DIR}"
          echo "üì• [FLAKY] Normalized : ${IN_NORM}"
          echo "üì§ [FLAKY] Output     : ${OUT_JSON}"
          echo "üõ°Ô∏è [FLAKY] Enforce    : ${FLAKY_POLICY_ENFORCE}"

          if [[ ! -f "${POLICY}" ]]; then
            echo "‚ùå [FLAKY] Missing policy file: ${POLICY}"
            exit 1
          fi

          if [[ ! -f "${IN_NORM}" ]]; then
            echo "‚ÑπÔ∏è [FLAKY] Normalized summary missing ‚Üí skipping evaluation (non-blocking)."
            ls -la "${EXPORT_DIR}" || true
            exit 0
          fi

          EVAL_TS="${GITHUB_WORKSPACE}/.brikbyte-github/.github/scripts/evaluate-flaky.ts"
          if [[ ! -f "${EVAL_TS}" ]]; then
            echo "‚ùå [FLAKY] evaluate-flaky.ts not found at: ${EVAL_TS}"
            exit 1
          fi

          # Run evaluator from repo root so module resolution is stable.
          pushd "${GITHUB_WORKSPACE}" >/dev/null
          npx tsx "${EVAL_TS}" \
            --policy "${POLICY}" \
            --input "${IN_NORM}" \
            --out "${OUT_JSON}" \
            --md || rc=$?
          popd >/dev/null

          if [[ "${rc:-0}" != "0" && "${FLAKY_POLICY_ENFORCE}" != "true" ]]; then
            echo "‚ö†Ô∏è [FLAKY] Evaluator exit=${rc} but enforce=false ‚Üí not blocking."
            exit 0
          fi

          exit "${rc:-0}"

      - name: Export flaky analytics (when enabled)
        if: ${{ always() && env.FLAKY_DETECT == 'true' }}
        working-directory: ${{ env.WORKING_DIRECTORY }}
        run: |
          set -euo pipefail
          BRIK_SCRIPTS="${GITHUB_WORKSPACE}/.brikbyte-github/.github/scripts"
          FLAKY_SH="${BRIK_SCRIPTS}/export-flaky-analytics.mjs"

          if [[ ! -f "${FLAKY_SH}" ]]; then
            echo "‚ùå export-flaky-analytics.ts not found at: ${FLAKY_SH}"
            echo "üìÅ Available scripts:"
            ls -la "${BRIK_SCRIPTS}" || true
            exit 1
          fi

          chmod +x "${FLAKY_SH}"
          node "${FLAKY_SH}" \
            --suite unit \
            --audit-root "${GITHUB_WORKSPACE}/.audit" \
            --out-dir "${FLAKY_EXPORT_PATH:-out/flaky}" \
            --top-n 10 \
            --write-md true \
            --allow-missing-evaluation true

      - name: "Upload flaky evaluation (always)"
        if: ${{ always() && env.FLAKY_DETECT == 'true' }}
        uses: actions/upload-artifact@v4
        with:
          name: flaky-eval-java-shard${{ env.SHARD_INDEX }}
          path: |
            ${{ env.WORKING_DIRECTORY }}/${{ inputs.flaky_export_path }}/
          if-no-files-found: warn
          include-hidden-files: true
          retention-days: 14

      # -----------------------------------------------------------------------
      # Detect JaCoCo presence (empty shard => no jacoco.xml)
      # -----------------------------------------------------------------------
      - name: Detect JaCoCo XML presence
        id: jacoco
        working-directory: ${{ env.WORKING_DIRECTORY }}
        run: |
          set -euo pipefail
          if [ -f "target/site/jacoco/jacoco.xml" ] || [ -f "jacoco.xml" ]; then
            echo "has_jacoco=true" >> "$GITHUB_OUTPUT"
          else
            echo "has_jacoco=false" >> "$GITHUB_OUTPUT"
          fi

      # -----------------------------------------------------------------------
      # Collect coverage (Java: JaCoCo XML)
      # -----------------------------------------------------------------------
      - name: Normalize coverage ‚Üí coverage.json
        if: steps.jacoco.outputs.has_jacoco == 'true'
        uses: BrikByte-Studios/.github/.github/actions/coverage-merge@main
        with:
          language: ${{ env.LANGUAGE }}
          working-directory: ${{ env.WORKING_DIRECTORY }}
          out: out/coverage.json

      - name: Detect coverage.json presence
        id: covjson
        working-directory: ${{ env.WORKING_DIRECTORY }}
        run: |
          set -euo pipefail
          if [ -f "out/coverage.json" ]; then
            echo "has_covjson=true" >> "$GITHUB_OUTPUT"
          else
            echo "has_covjson=false" >> "$GITHUB_OUTPUT"
          fi

      - name: Ensure summary.line is set in coverage.json (Java / JaCoCo)
        if: steps.jacoco.outputs.has_jacoco == 'true'
        working-directory: ${{ env.WORKING_DIRECTORY }}
        run: |
          set -euo pipefail
          echo "üîß Normalizing coverage: syncing summary.line from JaCoCo XML"

          if [ -f "target/site/jacoco/jacoco.xml" ]; then
            export JACOCO_XML="target/site/jacoco/jacoco.xml"
          elif [ -f "jacoco.xml" ]; then
            export JACOCO_XML="jacoco.xml"
          else
            echo "‚ùå JaCoCo XML not found (expected target/site/jacoco/jacoco.xml or jacoco.xml)."
            ls -R
            exit 1
          fi

          python - <<'EOF'
          import json
          import xml.etree.ElementTree as ET
          from pathlib import Path
          import os

          jacoco_path = os.environ.get("JACOCO_XML", "target/site/jacoco/jacoco.xml")
          xml_path = Path(jacoco_path)

          if not xml_path.is_file():
            raise SystemExit(f"JaCoCo XML not found at {xml_path}")

          tree = ET.parse(xml_path)
          root = tree.getroot()

          missed = 0
          covered = 0
          for counter in root.iter("counter"):
            if counter.get("type") == "LINE":
              missed = int(counter.get("missed", "0"))
              covered = int(counter.get("covered", "0"))
              break

          total = missed + covered
          if total == 0:
            raise SystemExit("No LINE coverage data found in JaCoCo XML.")

          line_pct = (covered / total) * 100.0

          out_dir = Path("out")
          out_dir.mkdir(parents=True, exist_ok=True)
          cov_path = out_dir / "coverage.json"

          try:
            cov = json.loads(cov_path.read_text(encoding="utf-8"))
          except FileNotFoundError:
            cov = {}

          cov.setdefault("summary", {})
          cov["summary"]["line"] = line_pct
          cov.setdefault("files", [])

          cov_path.write_text(json.dumps(cov, indent=2), encoding="utf-8")
          print(f"‚úÖ Updated out/coverage.json with summary.line = {line_pct:.1f}")
          EOF

          echo "‚úÖ coverage.json after normalization:"
          cat out/coverage.json

      # -----------------------------------------------------------------------
      # Upload coverage artifacts (per shard)
      # -----------------------------------------------------------------------
      - name: Upload Java coverage artifacts
        if: steps.covjson.outputs.has_covjson == 'true'
        uses: actions/upload-artifact@v4
        with:
          name: coverage-java-shard${{ env.SHARD_INDEX }}
          path: |
            ${{ env.WORKING_DIRECTORY }}/out/coverage.json
            ${{ env.WORKING_DIRECTORY }}/target/site/jacoco/jacoco.xml
            ${{ env.WORKING_DIRECTORY }}/out/junit.xml
            ${{ env.WORKING_DIRECTORY }}/out/shard-files.txt
            ${{ env.WORKING_DIRECTORY }}/out/shard-packages.txt
          if-no-files-found: error
          include-hidden-files: true
          retention-days: 14

      - name: Upload flaky evidence (always)
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: flaky-java-shard${{ env.SHARD_INDEX }}
          path: |
            ${{ env.WORKING_DIRECTORY }}/${{ inputs.flaky_export_path }}/
          if-no-files-found: ignore
          include-hidden-files: true
          retention-days: 14
