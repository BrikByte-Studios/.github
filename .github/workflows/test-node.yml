# =============================================================================
# BrikByteOS ‚Äî Reusable Node.js Unit Test Workflow (wired like Python)
# -----------------------------------------------------------------------------
# Mirrors: BrikByteOS ‚Äî Python Unit Tests wiring (plan -> shard -> flaky rerun ->
# policy eval -> analytics export -> artifacts)
#
# Contract:
# - Expects Makefile with `make test`
# - Node project has package.json
# - Unit tests discoverable under tests/unit/** or project runner honors TEST_ITEMS_FILE
#
# Key hurdles avoided:
# - Evidence file naming drift: summary.json vs *.summary.json -> robust resolver
# - total_attempts mismatch -> normalized summary.normalized.json always created
# - js-yaml resolution -> deps installed at repo-root, evaluator run from stable CWD
# - empty shard -> evaluation/analytics safely no-op (allow-missing-evaluation)
# =============================================================================
name: "BrikByteOS ‚Äî Node.js Unit Tests"

on:
  workflow_call:
    inputs:
      node-version:
        description: "Node.js version (must align with Runtime Matrix)"
        required: false
        type: string
        default: "20"

      working-directory:
        description: "Path to Node project (folder with package.json + Makefile)"
        required: false
        type: string
        default: "."

      # -----------------------------
      # Matrix-plan (unit) wiring
      # -----------------------------
      override_shards:
        description: "Requested shard count (unit). Will be clamped by governance caps."
        required: false
        type: string
        default: ""

      matrix_config_path:
        description: "Optional path to parallel-matrix.yml. Leave empty to use action default."
        required: false
        type: string
        default: ""

      parallel_mode:
        description: "Parallel mode: static|dynamic (default static)"
        required: false
        type: string
        default: "static"

      parallel_enabled:
        description: "Enable parallel shard execution (true|false)"
        required: false
        type: string
        default: "true"

      # -----------------------------------------------------------------------
      # Flaky detection (PIPE-FLAKY-RERUN-INTEG-001)
      # -----------------------------------------------------------------------
      flaky_detect:
        description: "Enable suite-level flaky detection reruns (true|false)"
        required: false
        type: string
        default: "false"

      flaky_reruns:
        description: "Total attempts when flaky_detect=true (e.g., 3)"
        required: false
        type: string
        default: "3"

      flaky_export_path:
        description: "Relative path (from working-directory) to store flaky evidence"
        required: false
        type: string
        default: "out/flaky"

      # -----------------------------------------------------------------------
      # Flaky policy evaluation (PIPE-FLAKY-POLICY-CONFIG-002)
      # -----------------------------------------------------------------------
      flaky_policy_path:
        description: >
          Path to policy-as-code YAML (repo root) IF repo overrides exist.
          NOTE: If missing, central policy from BrikByte-Studios/.github is used.
        required: false
        type: string
        default: ".governance/flaky-tests.yml"

      flaky_policy_enforce:
        description: >
          If true, evaluator may block ONLY if policy enables blocking.
          If false, evaluator still runs (when flaky_detect=true) but never blocks.
        required: false
        type: boolean
        default: true

permissions:
  contents: read

jobs:
  # ----------------------------------------------------------------------------
  # PLAN: governed deterministic matrix (unit shards)
  # ----------------------------------------------------------------------------
  plan:
    name: "Plan governed Unit matrix"
    runs-on: ubuntu-latest
    outputs:
      matrix: ${{ steps.plan.outputs.matrix_json }}
    steps:
      - name: "Checkout repository"
        uses: actions/checkout@v4

      - name: "Generate unit shard matrix (governed)"
        id: plan
        uses: BrikByte-Studios/.github/.github/actions/matrix-plan@main
        with:
          test_type: unit
          config_path: ${{ inputs.matrix_config_path }}
          override_shards: ${{ inputs.override_shards }}
          browsers: ""
          items: ""

  # ----------------------------------------------------------------------------
  # TEST: shard matrix
  # ----------------------------------------------------------------------------
  test:
    name: "Node.js: Unit Tests ‚Ä¢ shard ${{ matrix.shard }}"
    needs: plan
    runs-on: ubuntu-latest

    strategy:
      fail-fast: false
      matrix: ${{ fromJson(needs.plan.outputs.matrix) }}

    env:
      LANGUAGE: node
      NODE_VERSION: ${{ inputs.node-version != '' && inputs.node-version || '20' }}
      WORKING_DIRECTORY: ${{ inputs.working-directory != '' && inputs.working-directory || '.' }}

      # Shard contract (0-based + total)
      SHARD_INDEX: ${{ matrix.shard }}
      SHARD_TOTAL: ${{ strategy.job-total }}

      # Optional generic contract
      E2E_SHARD: ${{ matrix.shard }}
      E2E_SHARD_TOTAL: ${{ strategy.job-total }}

      PARALLEL_MODE: ${{ inputs.parallel_mode }}
      PARALLEL: ${{ inputs.parallel_enabled }}

      # Flaky detection (2.5.1)
      FLAKY_DETECT: ${{ inputs.flaky_detect }}
      FLAKY_RERUNS: ${{ inputs.flaky_reruns }}
      FLAKY_EXPORT_PATH: ${{ inputs.flaky_export_path }}

      # Flaky policy (2.5.2)
      FLAKY_POLICY_PATH: ${{ inputs.flaky_policy_path }}
      FLAKY_POLICY_ENFORCE: ${{ inputs.flaky_policy_enforce }}

      FORCE_COLOR: "0"

    steps:
      # -----------------------------------------------------------------------
      # 1) Checkout repository
      # -----------------------------------------------------------------------
      - name: "Checkout repository"
        uses: actions/checkout@v4

      # -----------------------------------------------------------------------
      # 2) Verify Node project layout
      # -----------------------------------------------------------------------
      - name: "Verify Node test layout"
        run: |
          set -euo pipefail
          echo "üìÅ Working directory: ${WORKING_DIRECTORY}"

          if [ ! -d "${WORKING_DIRECTORY}" ]; then
            echo "‚ùå WORKING_DIRECTORY '${WORKING_DIRECTORY}' does not exist."
            exit 1
          fi

          if [ ! -f "${WORKING_DIRECTORY}/package.json" ]; then
            echo "‚ùå package.json not found in ${WORKING_DIRECTORY}."
            exit 1
          fi

          if [ ! -f "${WORKING_DIRECTORY}/Makefile" ]; then
            echo "‚ùå Makefile not found in ${WORKING_DIRECTORY}."
            echo "   Expected a Makefile exposing 'make test' (Node)."
            exit 1
          fi

      # -----------------------------------------------------------------------
      # 3) Setup Node.js runtime
      # -----------------------------------------------------------------------
      - name: "Setup Node.js"
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      # -----------------------------------------------------------------------
      # 4) Cache deps
      # -----------------------------------------------------------------------
      - name: "Cache Node dependencies (npm / Yarn / pnpm)"
        uses: BrikByte-Studios/.github/.github/actions/cache-node-deps@main
        with:
          node-version: ${{ env.NODE_VERSION }}
          project-path: ${{ env.WORKING_DIRECTORY }}

      # -----------------------------------------------------------------------
      # 5) Compute shard env (1-based for Makefile)
      # -----------------------------------------------------------------------
      - name: "Compute shard env (1-based for Makefile)"
        shell: bash
        run: |
          set -euo pipefail
          SHARD0="${SHARD_INDEX}"
          TOTAL="${SHARD_TOTAL}"
          SHARD1=$((SHARD0 + 1))

          {
            echo "UNIT_SHARD=${SHARD1}"
            echo "UNIT_SHARD_TOTAL=${TOTAL}"
          } >> "$GITHUB_ENV"

          echo "[SHARD] 0-based=${SHARD0} -> 1-based=${SHARD1} / total=${TOTAL}"

      # -----------------------------------------------------------------------
      # 6) Parallel runner selection (file-split)
      # -----------------------------------------------------------------------
      - name: "Parallel runner (serial/static/dynamic)"
        id: pr
        uses: BrikByte-Studios/.github/.github/actions/parallel-runner@main
        with:
          parallel_enabled: ${{ env.PARALLEL }}
          parallel_mode: ${{ env.PARALLEL_MODE }}
          shard_index: ${{ matrix.shard }}          # 0-based
          shard_total: ${{ strategy.job-total }}
          selection_mode: "file-split"
          working_directory: ${{ env.WORKING_DIRECTORY }}
          test_glob: "tests/unit/**/*.test.*"
          out_list: "${{ env.WORKING_DIRECTORY }}/out/shard-files.txt"
          allow_missing_items_file: true

      # -----------------------------------------------------------------------
      # Shared scripts repo (flaky-rerun.sh + evaluator sources + central policy)
      # -----------------------------------------------------------------------
      - name: "Checkout BrikByte shared scripts"
        uses: actions/checkout@v4
        with:
          repository: BrikByte-Studios/.github
          ref: main
          path: .brikbyte-github

      # -----------------------------------------------------------------------
      # Run unit tests via flaky-rerun.sh (2.5.1)
      # -----------------------------------------------------------------------
      - name: "Run Node.js unit tests (make test) with flaky reruns (opt-in)"
        if: steps.pr.outputs.is_empty_shard != 'true'
        working-directory: ${{ env.WORKING_DIRECTORY }}
        run: |
          set -euo pipefail

          echo "üß™ [TEST] Language      : ${LANGUAGE}"
          echo "üß™ [TEST] Runtime       : Node.js ${NODE_VERSION}"
          echo "üß™ [TEST] Directory     : ${PWD}"
          echo "üß™ [TEST] Command       : make test"
          echo "üß™ [TEST] Shard (Makefile 1-based): ${UNIT_SHARD}/${UNIT_SHARD_TOTAL}"
          echo "üß™ [TEST] Shard (Runner 0-based)  : ${SHARD_INDEX}/${SHARD_TOTAL}"
          echo "üß™ [TEST] Selection               : ${{ steps.pr.outputs.selection_path }}"
          echo "üß™ [TEST] FlakyDetect   : ${FLAKY_DETECT:-false}"
          echo "üß™ [TEST] FlakyReruns   : ${FLAKY_RERUNS:-3}"
          echo "üß™ [TEST] FlakyExport   : ${FLAKY_EXPORT_PATH:-out/flaky}"
          echo "üß™ [TEST] Status        : STARTING"

          export UNIT_SHARD UNIT_SHARD_TOTAL
          export TEST_ITEMS_FILE="${{ steps.pr.outputs.selection_path }}"

          # Wrapper config
          export FLAKY_DETECT="${FLAKY_DETECT:-false}"
          export FLAKY_RERUNS="${FLAKY_RERUNS:-3}"
          export FLAKY_EXPORT_PATH="${PWD}/${FLAKY_EXPORT_PATH:-out/flaky}"
          export FLAKY_LABEL="node-unit"

          BRIK_SCRIPTS="${GITHUB_WORKSPACE}/.brikbyte-github/.github/scripts"
          FLAKY_SH="${BRIK_SCRIPTS}/flaky-rerun.sh"

          if [[ ! -f "${FLAKY_SH}" ]]; then
            echo "‚ùå flaky-rerun.sh not found at: ${FLAKY_SH}"
            echo "üìÅ Available scripts:"
            ls -la "${BRIK_SCRIPTS}" || true
            exit 1
          fi
          chmod +x "${FLAKY_SH}"

          "${FLAKY_SH}" -- make test

          echo "‚úÖ [TEST] Status        : COMPLETED"

      - name: "Empty shard (skip)"
        if: steps.pr.outputs.is_empty_shard == 'true'
        run: echo "‚ÑπÔ∏è Empty shard ‚Äî nothing to run."

      # =============================================================================
      # PIPE-FLAKY-POLICY-CONFIG-002 ‚Äî Evaluate evidence against policy-as-code
      # =============================================================================

      - name: "Select policy source (repo override -> central fallback)"
        if: ${{ always() && env.FLAKY_DETECT == 'true' }}
        working-directory: ${{ github.workspace }}
        run: |
          set -euo pipefail

          mkdir -p .tmp-flaky-eval

          REPO_POLICY="${GITHUB_WORKSPACE}/${FLAKY_POLICY_PATH}"
          CENTRAL_POLICY="${GITHUB_WORKSPACE}/.brikbyte-github/.governance/flaky-tests.yml"
          OUT_POLICY="${GITHUB_WORKSPACE}/.tmp-flaky-eval/policy.yml"

          echo "üß© [FLAKY] Repo policy     : ${REPO_POLICY}"
          echo "üèõÔ∏è [FLAKY] Central policy  : ${CENTRAL_POLICY}"
          echo "üìå [FLAKY] Selected policy : ${OUT_POLICY}"

          if [[ -f "${REPO_POLICY}" ]]; then
            echo "‚úÖ [FLAKY] Using repo override policy."
            cp "${REPO_POLICY}" "${OUT_POLICY}"
          else
            if [[ ! -f "${CENTRAL_POLICY}" ]]; then
              echo "‚ùå [FLAKY] Central policy missing at: ${CENTRAL_POLICY}"
              exit 1
            fi
            echo "‚úÖ [FLAKY] Repo policy not found; using central policy."
            cp "${CENTRAL_POLICY}" "${OUT_POLICY}"
          fi

      # Fix module resolution: install at repo-root and run evaluator from stable CWD
      - name: "Install evaluator deps (repo-root, pinned) [js-yaml + tsx]"
        if: ${{ always() && env.FLAKY_DETECT == 'true' }}
        working-directory: ${{ github.workspace }}
        env:
          NPM_CONFIG_FUND: "false"
          NPM_CONFIG_AUDIT: "false"
        run: |
          set -euo pipefail
          node -v
          npm -v

          if [[ ! -f package.json ]]; then
            npm init -y >/dev/null 2>&1
          fi

          npm i --no-save js-yaml@4 tsx@4 >/dev/null 2>&1
          echo "‚úÖ deps installed into repo-root node_modules"

      # Normalize wrapper output to evaluator contract (same resolver strategy as Python)
      - name: "Normalize flaky summary (derive counts from exit_code)"
        if: ${{ always() && env.FLAKY_DETECT == 'true' }}
        working-directory: ${{ env.WORKING_DIRECTORY }}
        run: |
          set -euo pipefail

          EXPORT_DIR="${PWD}/${FLAKY_EXPORT_PATH}"
          EXPECTED="${EXPORT_DIR}/summary.json"
          LABELED="${EXPORT_DIR}/${FLAKY_LABEL:-node-unit}.summary.json"

          # Resolve evidence
          EVIDENCE=""
          if [[ -f "${EXPECTED}" ]]; then
            EVIDENCE="${EXPECTED}"
          elif [[ -f "${LABELED}" ]]; then
            EVIDENCE="${LABELED}"
          else
            found="$(ls -1 "${EXPORT_DIR}"/*.summary.json 2>/dev/null | head -n 1 || true)"
            if [[ -n "${found}" ]]; then EVIDENCE="${found}"; fi
          fi

          if [[ -z "${EVIDENCE}" ]]; then
            echo "‚ÑπÔ∏è [FLAKY] No evidence found ‚Üí skipping normalization."
            exit 0
          fi

          OUT_NORM="${EXPORT_DIR}/summary.normalized.json"
          echo "üîß [FLAKY] Normalizing: ${EVIDENCE} -> ${OUT_NORM}"

          EVIDENCE_PATH="${EVIDENCE}" OUT_NORM_PATH="${OUT_NORM}" python - << 'PY'
          import json, os
          from pathlib import Path

          evidence = Path(os.environ["EVIDENCE_PATH"])
          out_norm = Path(os.environ["OUT_NORM_PATH"])

          data = json.loads(evidence.read_text(encoding="utf-8"))

          attempts = data.get("attempts") if isinstance(data, dict) else None
          if not isinstance(attempts, list):
              attempts = []

          pass_count = 0
          fail_count = 0

          for a in attempts:
              if not isinstance(a, dict):
                  continue

              status = (a.get("status") or a.get("result") or "").lower().strip()
              if status in ("pass", "passed", "ok", "success"):
                  pass_count += 1
                  a["status"] = "pass"
                  continue
              if status in ("fail", "failed", "error"):
                  fail_count += 1
                  a["status"] = "fail"
                  continue

              exit_code = a.get("exit_code")
              try:
                  exit_code = int(exit_code)
              except Exception:
                  exit_code = None

              if exit_code == 0:
                  pass_count += 1
                  a["status"] = "pass"
              else:
                  fail_count += 1
                  a["status"] = "fail"

          total_attempts = len(attempts)

          data["attempts"] = attempts
          data["pass_count"] = pass_count
          data["fail_count"] = fail_count
          data["total_attempts"] = total_attempts

          out_norm.write_text(json.dumps(data, indent=2), encoding="utf-8")
          print(f"‚úÖ wrote {out_norm} (pass={pass_count}, fail={fail_count}, total={total_attempts})")
          PY

      - name: "Evaluate flaky policy (normalized + policy-as-code)"
        if: ${{ always() && env.FLAKY_DETECT == 'true' }}
        working-directory: ${{ env.WORKING_DIRECTORY }}
        run: |
          set -euo pipefail

          EXPORT_DIR="${PWD}/${FLAKY_EXPORT_PATH}"
          POLICY="${GITHUB_WORKSPACE}/.tmp-flaky-eval/policy.yml"

          NORM="${EXPORT_DIR}/summary.normalized.json"
          OUT_JSON="${EXPORT_DIR}/evaluation.json"

          echo "üß© [FLAKY] Policy     : ${POLICY}"
          echo "üìÅ [FLAKY] Export dir : ${EXPORT_DIR}"
          echo "üì• [FLAKY] Normalized : ${NORM}"
          echo "üì§ [FLAKY] Output     : ${OUT_JSON}"
          echo "üõ°Ô∏è [FLAKY] Enforce    : ${FLAKY_POLICY_ENFORCE}"

          if [[ ! -f "${NORM}" ]]; then
            echo "‚ÑπÔ∏è [FLAKY] Normalized summary missing ‚Üí skipping evaluation (non-blocking)."
            exit 0
          fi

          EVAL_TS="${GITHUB_WORKSPACE}/.brikbyte-github/.github/scripts/evaluate-flaky.ts"
          if [[ ! -f "${EVAL_TS}" ]]; then
            echo "‚ùå [FLAKY] evaluate-flaky.ts not found at: ${EVAL_TS}"
            exit 1
          fi

          # Run from repo root so node resolves js-yaml
          pushd "${GITHUB_WORKSPACE}" >/dev/null
          npx tsx "${EVAL_TS}" \
            --policy "${POLICY}" \
            --input "${NORM}" \
            --out "${OUT_JSON}" \
            --md || rc=$?
          popd >/dev/null

          if [[ "${rc:-0}" != "0" && "${FLAKY_POLICY_ENFORCE}" != "true" ]]; then
            echo "‚ö†Ô∏è [FLAKY] Evaluator exit=${rc} but enforce=false ‚Üí not blocking."
            exit 0
          fi

          exit "${rc:-0}"

      - name: "Export flaky analytics (when enabled)"
        if: ${{ always() && env.FLAKY_DETECT == 'true' }}
        working-directory: ${{ env.WORKING_DIRECTORY }}
        run: |
          set -euo pipefail
          BRIK_SCRIPTS="${GITHUB_WORKSPACE}/.brikbyte-github/.github/scripts"
          EXPORT_MJS="${BRIK_SCRIPTS}/export-flaky-analytics.mjs"

          if [[ ! -f "${EXPORT_MJS}" ]]; then
            echo "‚ùå export-flaky-analytics.mjs not found at: ${EXPORT_MJS}"
            echo "üìÅ Available scripts:"
            ls -la "${BRIK_SCRIPTS}" || true
            exit 1
          fi

          chmod +x "${EXPORT_MJS}"

          # Use explicit input/eval paths (matches Python wiring and avoids CWD surprises)
          node "${EXPORT_MJS}" \
            --suite node-unit \
            --audit-root "${GITHUB_WORKSPACE}/.audit" \
            --out-dir "${FLAKY_EXPORT_PATH:-out/flaky}" \
            --input "${PWD}/${FLAKY_EXPORT_PATH}/summary.normalized.json" \
            --evaluation "${PWD}/${FLAKY_EXPORT_PATH}/evaluation.json" \
            --top-n 10 \
            --write-md true \
            --allow-missing-evaluation true

      # -----------------------------------------------------------------------
      # Upload flaky artifacts
      # -----------------------------------------------------------------------
      - name: "Upload flaky audit ledger (.audit) ‚Äî shard"
        if: ${{ always() && env.FLAKY_DETECT == 'true' }}
        uses: actions/upload-artifact@v4
        with:
          name: flaky-audit-${{ env.LANGUAGE }}-shard${{ matrix.shard }}
          path: |
            .audit/**/flaky/*.json
          if-no-files-found: warn
          include-hidden-files: true
          retention-days: 14

      - name: "Upload flaky evaluation (always)"
        if: ${{ always() && env.FLAKY_DETECT == 'true' }}
        uses: actions/upload-artifact@v4
        with:
          name: flaky-eval-${{ env.LANGUAGE }}-shard${{ matrix.shard }}
          path: |
            ${{ env.WORKING_DIRECTORY }}/${{ inputs.flaky_export_path }}/
          if-no-files-found: warn
          include-hidden-files: true
          retention-days: 14

      - name: "Upload JUnit (for flaky report) ‚Äî shard"
        if: ${{ always() && env.FLAKY_DETECT == 'true' }}
        uses: actions/upload-artifact@v4
        with:
          name: junit-${{ env.LANGUAGE }}-shard${{ matrix.shard }}
          path: |
            ${{ env.WORKING_DIRECTORY }}/out/junit.xml
          if-no-files-found: warn
          retention-days: 14

      # -----------------------------------------------------------------------
      # Coverage handling + uploads...
      # -----------------------------------------------------------------------
      - name: "Detect coverage presence"
        id: cov
        working-directory: ${{ env.WORKING_DIRECTORY }}
        run: |
          set -euo pipefail
          if [ -f "coverage/coverage-final.json" ] || [ -f "coverage/coverage-summary.json" ]; then
            echo "has_coverage=true" >> "$GITHUB_OUTPUT"
          else
            echo "has_coverage=false" >> "$GITHUB_OUTPUT"
          fi

      - name: "Normalize coverage ‚Üí coverage.json"
        if: ${{ steps.cov.outputs.has_coverage == 'true' }}
        uses: BrikByte-Studios/.github/.github/actions/coverage-merge@main
        with:
          language: ${{ env.LANGUAGE }}
          working-directory: ${{ env.WORKING_DIRECTORY }}
          out: out/coverage.json

      - name: "Detect out/coverage.json presence"
        id: covjson
        working-directory: ${{ env.WORKING_DIRECTORY }}
        run: |
          set -euo pipefail
          if [ -f "out/coverage.json" ]; then
            echo "has_covjson=true" >> "$GITHUB_OUTPUT"
          else
            echo "has_covjson=false" >> "$GITHUB_OUTPUT"
          fi

      - name: "Ensure summary.line is set in coverage.json (Node + c8 json-summary)"
        if: ${{ steps.cov.outputs.has_coverage == 'true' }}
        working-directory: ${{ env.WORKING_DIRECTORY }}
        run: |
          set -euo pipefail
          echo "üîß Normalizing coverage: syncing summary.line from coverage/coverage-summary.json"

          # Empty shard => no tests executed => no coverage folder.
          if [ ! -f "coverage/coverage-summary.json" ]; then
            echo "‚ÑπÔ∏è No coverage/coverage-summary.json found (likely empty shard). Skipping summary sync."
            exit 0
          fi

          node - << 'EOF'
          const fs = require('fs');

          function readJson(p) {
            return JSON.parse(fs.readFileSync(p, 'utf8'));
          }

          const summary = readJson('coverage/coverage-summary.json');
          if (!summary.total || !summary.total.lines || typeof summary.total.lines.pct !== 'number') {
            console.error('Unexpected coverage-summary.json format. total.lines.pct is missing.');
            process.exit(1);
          }

          const linePct = summary.total.lines.pct;

          let cov;
          try { cov = readJson('out/coverage.json'); } catch { cov = {}; }

          if (!cov.summary || typeof cov.summary !== 'object') cov.summary = {};
          cov.summary.line = linePct;

          if (!Array.isArray(cov.files)) cov.files = [];

          fs.mkdirSync('out', { recursive: true });
          fs.writeFileSync('out/coverage.json', JSON.stringify(cov, null, 2));
          console.log('‚úÖ Updated out/coverage.json with summary.line =', linePct);
          EOF

      - name: "Upload Node coverage artifacts (per shard)"
        if: ${{ steps.covjson.outputs.has_covjson == 'true' }}
        uses: actions/upload-artifact@v4
        with:
          name: coverage-${{ env.LANGUAGE }}-shard${{ matrix.shard }}
          path: |
            ${{ env.WORKING_DIRECTORY }}/out/coverage.json
            ${{ env.WORKING_DIRECTORY }}/coverage/
            ${{ env.WORKING_DIRECTORY }}/out/junit.xml
            ${{ env.WORKING_DIRECTORY }}/out/shard-files.txt
            ${{ env.WORKING_DIRECTORY }}/out/shard-packages.txt
          if-no-files-found: error
          include-hidden-files: true
          retention-days: 14

      - name: "Upload flaky evidence (always)"
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: flaky-${{ env.LANGUAGE }}-shard${{ matrix.shard }}
          path: |
            ${{ env.WORKING_DIRECTORY }}/${{ inputs.flaky_export_path }}/
          if-no-files-found: ignore
          include-hidden-files: true
          retention-days: 14
