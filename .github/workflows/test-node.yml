# =============================================================================
# BrikByteOS ‚Äî Reusable Node.js Unit Test Workflow (with governed matrix-plan)
# -----------------------------------------------------------------------------
# WBS ID : PIPE-TEST-UNIT-CI-BUILD-002
#
# Adds:
#   - Deterministic shards via BrikPipe matrix-plan (unit)
#   - Safe-by-default shard caps (clamped by parallel-matrix.yml in .github repo)
#   - Per-shard coverage artifact naming to support merge later
# =============================================================================
name: "BrikByteOS ‚Äî Node.js Unit Tests"

on:
  workflow_call:
    inputs:
      node-version:
        description: "Node.js version (must align with Runtime Matrix)"
        required: false
        type: string
        default: "20"

      working-directory:
        description: "Path to Node project (folder with package.json + Makefile)"
        required: false
        type: string
        default: "."

      # -----------------------------
      # Matrix-plan (unit) wiring
      # -----------------------------
      override_shards:
        description: "Requested shard count (unit). Will be clamped by governance caps."
        required: false
        type: string
        default: ""

      matrix_config_path:
        description: "Optional path to parallel-matrix.yml. Leave empty to use action default."
        required: false
        type: string
        default: ""

      parallel_mode:
        description: "Parallel mode: static|dynamic (default static)"
        required: false
        type: string
        default: "static"

      parallel_enabled:
        description: "Enable parallel shard execution (true|false)"
        required: false
        type: string
        default: "true"

      # -----------------------------------------------------------------------
      # Flaky detection (PIPE-FLAKY-RERUN-INTEG-001)
      # -----------------------------------------------------------------------
      flaky_detect:
        description: "Enable suite-level flaky detection reruns (true|false)"
        required: false
        type: string
        default: "false"

      flaky_reruns:
        description: "Total attempts when flaky_detect=true (e.g., 3)"
        required: false
        type: string
        default: "3"

      flaky_export_path:
        description: "Relative path (from working-directory) to store flaky evidence"
        required: false
        type: string
        default: "out/flaky"

      # -----------------------------------------------------------------------
      # Flaky policy evaluation (PIPE-FLAKY-POLICY-CONFIG-002)
      # -----------------------------------------------------------------------
      flaky_policy_path:
        description: >
          Path to policy-as-code YAML (repo root) IF repo overrides exist.
          NOTE: If missing, central policy from BrikByte-Studios/.github is used.
        required: false
        type: string
        default: ".governance/flaky-tests.yml"

      flaky_policy_enforce:
        description: >
          If true, evaluator may block ONLY if policy enables blocking.
          If false, evaluator still runs (when flaky_detect=true) but never blocks.
        required: false
        type: boolean
        default: true

permissions:
  contents: read

jobs:
  # ----------------------------------------------------------------------------
  # PLAN: governed deterministic matrix (unit shards)
  # ----------------------------------------------------------------------------
  plan:
    name: "Plan governed Unit matrix"
    runs-on: ubuntu-latest
    outputs:
      matrix: ${{ steps.plan.outputs.matrix_json }}
    steps:
      - name: "Checkout repository"
        uses: actions/checkout@v4

      - name: "Generate unit shard matrix (governed)"
        id: plan
        uses: BrikByte-Studios/.github/.github/actions/matrix-plan@main
        with:
          test_type: unit
          config_path: ${{ inputs.matrix_config_path }}
          override_shards: ${{ inputs.override_shards }}

  # ----------------------------------------------------------------------------
  # TEST: shard matrix
  # ----------------------------------------------------------------------------
  test:
    name: "Node.js: Unit Tests ‚Ä¢ shard ${{ matrix.shard }}"
    needs: plan
    runs-on: ubuntu-latest

    strategy:
      fail-fast: false
      matrix: ${{ fromJson(needs.plan.outputs.matrix) }}

    env:
      LANGUAGE: node
      NODE_VERSION: ${{ inputs.node-version != '' && inputs.node-version || '20' }}
      WORKING_DIRECTORY: ${{ inputs.working-directory != '' && inputs.working-directory || '.' }}

      # Shard contract (consumed by your Makefile/test runner when implemented)
      SHARD_INDEX: ${{ matrix.shard }}              # 0-based
      SHARD_TOTAL: ${{ strategy.job-total }}

      # Optional generic contract (if you want to standardize across languages).
      E2E_SHARD: ${{ matrix.shard }}
      E2E_SHARD_TOTAL: ${{ strategy.job-total }}

      PARALLEL_MODE: ${{ inputs.parallel_mode }}
      PARALLEL: ${{ inputs.parallel_enabled }}

      # Flaky detection (2.5.1)
      FLAKY_DETECT: ${{ inputs.flaky_detect }}
      FLAKY_RERUNS: ${{ inputs.flaky_reruns }}
      FLAKY_EXPORT_PATH: ${{ inputs.flaky_export_path }}

      # Flaky policy (2.5.2)
      FLAKY_POLICY_PATH: ${{ inputs.flaky_policy_path }}
      FLAKY_POLICY_ENFORCE: ${{ inputs.flaky_policy_enforce }}

      FORCE_COLOR: "0"

    steps:
      # -----------------------------------------------------------------------
      # 1) Checkout repository
      # -----------------------------------------------------------------------
      - name: Checkout repository
        uses: actions/checkout@v4

      # -----------------------------------------------------------------------
      # 2) Verify Node project layout
      # -----------------------------------------------------------------------
      - name: Verify Node test layout
        run: |
          set -euo pipefail
          echo "üìÅ Working directory: ${WORKING_DIRECTORY}"

          if [ ! -d "${WORKING_DIRECTORY}" ]; then
            echo "‚ùå WORKING_DIRECTORY '${WORKING_DIRECTORY}' does not exist."
            exit 1
          fi

          if [ ! -f "${WORKING_DIRECTORY}/package.json" ]; then
            echo "‚ùå package.json not found in ${WORKING_DIRECTORY}."
            exit 1
          fi

          if [ ! -f "${WORKING_DIRECTORY}/Makefile" ]; then
            echo "‚ùå Makefile not found in ${WORKING_DIRECTORY}."
            echo "   Expected a Makefile exposing 'make test' (Node)."
            exit 1
          fi

      # -----------------------------------------------------------------------
      # 3) Setup Node.js runtime
      # -----------------------------------------------------------------------
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      # -----------------------------------------------------------------------
      # 4) Cache deps.
      # -----------------------------------------------------------------------
      - name: "Cache Node dependencies (npm / Yarn / pnpm)"
        uses: BrikByte-Studios/.github/.github/actions/cache-node-deps@main
        with:
          node-version: ${{ env.NODE_VERSION }}
          project-path: ${{ env.WORKING_DIRECTORY }}

      - name: Compute shard env (1-based for Makefile)
        shell: bash
        run: |
          set -euo pipefail

          # matrix.shard is 0-based
          SHARD0="${SHARD_INDEX}"
          TOTAL="${SHARD_TOTAL}"

          # Convert to 1-based (for your Node Makefile/shard runner)
          SHARD1=$((SHARD0 + 1))

          {
            echo "UNIT_SHARD=${SHARD1}"
            echo "UNIT_SHARD_TOTAL=${TOTAL}"
          } >> "$GITHUB_ENV"

          echo "[SHARD] 0-based=${SHARD0} -> 1-based=${SHARD1} / total=${TOTAL}"

      - name: Parallel runner (serial/static/dynamic)
        id: pr
        uses: BrikByte-Studios/.github/.github/actions/parallel-runner@main
        with:
          parallel_enabled: ${{ env.PARALLEL }}
          parallel_mode: ${{ env.PARALLEL_MODE }}
          shard_index: ${{ matrix.shard }}          # 0-based
          shard_total: ${{ strategy.job-total }}
          selection_mode: "file-split"
          working_directory: ${{ env.WORKING_DIRECTORY }}
          test_glob: "tests/unit/**/*.test.*"
          out_list: "${{ env.WORKING_DIRECTORY }}/out/shard-files.txt"
          allow_missing_items_file: true

      # -----------------------------------------------------------------------
      # Shared scripts repo (flaky-rerun.sh + evaluator sources + central policy)
      # -----------------------------------------------------------------------
      - name: Checkout BrikByte shared scripts
        uses: actions/checkout@v4
        with:
          repository: BrikByte-Studios/.github
          ref: main
          path: .brikbyte-github

      # -----------------------------------------------------------------------
      # 5) Run unit tests via `make test` (wired through flaky-rerun.sh)
      # -----------------------------------------------------------------------
      - name: Run Node.js unit tests (make test) with flaky reruns (opt-in)
        if: steps.pr.outputs.is_empty_shard != 'true'
        working-directory: ${{ env.WORKING_DIRECTORY }}
        run: |
          set -euo pipefail

          echo "üß™ [TEST] Language      : ${LANGUAGE}"
          echo "üß™ [TEST] Runtime       : Node.js ${NODE_VERSION}"
          echo "üß™ [TEST] Directory     : ${PWD}"
          echo "üß™ [TEST] Command       : make test"
          echo "üß™ [TEST] Shard (Makefile 1-based): ${UNIT_SHARD}/${UNIT_SHARD_TOTAL}"
          echo "üß™ [TEST] Shard (Runner 0-based)  : ${SHARD_INDEX}/${SHARD_TOTAL}"
          echo "üß™ [TEST] Selection               : ${{ steps.pr.outputs.selection_path }}"
          echo "üß™ [TEST] FlakyDetect   : ${FLAKY_DETECT:-false}"
          echo "üß™ [TEST] FlakyReruns   : ${FLAKY_RERUNS:-3}"
          echo "üß™ [TEST] FlakyExport   : ${FLAKY_EXPORT_PATH:-out/flaky}"
          echo "üß™ [TEST] Status        : STARTING"

          export UNIT_SHARD UNIT_SHARD_TOTAL
          export TEST_ITEMS_FILE="${{ steps.pr.outputs.selection_path }}"

          # Flaky wrapper config (used by flaky-rerun.sh)
          export FLAKY_DETECT="${FLAKY_DETECT:-false}"
          export FLAKY_RERUNS="${FLAKY_RERUNS:-3}"
          export FLAKY_EXPORT_PATH="${PWD}/${FLAKY_EXPORT_PATH:-out/flaky}"
          export FLAKY_LABEL="node-unit"

          BRIK_SCRIPTS="${GITHUB_WORKSPACE}/.brikbyte-github/.github/scripts"
          FLAKY_SH="${BRIK_SCRIPTS}/flaky-rerun.sh"

          if [[ ! -f "${FLAKY_SH}" ]]; then
            echo "‚ùå flaky-rerun.sh not found at: ${FLAKY_SH}"
            echo "üìÅ Available scripts:"
            ls -la "${BRIK_SCRIPTS}" || true
            exit 1
          fi
          chmod +x "${FLAKY_SH}"

          # Run through wrapper (opt-in via FLAKY_DETECT)
          "${FLAKY_SH}" -- make test

          echo "‚úÖ [TEST] Status        : COMPLETED"

      - name: Empty shard (skip)
        if: steps.pr.outputs.is_empty_shard == 'true'
        run: echo "‚ÑπÔ∏è Empty shard ‚Äî nothing to run."

      # =============================================================================
      # PIPE-FLAKY-POLICY-CONFIG-002 ‚Äî Evaluate evidence against policy-as-code
      # =============================================================================

      # Node is already set up above, so no extra setup-node step needed here.

      - name: "Select policy source (repo override -> central fallback)"
        if: ${{ always() && env.FLAKY_DETECT == 'true' }}
        working-directory: ${{ github.workspace }}
        run: |
          set -euo pipefail

          mkdir -p .tmp-flaky-eval

          REPO_POLICY="${GITHUB_WORKSPACE}/${FLAKY_POLICY_PATH}"
          CENTRAL_POLICY="${GITHUB_WORKSPACE}/.brikbyte-github/.governance/flaky-tests.yml"
          OUT_POLICY="${GITHUB_WORKSPACE}/.tmp-flaky-eval/policy.yml"

          echo "üß© [FLAKY] Repo policy     : ${REPO_POLICY}"
          echo "üèõÔ∏è [FLAKY] Central policy  : ${CENTRAL_POLICY}"
          echo "üìå [FLAKY] Selected policy : ${OUT_POLICY}"

          if [[ -f "${REPO_POLICY}" ]]; then
            echo "‚úÖ [FLAKY] Using repo override policy."
            cp "${REPO_POLICY}" "${OUT_POLICY}"
          else
            if [[ ! -f "${CENTRAL_POLICY}" ]]; then
              echo "‚ùå [FLAKY] Central policy missing at: ${CENTRAL_POLICY}"
              exit 1
            fi
            echo "‚úÖ [FLAKY] Repo policy not found; using central policy."
            cp "${CENTRAL_POLICY}" "${OUT_POLICY}"
          fi

      # Avoid ‚ÄúCannot find module 'js-yaml'‚Äù:
      # Install deps at repo root so tsx + require() resolve regardless of CWD.
      - name: "Install evaluator deps (repo-root, pinned) [js-yaml + tsx]"
        if: ${{ always() && env.FLAKY_DETECT == 'true' }}
        working-directory: ${{ github.workspace }}
        env:
          NPM_CONFIG_FUND: "false"
          NPM_CONFIG_AUDIT: "false"
        run: |
          set -euo pipefail
          node -v
          npm -v

          if [[ ! -f package.json ]]; then
            npm init -y >/dev/null 2>&1
          fi

          npm i --no-save js-yaml@4 tsx@4 >/dev/null 2>&1
          echo "‚úÖ deps installed into repo-root node_modules"

      # Avoid ‚ÄúInvalid summary: total_attempts must equal fail_count + pass_count‚Äù:
      # Normalize wrapper output to evaluator contract.
      - name: "Normalize flaky evidence ‚Üí summary.normalized.json"
        if: ${{ always() && env.FLAKY_DETECT == 'true' }}
        working-directory: ${{ env.WORKING_DIRECTORY }}
        run: |
          set -euo pipefail

          EXPORT_DIR="${PWD}/${FLAKY_EXPORT_PATH}"
          EXPECTED="${EXPORT_DIR}/summary.json"
          LABELED="${EXPORT_DIR}/${FLAKY_LABEL:-node-unit}.summary.json"

          # Resolve evidence
          EVIDENCE=""
          if [[ -f "${EXPECTED}" ]]; then
            EVIDENCE="${EXPECTED}"
          elif [[ -f "${LABELED}" ]]; then
            EVIDENCE="${LABELED}"
          else
            found="$(ls -1 "${EXPORT_DIR}"/*.summary.json 2>/dev/null | head -n 1 || true)"
            if [[ -n "${found}" ]]; then EVIDENCE="${found}"; fi
          fi

          if [[ -z "${EVIDENCE}" ]]; then
            echo "‚ÑπÔ∏è [FLAKY] No evidence found ‚Üí skipping normalization."
            ls -la "${EXPORT_DIR}" || true
            exit 0
          fi

          OUT_NORM="${EXPORT_DIR}/summary.normalized.json"
          echo "üîß [FLAKY] Normalizing: ${EVIDENCE} -> ${OUT_NORM}"

          python - <<'PY'
          import json
          from pathlib import Path
          import os

          evidence = Path(os.environ["EVIDENCE"])
          out_norm = Path(os.environ["OUT_NORM"])

          data = json.loads(evidence.read_text(encoding="utf-8"))

          # Attempts-based normalization
          attempts = data.get("attempts") if isinstance(data, dict) else None
          pass_count = 0
          fail_count = 0
          total_attempts = 0

          if isinstance(attempts, list) and attempts:
            total_attempts = len(attempts)
            for a in attempts:
              # Prefer explicit status; else infer from exit_code
              s = (a.get("status") or "").strip().lower()
              if not s:
                rc = int(a.get("exit_code", 0) or 0)
                s = "pass" if rc == 0 else "fail"
                a["status"] = s

              if s in ("pass", "passed", "ok", "success"):
                pass_count += 1
              elif s in ("fail", "failed", "error"):
                fail_count += 1

          else:
            # Counter-based normalization fallback
            pass_count = int(data.get("pass_count", 0) or 0) if isinstance(data, dict) else 0
            fail_count = int(data.get("fail_count", 0) or 0) if isinstance(data, dict) else 0
            total_attempts = pass_count + fail_count

          if isinstance(data, dict):
            data["pass_count"] = pass_count
            data["fail_count"] = fail_count
            data["total_attempts"] = total_attempts
            data["attempts"] = attempts if isinstance(attempts, list) else data.get("attempts", [])

          out_norm.parent.mkdir(parents=True, exist_ok=True)
          out_norm.write_text(json.dumps(data, indent=2), encoding="utf-8")
          print(f"‚úÖ wrote {out_norm} (pass={pass_count}, fail={fail_count}, total={total_attempts})")
          PY
        env:
          EVIDENCE: ${{ env.WORKING_DIRECTORY }}/${{ inputs.flaky_export_path }}/${{ env.FLAKY_LABEL || 'node-unit' }}.summary.json
          OUT_NORM: ${{ env.WORKING_DIRECTORY }}/${{ inputs.flaky_export_path }}/summary.normalized.json

      - name: "Evaluate flaky policy (use normalized summary)"
        if: ${{ always() && env.FLAKY_DETECT == 'true' }}
        working-directory: ${{ env.WORKING_DIRECTORY }}
        run: |
          set -euo pipefail

          POLICY="${GITHUB_WORKSPACE}/.tmp-flaky-eval/policy.yml"
          EXPORT_DIR="${PWD}/${FLAKY_EXPORT_PATH}"
          IN_NORM="${EXPORT_DIR}/summary.normalized.json"
          OUT_JSON="${EXPORT_DIR}/evaluation.json"

          echo "üß© [FLAKY] Policy     : ${POLICY}"
          echo "üìÅ [FLAKY] Export dir : ${EXPORT_DIR}"
          echo "üì• [FLAKY] Normalized : ${IN_NORM}"
          echo "üì§ [FLAKY] Output     : ${OUT_JSON}"
          echo "üõ°Ô∏è [FLAKY] Enforce    : ${FLAKY_POLICY_ENFORCE}"

          if [[ ! -f "${POLICY}" ]]; then
            echo "‚ùå [FLAKY] Missing policy file: ${POLICY}"
            exit 1
          fi

          if [[ ! -f "${IN_NORM}" ]]; then
            echo "‚ÑπÔ∏è [FLAKY] Normalized summary missing ‚Üí skipping evaluation (non-blocking)."
            ls -la "${EXPORT_DIR}" || true
            exit 0
          fi

          EVAL_TS="${GITHUB_WORKSPACE}/.brikbyte-github/.github/scripts/evaluate-flaky.ts"
          if [[ ! -f "${EVAL_TS}" ]]; then
            echo "‚ùå [FLAKY] evaluate-flaky.ts not found at: ${EVAL_TS}"
            exit 1
          fi

          # Run evaluator from repo root so module resolution is stable.
          pushd "${GITHUB_WORKSPACE}" >/dev/null
          npx tsx "${EVAL_TS}" \
            --policy "${POLICY}" \
            --input "${IN_NORM}" \
            --out "${OUT_JSON}" \
            --md || rc=$?
          popd >/dev/null

          if [[ "${rc:-0}" != "0" && "${FLAKY_POLICY_ENFORCE}" != "true" ]]; then
            echo "‚ö†Ô∏è [FLAKY] Evaluator exit=${rc} but enforce=false ‚Üí not blocking."
            exit 0
          fi

          exit "${rc:-0}"
      - name: Export flaky analytics (when enabled)
        if: ${{ always() && env.FLAKY_DETECT == 'true' }}
        working-directory: ${{ env.WORKING_DIRECTORY }}
        run: |
          set -euo pipefail
          BRIK_SCRIPTS="${GITHUB_WORKSPACE}/.brikbyte-github/.github/scripts"
          FLAKY_SH="${BRIK_SCRIPTS}/export-flaky-analytics.mjs"

          if [[ ! -f "${FLAKY_SH}" ]]; then
            echo "‚ùå export-flaky-analytics.ts not found at: ${FLAKY_SH}"
            echo "üìÅ Available scripts:"
            ls -la "${BRIK_SCRIPTS}" || true
            exit 1
          fi

          chmod +x "${FLAKY_SH}"
          node "${FLAKY_SH}" \
            --suite unit \
            --audit-root "${GITHUB_WORKSPACE}/.audit" \
            --out-dir "${FLAKY_EXPORT_PATH:-out/flaky}" \
            --top-n 10 \
            --write-md true \
            --allow-missing-evaluation true
      - name: "Upload flaky evaluation (always)"
        if: ${{ always() && env.FLAKY_DETECT == 'true' }}
        uses: actions/upload-artifact@v4
        with:
          name: flaky-eval-${{ env.LANGUAGE }}-shard${{ matrix.shard }}
          path: |
            ${{ env.WORKING_DIRECTORY }}/${{ inputs.flaky_export_path }}/
          if-no-files-found: warn
          include-hidden-files: true
          retention-days: 14

      # -----------------------------------------------------------------------
      # Coverage handling + uploads...
      # -----------------------------------------------------------------------
      - name: Detect coverage presence
        id: cov
        working-directory: ${{ env.WORKING_DIRECTORY }}
        run: |
          set -euo pipefail
          if [ -f "coverage/coverage-final.json" ] || [ -f "coverage/coverage-summary.json" ]; then
            echo "has_coverage=true" >> "$GITHUB_OUTPUT"
          else
            echo "has_coverage=false" >> "$GITHUB_OUTPUT"
          fi

      - name: Normalize coverage ‚Üí coverage.json
        if: steps.cov.outputs.has_coverage == 'true'
        uses: BrikByte-Studios/.github/.github/actions/coverage-merge@main
        with:
          language: ${{ env.LANGUAGE }}
          working-directory: ${{ env.WORKING_DIRECTORY }}
          out: out/coverage.json

      - name: Detect out/coverage.json presence
        id: covjson
        working-directory: ${{ env.WORKING_DIRECTORY }}
        run: |
          set -euo pipefail
          if [ -f "out/coverage.json" ]; then
            echo "has_covjson=true" >> "$GITHUB_OUTPUT"
          else
            echo "has_covjson=false" >> "$GITHUB_OUTPUT"
          fi

      - name: Ensure summary.line is set in coverage.json (Node + c8 json-summary)
        working-directory: ${{ env.WORKING_DIRECTORY }}
        run: |
          set -euo pipefail
          echo "üîß Normalizing coverage: syncing summary.line from coverage/coverage-summary.json"

          # Empty shard => no tests executed => no coverage folder.
          if [ ! -f "coverage/coverage-summary.json" ]; then
            echo "‚ÑπÔ∏è No coverage/coverage-summary.json found (likely empty shard). Skipping summary sync."
            ls -la
            exit 0
          fi

          node - << 'EOF'
          const fs = require('fs');

          function readJson(path) {
            return JSON.parse(fs.readFileSync(path, 'utf8'));
          }

          const summary = readJson('coverage/coverage-summary.json');

          if (!summary.total || !summary.total.lines || typeof summary.total.lines.pct !== 'number') {
            console.error('Unexpected coverage-summary.json format. total.lines.pct is missing.');
            process.exit(1);
          }

          const linePct = summary.total.lines.pct;

          let cov;
          try { cov = readJson('out/coverage.json'); } catch { cov = {}; }

          if (!cov.summary || typeof cov.summary !== 'object') cov.summary = {};
          cov.summary.line = linePct;

          if (!Array.isArray(cov.files)) cov.files = [];

          fs.mkdirSync('out', { recursive: true });
          fs.writeFileSync('out/coverage.json', JSON.stringify(cov, null, 2));
          console.log('‚úÖ Updated out/coverage.json with summary.line =', linePct);
          EOF

      - name: Upload Node coverage artifacts (per shard)
        if: steps.covjson.outputs.has_covjson == 'true'
        uses: actions/upload-artifact@v4
        with:
          name: coverage-${{ env.LANGUAGE }}-shard${{ matrix.shard }}
          path: |
            ${{ env.WORKING_DIRECTORY }}/out/coverage.json
            ${{ env.WORKING_DIRECTORY }}/coverage/
            ${{ env.WORKING_DIRECTORY }}/out/junit.xml
            ${{ env.WORKING_DIRECTORY }}/out/shard-files.txt
            ${{ env.WORKING_DIRECTORY }}/out/shard-packages.txt
          if-no-files-found: error
          include-hidden-files: true
          retention-days: 14

      - name: Upload flaky evidence (always)
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: flaky-${{ env.LANGUAGE }}-shard${{ matrix.shard }}
          path: |
            ${{ env.WORKING_DIRECTORY }}/${{ inputs.flaky_export_path }}/
          if-no-files-found: ignore
          include-hidden-files: true
          retention-days: 14
